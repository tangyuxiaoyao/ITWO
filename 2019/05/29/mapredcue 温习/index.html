<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>mapreduce 温故 | ITWO</title><meta name="description" content="mapreduce 温故"><meta name="keywords" content="mapreduce,shuffer"><meta name="author" content="唐钰逍遥"><meta name="copyright" content="唐钰逍遥"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/ITWO/img/favicon.ico"><link rel="stylesheet" href="/ITWO/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="http://www.tangyuxiaoyao.club/ITWO/2019/05/29/mapredcue 温习/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="mapreduce 温故"><meta name="twitter:description" content="mapreduce 温故"><meta name="twitter:image" content="https://s2.ax1x.com/2019/07/11/ZRK5z6.jpg"><meta property="og:type" content="article"><meta property="og:title" content="mapreduce 温故"><meta property="og:url" content="http://www.tangyuxiaoyao.club/ITWO/2019/05/29/mapredcue 温习/"><meta property="og:site_name" content="ITWO"><meta property="og:description" content="mapreduce 温故"><meta property="og:image" content="https://s2.ax1x.com/2019/07/11/ZRK5z6.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="Hadoop HDFS 数据自动平衡" href="http://www.tangyuxiaoyao.club/ITWO/2019/05/29/ Hadoop HDFS 数据自动平衡/"><link rel="next" title="线上mongo查询过慢排查总结" href="http://www.tangyuxiaoyao.club/ITWO/2019/05/29/线上mongo查询过慢排查总结/"><script>var GLOBAL_CONFIG = { 
  root: '/ITWO/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"cookieDomain":"http://www.tangyuxiaoyao.club/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Bookmark',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days'

  
}</script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#需求背景："><span class="toc-number">1.</span> <span class="toc-text">需求背景：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapreduce"><span class="toc-number">2.</span> <span class="toc-text">mapreduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reduce个数的计算方法"><span class="toc-number">3.</span> <span class="toc-text">reduce个数的计算方法:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#流程细节："><span class="toc-number">4.</span> <span class="toc-text">流程细节：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#map输出过程："><span class="toc-number">4.1.</span> <span class="toc-text">map输出过程：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reducer如何知道要从哪个tasktracker取得map输出呢？"><span class="toc-number">4.2.</span> <span class="toc-text">reducer如何知道要从哪个tasktracker取得map输出呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#map和reduce如何合理控制自己的个数？"><span class="toc-number">4.3.</span> <span class="toc-text">map和reduce如何合理控制自己的个数？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapreduce进度说明"><span class="toc-number">5.</span> <span class="toc-text">mapreduce进度说明</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Prepare"><span class="toc-number">5.1.</span> <span class="toc-text">1. Prepare</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Sort"><span class="toc-number">5.2.</span> <span class="toc-text">2. Sort</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Reduce"><span class="toc-number">5.3.</span> <span class="toc-text">3. Reduce</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop-yarn-配置的图解"><span class="toc-number">6.</span> <span class="toc-text">hadoop yarn 配置的图解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AM的内存使用错误"><span class="toc-number">6.1.</span> <span class="toc-text">AM的内存使用错误</span></a></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://s2.ax1x.com/2019/07/11/ZRnN6S.png)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/ITWO/">ITWO</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><span class="pull-right menus"><div class="mobile_author_icon"><img class="lozad" data-src="https://s2.ax1x.com/2019/07/11/ZRK5z6.jpg" onerror="onerror=null;src='/img/friend_404.gif'"><div class="mobile_author-info__description">毋庸多言,只管前行.</div></div><hr><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a><a class="site-page" href="/ITWO/archives/"><i class="fa-fw fa fa-archive"></i><span> 作品总纲</span></a><a class="site-page" href="/ITWO/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签库</span></a><a class="site-page" href="/ITWO/about/"><i class="fa-fw fa fa-heart"></i><span> 关于自己</span></a><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title"><div class="posttitle">mapreduce 温故</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2019-05-29<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> Updated 2018-07-23</time></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h2 id="需求背景："><a href="#需求背景：" class="headerlink" title="需求背景："></a>需求背景：</h2><blockquote>
<p>做大数据有一段时间了，梳理下用到mapreduce的一些问题和解决方案。<a id="more"></a></p>
</blockquote>
<h2 id="mapreduce"><a href="#mapreduce" class="headerlink" title="mapreduce"></a>mapreduce</h2><blockquote>
<p>mapreduce:顾名思义，map做映射，reduce做规约。<br>主要分以下步骤：<br>1.输入分块<br>2.map<br>3.shuffer<br>4.reduce</p>
</blockquote>
<p><img src="/ITWO/assets/mapreduce01.jpg" alt="mapredcue流程图"><br>重点是shuffer阶段</p>
<h2 id="reduce个数的计算方法"><a href="#reduce个数的计算方法" class="headerlink" title="reduce个数的计算方法:"></a>reduce个数的计算方法:</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">double</span> bytes = Math.max(totalInputFileSize, bytesPerReducer);</div><div class="line"><span class="keyword">int</span> reducers = (<span class="keyword">int</span>) Math.ceil(bytes / bytesPerReducer);</div><div class="line">reducers = Math.max(<span class="number">1</span>, reducers);</div><div class="line">reducers = Math.min(maxReducers, reducers);</div></pre></td></tr></table></figure>
<blockquote>
<p>　从计算逻辑可以看出该量由输入文件的大小以及设置的每个reduce可以处理的字节数大小决定．</p>
</blockquote>
<p><img src="/ITWO/assets/mapreduce02.png" alt="shuffer流程图"></p>
<h2 id="流程细节："><a href="#流程细节：" class="headerlink" title="流程细节："></a>流程细节：</h2><h3 id="map输出过程："><a href="#map输出过程：" class="headerlink" title="map输出过程："></a>map输出过程：</h3><blockquote>
<p>&ensp;&ensp;&ensp;&ensp;如果没有reduce阶段，则直接输出到hdfs上，如果有reduce作业，则每个map方法的输出在写磁盘前先在内存中缓存。每个map task都有一个环状的内存缓冲区，存储着map的输出结果，默认100m，在写磁盘时，根据reduce的数量把数据划分为相应的分区(使用默认的分区算法（对输入文件的kv中对key hash后再对reduce task数量取模(reduce个数的算法见前文)),默认的hashPartioner只会作用默认分隔符分割以后的key，如果需要自定义分区，则需要你自定义二次分区比如keyfieldParttioner来实现,在每个分区中数据进行内排序，分区的个数和reduce的个数是一致的，在每次当缓冲区快满的时候由一个独立的线程将缓冲区的数据以一个溢出文件的方式存放到磁盘(这个溢写是由单独线程来完成，不影响往缓冲区写map结果的线程。溢写线程启动时不应该阻止map的结果输出，所以整个缓冲区有个溢写的比例spill.percent。这个比例默认是0.8，也就是当缓冲区的数据已经达到阈值（buffer size <em> spill percent = 100MB </em> 0.8 = 80MB），溢写线程启动，锁定这80MB的内存，执行溢写过程。Map task的输出结果还可以往剩下的20MB内存中写，互不影响。)，当整个map task结束后再对磁盘中这个map task产生的所有溢出文件做合并，被合并成已分区且已排序的输出文件。然后reduce开始fetch（拉取）map端合并好对应分区的数据，然后在reduce端合并（因为会有很多map的输出，需要合并），此时在reduce端也会进行一次sort,确保所有map的输出都排序并合并成完成以后，才会启动reduce task,所以怎么才能确保你在reduce逻辑处理时拿到的是你要的排序后的数据配合你的处理就至关重要了。</p>
</blockquote>
<h3 id="reducer如何知道要从哪个tasktracker取得map输出呢？"><a href="#reducer如何知道要从哪个tasktracker取得map输出呢？" class="headerlink" title="reducer如何知道要从哪个tasktracker取得map输出呢？"></a>reducer如何知道要从哪个tasktracker取得map输出呢？</h3><blockquote>
<p>&ensp;&ensp;&ensp;&ensp;map任务成功完成以后，他们会通知其父tasktracker状态已更新，然后taskTracker进而通知jobTracker。这些通知在前面的心跳机制中传输。因此，对于指定作业，jobTracker知道map输出和taskTracker之间的映射关系。reducer中的一个线程定期询问jobTracher以便获取map输出的位置,直到它获得所有输出位置。</p>
</blockquote>
<h3 id="map和reduce如何合理控制自己的个数？"><a href="#map和reduce如何合理控制自己的个数？" class="headerlink" title="map和reduce如何合理控制自己的个数？"></a>map和reduce如何合理控制自己的个数？</h3><blockquote>
<p>&ensp;&ensp;&ensp;&ensp;map的个数是由dfs.block.size控制，该配置可以在执行程序之前由参数（见下文）控制，默认配置位于hdfs-site.xml中dfs.block.size控制，1.x的默认配置为64m,2.x的默认配置为128m,</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"> <span class="keyword">long</span> goalSize = totalSize / (numSplits == <span class="number">0</span> ? <span class="number">1</span> : numSplits);</div><div class="line"> <span class="keyword">long</span> minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.</div><div class="line">    FileInputFormat.SPLIT_MINSIZE, <span class="number">1</span>), minSplitSize);</div><div class="line"><span class="keyword">long</span> blockSize = file.getBlockSize();</div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">computeSplitSize</span><span class="params">(<span class="keyword">long</span> goalSize, <span class="keyword">long</span> minSize,</span></span></div><div class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> blockSize)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> Math.max(minSize, Math.min(goalSize, blockSize));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p>&ensp;&ensp;&ensp;&ensp;从上面可以看出，最终的split size是由三个因素决定，goalsize为map输入数据除以用户自己设置的map个数（默认为1）得到的;minsize为mapred-site.xml配置的mapred.min.split.size决定，因为minSplitSize为1;第三个影响因素为blocksize,这个看配置，最终我们可以得出,如果不设置min.size,则由blocksize决定，如果设置了，则是由这两者中大的一个决定。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="built_in">set</span> mapred.min.split.size=256000000;        -- 决定每个map处理的最大的文件大小，单位为B</div><div class="line"></div><div class="line">方法1</div><div class="line"><span class="built_in">set</span> mapred.reduce.tasks=10;  -- 设置reduce的数量</div><div class="line">方法2</div><div class="line"><span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=1073741824 -- 每个reduce处理的数据量,默认1GB</div></pre></td></tr></table></figure>
<p>block_size : hdfs的文件块大小，默认为64M，可以通过参数dfs.block.size设置<br>total_size : 输入文件整体的大小<br>input_file_num : 输入文件的个数</p>
<p>（1）默认map个数</p>
<blockquote>
<p>如果不进行任何设置，默认的map个数是和blcok_size相关的。<br>   default_num = total_size / block_size;</p>
</blockquote>
<p>（2）期望大小</p>
<blockquote>
<p>可以通过参数mapred.map.tasks来设置程序员期望的map个数，但是这个个数只有在大于default_num的时候，才会生效。<br>   goal_num = mapred.map.tasks;</p>
</blockquote>
<p>（3）设置处理的文件大小</p>
<blockquote>
<p>可以通过mapred.min.split.size 设置每个task处理的文件大小，但是这个大小只有在大于block_size的时候才会生效。<br>   split_size = max(mapred.min.split.size, block_size);<br>   split_num = total_size / split_size;</p>
</blockquote>
<p>（4）计算的map个数</p>
<blockquote>
<p>compute_map_num = min(split_num,  max(default_num, goal_num))</p>
<p>&ensp;&ensp;&ensp;&ensp;除了这些配置以外，mapreduce还要遵循一些原则。 mapreduce的每一个map处理的数据是不能跨越文件的，也就是说min_map_num &gt;= input_file_num。 所以，最终的map个数应该为：</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">final_map_num = max(compute_map_num, input_file_num)</div></pre></td></tr></table></figure>
<blockquote>
<p>经过以上的分析，在设置map个数的时候，可以简单的总结为以下几点：<br>（1）如果想增加map个数，则设置mapred.max.split.size为一个较小的值。<br>（2）如果想减小map个数，则设置mapred.min.split.size 为一个较大的值。</p>
</blockquote>
<p>reduce个数的设置则相对简单，要么你设置mapred.reduce.tasks的数值，要么你在hive中可以设置每个reduce可以处理的字节数，从而约束reduce的个数。</p>
<blockquote>
<p>小技巧</p>
</blockquote>
<p>&ensp;&ensp;&ensp;&ensp;在hive中带空的设置参数可以打印出当前该参数的设置值。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hive&gt; set dfs.block.size;</div><div class="line">dfs.block.size=268435456</div><div class="line">hive&gt; set mapred.map.tasks;</div><div class="line">mapred.map.tasks=2</div></pre></td></tr></table></figure>
<h2 id="mapreduce进度说明"><a href="#mapreduce进度说明" class="headerlink" title="mapreduce进度说明"></a>mapreduce进度说明</h2><h3 id="1-Prepare"><a href="#1-Prepare" class="headerlink" title="1. Prepare"></a>1. Prepare</h3><blockquote>
<p>准备数据，抓取Map过来的输出（进度：0~33%）</p>
</blockquote>
<h3 id="2-Sort"><a href="#2-Sort" class="headerlink" title="2. Sort"></a>2. Sort</h3><blockquote>
<p>排序阶段（进度：33%~66%）</p>
</blockquote>
<h3 id="3-Reduce"><a href="#3-Reduce" class="headerlink" title="3. Reduce"></a>3. Reduce</h3><blockquote>
<p>真正的reduce计算阶段，执行你所写的reduce代码（进度：66%~100%）.<br>如果前面66%速度很快，后面慢的话就是reduce部分没有写好；否则才是数据量大的问题。</p>
</blockquote>
<h2 id="hadoop-yarn-配置的图解"><a href="#hadoop-yarn-配置的图解" class="headerlink" title="hadoop yarn 配置的图解"></a>hadoop yarn 配置的图解</h2><p><img src="/ITWO/assets/hadoop 2.0 yarn 配置项.png" alt="hadoop yarn 配置的图解"></p>
<h3 id="AM的内存使用错误"><a href="#AM的内存使用错误" class="headerlink" title="AM的内存使用错误"></a>AM的内存使用错误</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Diagnostics: Container [pid=<span class="number">21387</span>,containerID=container_e33_1532170420957_0001_02_000001] is running beyond physical memory limits. </div><div class="line">Current usage: <span class="number">1.1</span> GB of <span class="number">1</span> GB physical memory used; <span class="number">2.7</span> GB of <span class="number">2.1</span> GB virtual memory used. Killing container.</div><div class="line">Dump of the process-tree <span class="keyword">for</span> container_e33_1532170420957_0001_02_000001 :</div><div class="line">        |- <span class="function">PID PPID PGRPID SESSID CMD_NAME <span class="title">USER_MODE_TIME</span><span class="params">(MILLIS)</span> <span class="title">SYSTEM_TIME</span><span class="params">(MILLIS)</span> <span class="title">VMEM_USAGE</span><span class="params">(BYTES)</span> <span class="title">RSSMEM_USAGE</span><span class="params">(PAGES)</span> FULL_CMD_LINE</span></div><div class="line"><span class="function">        |- 21399 21387 21387 21387 <span class="params">(java)</span> 14478 467 2856710144 281207 /usr/lib/jvm/java-8-oracle/bin/java </span></div><div class="line"><span class="function">		-Dlog4j.configuration</span>=container-log4j.properties </div><div class="line">		-Dyarn.app.container.log.dir=/data/dev/sdb1/yarn/container-logs/application_1532170420957_0001/container_e33_1532170420957_0001_02_000001 </div><div class="line">		-Dyarn.app.container.log.filesize=<span class="number">0</span> -Dhadoop.root.logger=INFO,CLA </div><div class="line">		-Dhadoop.root.logfile=syslog </div><div class="line">		-Djava.net.preferIPv4Stack=<span class="keyword">true</span> -Xmx825955249 org.apache.hadoop.mapreduce.v2.app.MRAppMaster</div></pre></td></tr></table></figure>
<blockquote>
<p>仔细预览以上的错误可以定位到以下的信息</p>
</blockquote>
<ol>
<li>AppMaster报出的错误</li>
<li>-Xmx825955249 设置了运行的参数值</li>
</ol>
<blockquote>
<p>结合图示我们找下应该去集群找那些配置来定位问题</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">上限参数:yarn.app.mapreduce.am.resource.mb</div><div class="line">运行参数:yarn.app.mapreduce.am.command-opts</div></pre></td></tr></table></figure>
<blockquote>
<p>以上的这两参数肯定少不了，后来从集群中的确也定位到的确是是yarn.app.mapreduce.am.resource.mb该参数差的设定过小为1G，同时yarn.app.mapreduce.am.command-opts为报错中的展示信息，需要更改，因为这两项更改的都是yarn-site.xml中的配置，cdh中改完之后保存分发这些信息，然后重启集群。</p>
</blockquote>
<table>
<thead>
<tr>
<th>配置文件</th>
<th>配置项</th>
<th>设置值</th>
</tr>
</thead>
<tbody>
<tr>
<td>yarn-site.xml</td>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>Container数量 * 每个Container的内存大小</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>每个Container的内存大小</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>Container数量 * 每个Container的内存大小</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.map.memory.mb</td>
<td>每个Container的内存大小</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.reduce.memory.mb</td>
<td>2 * 每个Container的内存大小</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.map.java.opts</td>
<td>0.8 * 每个Container的内存大小</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.reduce.java.opts</td>
<td>0.8 <em> 2 </em> 每个Container的内存大小</td>
</tr>
<tr>
<td>yarn-site.xml (check)</td>
<td>yarn.app.mapreduce.am.resource.mb</td>
<td>2 * 每个Container的内存大小</td>
</tr>
<tr>
<td>yarn-site.xml (check)</td>
<td>yarn.app.mapreduce.am.command-opts</td>
<td>0.8 <em> 2 </em> 每个Container的内存大小</td>
</tr>
</tbody>
</table>
<blockquote>
<p>以上为各配置的位置以及建议的设置值。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">例如：</div><div class="line">集群的节点有 12 CPU cores, 48 GB RAM, and 12 磁盘.</div><div class="line">预留内存= 6 GB 系统预留 + 8 GB HBase预留</div><div class="line">最小Container内存大小 = 2 GB</div><div class="line"></div><div class="line">如果不安装 HBase:</div><div class="line"><span class="meta">#</span><span class="bash">Container数 = min (2*12, 1.8* 12, (48-6)/2) = min (24, 21.6, 21) = 21</span></div><div class="line">每个Container的内存大小 = max (2, (48-6)/21) = max (2, 2) = 2</div><div class="line"></div><div class="line">如果安装 Hbase：</div><div class="line"><span class="meta">#</span><span class="bash">Container数 = min (2*12, 1.8* 12, (48-6-8)/2) = min (24, 21.6, 17) = 17</span></div><div class="line">每个Container的内存大小 = max (2, (48-6-8)/17) = max (2, 2) = 2</div></pre></td></tr></table></figure>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">唐钰逍遥</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://www.tangyuxiaoyao.club/ITWO/2019/05/29/mapredcue 温习/">http://www.tangyuxiaoyao.club/ITWO/2019/05/29/mapredcue 温习/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/ITWO/tags/mapreduce/">mapreduce    </a><a class="post-meta__tags" href="/ITWO/tags/shuffer/">shuffer    </a></div><div class="post_share"><div class="social-share" data-image="https://s2.ax1x.com/2019/07/11/ZRK5z6.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-buttom"><i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lozad post-qr-code__img" data-src="https://s2.ax1x.com/2019/07/11/ZRQPc6.png"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lozad post-qr-code__img" data-src="https://s2.ax1x.com/2019/07/11/ZRQC1x.png"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/ITWO/2019/05/29/ Hadoop HDFS 数据自动平衡/"><img class="prev_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>Hadoop HDFS 数据自动平衡</span></div></a></div><div class="next-post pull-right"><a href="/ITWO/2019/05/29/线上mongo查询过慢排查总结/"><img class="next_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>线上mongo查询过慢排查总结</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2017/11/22/hadoop-mapredcue和streaming-hive-三种思路实现not-in-join/" title="hadoop mapredcue和streaming hive 三种思路实现not in join"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif"><div class="relatedPosts_title">hadoop mapredcue和streaming hive 三种思路实现not in join</div></a></div><div class="relatedPosts_item"><a href="/2018/09/13/java-mr-lzo-支持/" title="java mr lzo 支持"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif"><div class="relatedPosts_title">java mr lzo 支持</div></a></div><div class="relatedPosts_item"><a href="/2018/04/27/mapreduce-结果集中在多个reduce输出中的一个/" title="mapreduce 结果集中在多个reduce输出part中的一个"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif"><div class="relatedPosts_title">mapreduce 结果集中在多个reduce输出part中的一个</div></a></div><div class="relatedPosts_item"><a href="/2017/12/22/yarn-详解/" title="yarn 详解"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif"><div class="relatedPosts_title">yarn 详解</div></a></div><div class="relatedPosts_item"><a href="/2018/07/18/使用hive-mapreduce给大数据全局排序，同时巧用该方法实现hbase的预分区/" title="使用hive/mapreduce给大数据全局排序，同时巧用该方法实现hbase的预分区"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif"><div class="relatedPosts_title">使用hive/mapreduce给大数据全局排序，同时巧用该方法实现hbase的预分区</div></a></div><div class="relatedPosts_item"><a href="/2018/04/11/如何在hadoop-streaming-mapreduce中-使用python第三方包/" title="如何在hadoop streaming mapreduce中 使用python第三方包"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/07/11/ZR1SQx.gif"><div class="relatedPosts_title">如何在hadoop streaming mapreduce中 使用python第三方包</div></a></div></div><div class="clear_both"></div></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2019 By 唐钰逍遥</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="http://www.tangyuxiaoyao.club/">ITWO</a>!</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><i class="fa fa-book" id="readmode" title="Read Mode"> </i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion">簡</a><i class="fa fa-moon-o nightshift" id="nightshift" title="Dark Mode"></i></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script src="/ITWO/js/utils.js"></script><script src="/ITWO/js/main.js"></script><script async src="/ITWO/js/search/local-search.js"></script><script src="/ITWO/js/nightshift.js"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/js/piao.js"></script><script src="/ITWO/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>