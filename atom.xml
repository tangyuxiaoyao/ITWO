<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ITWO</title>
  
  <subtitle>毋庸多言,只管前行.</subtitle>
  <link href="/ITWO/atom.xml" rel="self"/>
  
  <link href="https://www.tangyuxiaoyao.club/ITWO/"/>
  <updated>2019-01-03T12:49:43.468Z</updated>
  <id>https://www.tangyuxiaoyao.club/ITWO/</id>
  
  <author>
    <name>唐钰逍遥</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据特殊join</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2019/01/03/%E6%95%B0%E6%8D%AE%E7%89%B9%E6%AE%8Ajoin/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2019/01/03/数据特殊join/</id>
    <published>2019-01-03T12:05:06.000Z</published>
    <updated>2019-01-03T12:49:43.468Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>有两份计费数据一份是测试账号的，一份是正式账号，现计费策略如下：</p></blockquote><ul><li>测试账号调用过的key如果在正式账号调用记录中出现:<ol><li>测试账号调用该key的次数大于等于正式账号，则计费次数为测试出现的次数减去正式账号出现该key的次数。</li><li>测试账号调用该key的次数如果小于正式账号，则计费次数为正式账号调用的次数。</li></ol></li><li>测试账号和正式账号的没有重复的则分别计费即可。</li></ul><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ul><li>相同部分不好计费，需要特殊计费通过Python来实现。</li><li>不同部分通过awk追加到一个文件中，然后使用sort|uniq -c 来统计词频即可。（此处不能使用comm，使用该命令一定要先排序去重，那计费数据不就丢了？）</li></ul><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">step1:compute the key cnt with tag</div><div class="line"></div><div class="line">sort Tcard &gt; s_tcard</div><div class="line">sort Fcard &gt; s_fcard</div><div class="line"></div><div class="line">cat s_tcard|uniq -c |awk -F' ' '&#123;print $2"\tT_"$1&#125;' &gt;tag_tcard</div><div class="line">cat s_fcard|uniq -c |awk -F' ' '&#123;print $2"\tF_"$1&#125;' &gt;tag_Fcard</div><div class="line"></div><div class="line"></div><div class="line">step2: handle the common part</div><div class="line"></div><div class="line">sort tag* |python handleCnt.py &gt;common.tsv</div><div class="line"></div><div class="line"></div><div class="line">step3:handle the diff part</div><div class="line"></div><div class="line"></div><div class="line">awk  'NR==FNR&#123;a[$0]&#125;NR&gt;FNR&#123; if(!($1 in a)) print $0&#125;' s_tcard s_fcard &gt;diff_temp</div><div class="line">awk  'NR==FNR&#123;a[$0]&#125;NR&gt;FNR&#123; if(!($1 in a)) print $0&#125;' s_fcard s_tcard &gt;&gt; diff_temp</div><div class="line"></div><div class="line"></div><div class="line">sort diff_temp |uniq -c |awk -F' ' '&#123;print $2"\t"$1&#125;' &gt;diff.tsv</div><div class="line"></div><div class="line"></div><div class="line">step4:cat comm and diff to final.tsv</div><div class="line"></div><div class="line">cat common.tsv diff.tsv &gt;final.tsv</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># vim: set fileencoding=utf-8</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator = <span class="string">'\t'</span>)</span>:</span></div><div class="line">    initDict = &#123;&#125;</div><div class="line">    card = <span class="keyword">None</span></div><div class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> sys.stdin:</div><div class="line">        detail = data.strip().split(separator)</div><div class="line">        <span class="keyword">if</span>(detail[<span class="number">1</span>].startswith(<span class="string">"F"</span>)):</div><div class="line">            card = detail[<span class="number">0</span>]</div><div class="line">            cnt = detail[<span class="number">1</span>].split(<span class="string">"_"</span>)[<span class="number">1</span>]</div><div class="line">            initDict[card] = cnt</div><div class="line">        <span class="keyword">elif</span>(detail[<span class="number">0</span>] <span class="keyword">in</span>  initDict.keys() <span class="keyword">and</span> detail[<span class="number">1</span>].startswith(<span class="string">"T_"</span>)):</div><div class="line">            cnt =  detail[<span class="number">1</span>].split(<span class="string">"_"</span>,<span class="number">1</span>)[<span class="number">1</span>]</div><div class="line">            <span class="keyword">if</span>(initDict[card]&gt;=cnt):</div><div class="line">                <span class="keyword">print</span> card+separator+initDict[card]</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="keyword">print</span> card+separator+str(int(cnt)-int(initDict[card]))</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;需求背景&quot;&gt;&lt;a href=&quot;#需求背景&quot; class=&quot;headerlink&quot; title=&quot;需求背景&quot;&gt;&lt;/a&gt;需求背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;有两份计费数据一份是测试账号的，一份是正式账号，现计费策略如下：&lt;/p&gt;
&lt;/blockquote
      
    
    </summary>
    
    
      <category term="shell" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/shell/"/>
    
      <category term="python" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/python/"/>
    
      <category term="comm" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/comm/"/>
    
  </entry>
  
  <entry>
    <title>python中-1的妙用</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/11/12/python%E4%B8%AD-1%E7%9A%84%E5%A6%99%E7%94%A8/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/11/12/python中-1的妙用/</id>
    <published>2018-11-12T02:19:55.000Z</published>
    <updated>2018-11-12T07:39:51.591Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>在浏览HadoopStreaming官网时，有看到如下的用法也可以实现截取一行的数据。</p></blockquote><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateLongCountToken</span><span class="params">(id)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="string">"LongValueSum:"</span> + id + <span class="string">"\t"</span> + <span class="string">"1"</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv)</span>:</span></div><div class="line">    line = sys.stdin.readline();</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        <span class="keyword">while</span> line:</div><div class="line">            line = line[:<span class="number">-1</span>];</div><div class="line">            fields = line.split(<span class="string">"\t"</span>);</div><div class="line">            <span class="keyword">print</span> generateLongCountToken(fields[<span class="number">0</span>]);</div><div class="line">            line = sys.stdin.readline();</div><div class="line">    <span class="keyword">except</span> <span class="string">"end of file"</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">     main(sys.argv)</div></pre></td></tr></table></figure><h2 id="调研过程"><a href="#调研过程" class="headerlink" title="调研过程"></a>调研过程</h2><blockquote><p>很好奇这样的用法作用与字符串会有什么效果，就有了如下的调研。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line"><span class="keyword">print</span> line</div><div class="line"><span class="keyword">print</span> line[:<span class="number">-1</span>]</div><div class="line"><span class="keyword">print</span> line.strip()</div><div class="line"></div><div class="line">a = <span class="string">'   '</span></div><div class="line"><span class="keyword">print</span> len(a)</div><div class="line"><span class="keyword">print</span> len(a[:<span class="number">-1</span>])</div><div class="line"><span class="keyword">print</span> len(a.strip())</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">main()</div></pre></td></tr></table></figure><ul><li>输出如下：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1,2,3,4</div><div class="line"></div><div class="line">1,2,3,4</div><div class="line">1,2,3,4</div><div class="line">3</div><div class="line">2</div><div class="line">0</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote><p>从上可以得出如下的结论：</p></blockquote><ol><li>-1可以去除数据行后面的换行符或者最后的空格或者tab等单个字符</li><li>但是不可以去除多个空格或者多个无用字符</li><li>此类的场景还是推荐使用strip()来保证万无一失,当然在获得完整的一行的数据的场景,该用法完全够用。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用背景&quot;&gt;&lt;a href=&quot;#使用背景&quot; class=&quot;headerlink&quot; title=&quot;使用背景&quot;&gt;&lt;/a&gt;使用背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在浏览HadoopStreaming官网时，有看到如下的用法也可以实现截取一行的数据。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="python" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/python/"/>
    
      <category term="strip" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/strip/"/>
    
  </entry>
  
  <entry>
    <title>linux 下怎么使用命令制作U盘启动盘</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/10/24/linux-%E4%B8%8B%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E5%88%B6%E4%BD%9CU%E7%9B%98%E5%90%AF%E5%8A%A8%E7%9B%98/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/10/24/linux-下怎么使用命令制作U盘启动盘/</id>
    <published>2018-10-24T05:27:07.000Z</published>
    <updated>2018-10-25T01:41:31.855Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>ubantu自带的工具没有响应,后来查到可以使用命令的方式来格式化u盘和制作装机盘.</p></blockquote><a id="more"></a><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">unmout the mount pan</span></div><div class="line">sudo umount /dev/sdb</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">format u pan</span></div><div class="line">sudo mkfs.vfat /dev/sdb –I</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">make u pan to a pan <span class="built_in">which</span> can play as a bootpan</span></div><div class="line">sudo dd if=~/iso/deepin-15.7-amd64.iso of=/dev/sdb</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用背景&quot;&gt;&lt;a href=&quot;#使用背景&quot; class=&quot;headerlink&quot; title=&quot;使用背景&quot;&gt;&lt;/a&gt;使用背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;ubantu自带的工具没有响应,后来查到可以使用命令的方式来格式化u盘和制作装机盘.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ssh 免密码登录以及多种用途共存</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/10/12/ssh-%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E4%BB%A5%E5%8F%8A%E5%A4%9A%E7%A7%8D%E7%94%A8%E9%80%94%E5%85%B1%E5%AD%98/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/10/12/ssh-免密码登录以及多种用途共存/</id>
    <published>2018-10-12T08:51:58.000Z</published>
    <updated>2018-10-12T09:44:12.658Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>在日常使用ssh时,我们有以下几种使用场景</p></blockquote><ol><li>ssh 远程登录远端的机器</li><li>scp 与其他的主机 上传或者下载数据</li><li>ssh 生成邮箱的公钥用于免密拉取git的项目</li></ol><a id="more"></a><h2 id="实现和原理分析"><a href="#实现和原理分析" class="headerlink" title="实现和原理分析"></a>实现和原理分析</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">（1）在HOSTA机器上产生公钥和私钥</div><div class="line">   ssh-keygen -t rsa</div><div class="line">   </div><div class="line">（2）需要将HOSTA机器的公钥复制给HOSTB机器</div><div class="line">  ssh-copy-id -i .ssh/id_rsa.pub root@HOSTB</div></pre></td></tr></table></figure><ul><li>图解</li></ul><p><img src="/ITWO/assets/ssh-rsa.png" alt="详细交互过程"></p><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>既然ssh生成的公钥可以用来这么多用途,那么怎样让用于免密码登录/拷贝的公钥和用来拉取git项目的公钥共存呢?</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> man ssh-add</span></div><div class="line">NAME</div><div class="line">     ssh-add — adds private key identities to the authentication agent</div><div class="line">     ssh-add adds private key identities to the authentication agent, ssh-agent(1).  When run</div><div class="line">     without arguments, it adds the files ~/.ssh/id_rsa, ~/.ssh/id_dsa, ~/.ssh/id_ecdsa,</div><div class="line">     ~/.ssh/id_ed25519 and ~/.ssh/identity.  After loading a private key, ssh-add will try to load</div><div class="line">     corresponding certificate information from the filename obtained by appending -cert.pub to</div><div class="line">     the name of the private key file.  Alternative file names can be given on the command line.</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 从以上的解释可以看出通过该命令可以解决此问题</span></div><div class="line">ssh-add ~/.ssh/*_rsa</div></pre></td></tr></table></figure><ul><li>ssh-add操作<br><img src="/ITWO/assets/ssh-add.png" alt="ssh-add 操作过程"></li></ul><ul><li>过程测试<br><img src="/ITWO/assets/ssh-git.png" alt="ssh-add 操作过程"></li></ul><blockquote><p>ps: 用作一种用途时,生成id_rsa和id_rsa.pub之后记得重命名,然后使用ssh-add添加该密钥.</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用背景&quot;&gt;&lt;a href=&quot;#使用背景&quot; class=&quot;headerlink&quot; title=&quot;使用背景&quot;&gt;&lt;/a&gt;使用背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在日常使用ssh时,我们有以下几种使用场景&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;ssh 远程登录远端的机器&lt;/li&gt;
&lt;li&gt;scp 与其他的主机 上传或者下载数据&lt;/li&gt;
&lt;li&gt;ssh 生成邮箱的公钥用于免密拉取git的项目&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="git" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/git/"/>
    
      <category term="scp" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/scp/"/>
    
      <category term="ssh" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/ssh/"/>
    
  </entry>
  
  <entry>
    <title>ubantu unzip或手动解压文件乱码</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/10/08/ubantu-unzip%E6%88%96%E6%89%8B%E5%8A%A8%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/10/08/ubantu-unzip或手动解压文件乱码/</id>
    <published>2018-10-08T03:19:02.000Z</published>
    <updated>2018-10-12T08:37:53.856Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>从云盘下载的zip包中包含中文,解压出来的文件夹和文件均是乱码.<br><img src="/ITWO/assets/unziperror.png" alt="中文乱码"></p></blockquote><a id="more"></a><hr><h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p><img src="/ITWO/assets/ziphelp.png" alt="查看unzip的帮助命令"></p><blockquote><p>得到 -O 可以使用 windows或者dos的编码格式去解压文件.</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">unzip -O GBK 笔记.zip</div></pre></td></tr></table></figure><p><img src="/ITWO/assets/unzipsuccess.png" alt="解压的时候已经没有乱码了"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用背景&quot;&gt;&lt;a href=&quot;#使用背景&quot; class=&quot;headerlink&quot; title=&quot;使用背景&quot;&gt;&lt;/a&gt;使用背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;从云盘下载的zip包中包含中文,解压出来的文件夹和文件均是乱码.&lt;br&gt;&lt;img src=&quot;/ITWO/assets/unziperror.png&quot; alt=&quot;中文乱码&quot;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="ubantu" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/ubantu/"/>
    
      <category term="unzip" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/unzip/"/>
    
      <category term="乱码" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/%E4%B9%B1%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>java mr lzo 支持</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/09/13/java-mr-lzo-%E6%94%AF%E6%8C%81/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/09/13/java-mr-lzo-支持/</id>
    <published>2018-09-13T03:08:56.000Z</published>
    <updated>2018-09-13T03:15:08.397Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>lzo格式有很大的压缩比,相对于Hdfs文件而言有很大优势,支持分片,默认是不支持splitable的，需要为其添加索引文件，才能支持多个map并行对lzo文件进行处理.先阶段来说为了节约存储空间,lzo格式的文件存储随处可见,所以在mapreduce中怎么读取和存储lzo文件就很有必要了解下.</p></blockquote><a id="more"></a><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>如果希望mr输出的是lzo格式的文件，添加下面的语句</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">FileOutputFormat.setCompressOutput(job, <span class="keyword">true</span>);</div><div class="line">FileOutputFormat.setOutputCompressorClass(job, LzopCodec.class);</div><div class="line"><span class="keyword">int</span> result = job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</div><div class="line"><span class="comment">//上面的语句执行完成后，会生成最后的输出文件，需要在此基础上添加lzo的索引</span></div><div class="line">LzoIndexer lzoIndexer = <span class="keyword">new</span> LzoIndexer(conf);</div><div class="line">lzoIndexer.index(<span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div></pre></td></tr></table></figure><blockquote><p>如果已经存在lzo文件，但没有添加索引，可以采用下面的方法，在输入路径的文件上上添加lzo索引<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop jar $HADOOP_HOME/lib/hadoop-lzo-0.4.17.jar com.hadoop.compression.lzo.LzoIndexer hdf://inputpath</div></pre></td></tr></table></figure></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景描述&quot;&gt;&lt;a href=&quot;#背景描述&quot; class=&quot;headerlink&quot; title=&quot;背景描述&quot;&gt;&lt;/a&gt;背景描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;lzo格式有很大的压缩比,相对于Hdfs文件而言有很大优势,支持分片,默认是不支持splitable的，需要为其添加索引文件，才能支持多个map并行对lzo文件进行处理.先阶段来说为了节约存储空间,lzo格式的文件存储随处可见,所以在mapreduce中怎么读取和存储lzo文件就很有必要了解下.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="mapreduce" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/mapreduce/"/>
    
      <category term="java" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/java/"/>
    
      <category term="lzo" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/lzo/"/>
    
  </entry>
  
  <entry>
    <title>scala 使用遇到的问题</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/09/13/scala-match-%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/09/13/scala-match-使用遇到的问题/</id>
    <published>2018-09-13T02:45:29.000Z</published>
    <updated>2018-09-26T01:55:18.566Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>在使用spark来跑统计报告任务是,有使用scala,会遇到如下的问题.</p></blockquote><a id="more"></a><p>+用多个开关去控制不同的使用逻辑</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> dimensionCode = args(<span class="number">2</span>).toInt</div><div class="line">dimensionCode <span class="keyword">match</span> &#123;</div><div class="line"> <span class="keyword">case</span> <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getCode =&gt; &#123;</div><div class="line">   println(<span class="string">"正在生成报告的维度为"</span>, <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getDimensions)</div><div class="line">   <span class="comment">//  D0(0, "行业大类,行业小类")</span></div><div class="line"> &#125;</div></pre></td></tr></table></figure><ul><li>报错</li></ul><blockquote><p> 如上的用法会出现以下的错误：</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="type">Error</span>:(<span class="number">38</span>, <span class="number">33</span>) stable identifier required, but <span class="type">D0</span>.getCode found.</div><div class="line">    <span class="keyword">case</span> <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getCode =&gt; &#123;</div></pre></td></tr></table></figure><blockquote><p>必须要使用常量</p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><blockquote><p> 改动成如下的表达式就可以通过：</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">dimensionCode.toString.toInt <span class="keyword">match</span> &#123;</div><div class="line">  <span class="keyword">case</span> dimensionCode <span class="keyword">if</span> <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getCode == dimensionCode =&gt; &#123;</div><div class="line">    println(<span class="string">"正在生成报告的维度为:"</span>, <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getDimensions)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用背景&quot;&gt;&lt;a href=&quot;#使用背景&quot; class=&quot;headerlink&quot; title=&quot;使用背景&quot;&gt;&lt;/a&gt;使用背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在使用spark来跑统计报告任务是,有使用scala,会遇到如下的问题.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="scala" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/scala/"/>
    
      <category term="match" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/match/"/>
    
  </entry>
  
  <entry>
    <title>java/scala 怎么给可变参数传值</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/09/07/java-scala-%E6%80%8E%E4%B9%88%E7%BB%99%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0%E4%BC%A0%E5%80%BC/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/09/07/java-scala-怎么给可变参数传值/</id>
    <published>2018-09-07T10:06:55.000Z</published>
    <updated>2018-09-07T10:12:36.626Z</updated>
    
    <content type="html"><![CDATA[<h2 id="业务背景"><a href="#业务背景" class="headerlink" title="业务背景"></a>业务背景</h2><blockquote><p>java和scala 分别怎么给可变参数传值?</p></blockquote><a id="more"></a><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><ul><li>java</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">String[] args = <span class="string">"1,2,3"</span>.split(<span class="string">","</span>, -<span class="number">1</span>)</div><div class="line">testString(args);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testString</span><span class="params">(String... args)</span> </span>&#123;</div><div class="line">      <span class="keyword">for</span> (String arg : args) &#123;</div><div class="line">          System.out.println(arg);</div><div class="line">      &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure><ul><li>scala</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> test = <span class="string">"1,2,3,4"</span>.split(<span class="string">","</span>)</div><div class="line"></div><div class="line">  testArgs(test: _*)</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testArgs</span></span>(paths: <span class="type">String</span>*) = &#123;</div><div class="line">  paths.foreach(println(_))</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;业务背景&quot;&gt;&lt;a href=&quot;#业务背景&quot; class=&quot;headerlink&quot; title=&quot;业务背景&quot;&gt;&lt;/a&gt;业务背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;java和scala 分别怎么给可变参数传值?&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/java/"/>
    
      <category term="scala" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/scala/"/>
    
      <category term="string*" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/string/"/>
    
      <category term="string..." scheme="https://www.tangyuxiaoyao.club/ITWO/tags/string/"/>
    
  </entry>
  
  <entry>
    <title>使用elasticSearch 实现商户名称的模糊匹配</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/09/07/%E4%BD%BF%E7%94%A8elasticSearch-%E5%AE%9E%E7%8E%B0%E5%95%86%E6%88%B7%E5%90%8D%E7%A7%B0%E7%9A%84%E6%A8%A1%E7%B3%8A%E5%8C%B9%E9%85%8D/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/09/07/使用elasticSearch-实现商户名称的模糊匹配/</id>
    <published>2018-09-07T07:33:04.000Z</published>
    <updated>2018-12-26T02:36:03.536Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>总公司那边不允许输出流水中的刷卡地址,所以应对的方案是允许客户输入商户的关键字然后模糊匹配刷卡地址中是否存在</p></blockquote><a id="more"></a><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><blockquote><p>先从数据量着手选择技术,mysql 通过like来匹配肯定不能满足如此大的数据量,存量数据量来看已经有六千万之多,所以mysql技术不行,而且mysql仅仅是解决了包含的匹配关系,对于关键词和查询词组的相关度支持有限,另一方面考虑到数据的复用行,另一项目中数据已经存于es中.</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>开始之初,选择的是已经做好IK 分词的刷卡地址,但是无论使用wildcardQuery还是fuzzyQuery亦或prefixQuery热词还好,但是出现了冷门词语(是否包含与既定的分词包中),就会出现某个汉字多排名就考前的弊病,而且默认返回十条,这样就限制了包含模糊查询的二次匹配,次路不通.<br>后来鉴于上文提及的已做好分词命中不固定的原因,选择增加一个字段数据导入的时候不做分词(keyword)</p></blockquote><ul><li>知识点<blockquote><p>5.x以上已经没有string类型。如果需要分词的话使用text，不需要分词使用keyword。但是生成索引的时候你会看到后面还有一个关键词:index,默认为true,如果设置为false,该字段将不能被索引,keyword是整个文档被索引,text根据指定的分词器被索引(不指定的话默认的分词器是standard),<br>keyword,index:true=&gt;doc被每个term切词并与doc建立索引，可以用于模糊匹配， keyword,index:fals则doc不被切词，所以你要做的就是要么使用keyword,index:true的字段模糊匹配或者使用text类型的字段的全文检索匹配过滤，然后这些不被切词（查询项（二次查找（schame）））和被切词的字段作为查询项返回.<br>使用了keyword和index:false,该字段只能是作为查询项来返回,用法如下:</p></blockquote></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">MatchQueryBuilder termQueryBuilder = QueryBuilders.</div><div class="line">matchQuery(<span class="string">"content"</span>, <span class="string">"中国渔船"</span>).analyzer(<span class="string">"ik_max_word"</span>);</div><div class="line">String indexes = <span class="string">"CP5178,CP5177,CP5176"</span>;</div><div class="line">String[] includesIndexes = indexes.split(<span class="string">","</span>);</div><div class="line">String[] excludesIndexes = <span class="keyword">new</span> String[]&#123;&#125;;</div><div class="line">SearchResponse searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(termQueryBuilder)</div><div class="line">.setFetchSource(includesIndexes, excludesIndexes).execute().actionGet();</div></pre></td></tr></table></figure><blockquote><p>综上所述我们需要得到的最终技术实现</p></blockquote><ol><li>使用keyword,index:true配合wildcardQuery实现模糊匹配的查找(like “%key%”)</li><li>使用text字段配合分词器实现长关键词的二次匹配,搜索的关键词越长,关联度越高.</li></ol><ul><li>上代码</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">String mid = <span class="string">"A4816456E30D07B17C23B8D16FC26CCEC0E7EBE10A7554732A25753EBE533569"</span>;</div><div class="line"> String searchKey = <span class="string">"南通新时代电器科技有限公司"</span>;</div><div class="line"></div><div class="line"> MatchQueryBuilder merId = QueryBuilders.matchQuery(<span class="string">"mid"</span>, mid);</div><div class="line"></div><div class="line"></div><div class="line"> BoolQueryBuilder midMust = QueryBuilders.boolQuery().must(merId);</div><div class="line"></div><div class="line"></div><div class="line"> SearchResponse searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(midMust).execute().actionGet();</div><div class="line"></div><div class="line"> SearchHit[] hits = searchResponse.getHits().getHits();</div><div class="line"> String msg = <span class="string">"未找到"</span>;</div><div class="line"></div><div class="line"> <span class="keyword">if</span> (<span class="number">0</span> &lt; hits.length) &#123;</div><div class="line">     WildcardQueryBuilder mchntName = QueryBuilders.wildcardQuery(<span class="string">"name"</span>, <span class="string">"*"</span> + searchKey + <span class="string">"*"</span>);</div><div class="line">     QueryBuilders.prefixQuery()</div><div class="line">     BoolQueryBuilder mchntNameMust = QueryBuilders.boolQuery().must(merId).must(mchntName);</div><div class="line">     searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(mchntNameMust).execute().actionGet();</div><div class="line">     hits = searchResponse.getHits().getHits();</div><div class="line">     <span class="keyword">if</span> (<span class="number">0</span> &lt; hits.length) &#123;</div><div class="line">         <span class="keyword">for</span> (SearchHit searchHit : hits) &#123;</div><div class="line">             System.out.println(searchHit.getSourceAsMap().get(<span class="string">"name"</span>));</div><div class="line">         &#125;</div><div class="line">         msg = <span class="string">"匹配成功"</span>;</div><div class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">4</span> &lt; searchKey.length()) &#123;</div><div class="line">         MatchQueryBuilder nameQuery = QueryBuilders.</div><div class="line">                 matchQuery(<span class="string">"name_term"</span>, searchKey).analyzer(<span class="string">"ik_max_word"</span>);</div><div class="line">         BoolQueryBuilder nameMust = QueryBuilders.boolQuery().must(merId).must(nameQuery);</div><div class="line">         searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(nameMust).execute().actionGet();</div><div class="line">         hits = searchResponse.getHits().getHits();</div><div class="line">         <span class="keyword">if</span> (<span class="number">0</span> &lt; hits.length) &#123;</div><div class="line">             <span class="keyword">for</span> (SearchHit searchHit : hits) &#123;</div><div class="line">                 System.out.println(searchHit.getSourceAsMap().get(<span class="string">"name_term"</span>));</div><div class="line">             &#125;</div><div class="line">             msg = <span class="string">"匹配成功"</span>;</div><div class="line">         &#125;</div><div class="line"></div><div class="line">     &#125;</div><div class="line"> &#125; <span class="keyword">else</span> &#123;</div><div class="line">     System.out.println(<span class="string">"未匹配到商户名"</span>);</div><div class="line"> &#125;</div><div class="line"></div><div class="line"> System.out.println(msg);</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求背景&quot;&gt;&lt;a href=&quot;#需求背景&quot; class=&quot;headerlink&quot; title=&quot;需求背景&quot;&gt;&lt;/a&gt;需求背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;总公司那边不允许输出流水中的刷卡地址,所以应对的方案是允许客户输入商户的关键字然后模糊匹配刷卡地址中是否存在&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="es" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/es/"/>
    
      <category term="elasticSearch" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/elasticSearch/"/>
    
      <category term="term" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/term/"/>
    
      <category term="ik" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/ik/"/>
    
  </entry>
  
  <entry>
    <title>java 调用spark-submit填坑</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/08/24/java-%E8%B0%83%E7%94%A8spark-submit%E5%A1%AB%E5%9D%91/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/08/24/java-调用spark-submit填坑/</id>
    <published>2018-08-24T08:50:31.000Z</published>
    <updated>2018-08-27T09:31:25.311Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><blockquote><p>在开发过程中遇到了如下的问题:<br>使用shell调用spark-submit提交程序时,不到一分钟跑完所有的流程.<br>但是使用java调用shell进而调用spark-submit就会卡在parttion比较多的步骤,此问题我纠结了四天的时间.<br>可是可的确是弥补了很多知识上的短板.<br>排查过程如下:</p></blockquote><a id="more"></a><h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><h3 id="集群问题"><a href="#集群问题" class="headerlink" title="集群问题"></a>集群问题</h3><blockquote><p>首先怀疑的是集群问题,搜索度娘和谷哥有很多人告知是因为内存不够或者是分配给的内核不够,但是此类问题在过滤后台的日志来看是不存在的,</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">426.2 MB of 1 GB physical memory used; 2.2 GB of 2.1 GB virtual memory used</div></pre></td></tr></table></figure><h3 id="代码问题"><a href="#代码问题" class="headerlink" title="代码问题"></a>代码问题</h3><blockquote><p>后来怀疑是代码问题，因为使用python去调用该程序也是没问题的．<br>代码如下:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">runShell</span><span class="params">(String command)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">    String result = <span class="string">""</span>;</div><div class="line">    Process process = Runtime.getRuntime().exec(command);</div><div class="line">    <span class="comment">// 获取shell返回流</span></div><div class="line">    BufferedInputStream bufferedInputStream = <span class="keyword">new</span> BufferedInputStream(process.getInputStream());</div><div class="line">    <span class="comment">// 字符流转换字节流</span></div><div class="line">    BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(bufferedInputStream));</div><div class="line"></div><div class="line">    String line;</div><div class="line">    <span class="keyword">while</span> ((line = bufferedReader.readLine()) != <span class="keyword">null</span>)</div><div class="line">        result = line;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        process.waitFor();</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        <span class="comment">// 关闭输入流</span></div><div class="line">        bufferedInputStream.close();</div><div class="line">        bufferedReader.close();</div><div class="line">        process.destroy();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> result;</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>首先来解释一下 waitFor() 方法的意义， waitFor() 表示当前 Process 所在的子线程处于等待状态，如有必要，一直要等到由该 Process 对象表示的进程已经终止，官网说如果我们在调用此方法时，如果不注意的话，很容易出现主线程阻塞， Process 也挂起的情况。这就是我遇到的问题.解决办法是，在调用 waitFor() 的时候， Process 需要向主线程汇报运行状况，所以要注意清空缓存区，即 InputStream 和 ErrorStream ，注意这里 InputStream 和 ErrorStream 都需要清空。<br>但是上面的方式只是解决了标准输入流的读取，并且打印最后一行，并没有处理标准错误流，后来经过如下代码的测试，spark-submit提交的日志竟然打印在标准错误流中，所以也就解释了之前为什么会卡在partiion比较多的地方,因为该部分日志较多,达到了缓存区的上限,所以流程不能继续.<br>错误的表象:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">Container marked as failed: container_1535013730755_0026_01_000007 on host: rocket04.kylin.com. Exit status: <span class="number">1</span>. Diagnostics: Exception from container-launch.</div><div class="line">Container id: container_1535013730755_0026_01_000007</div><div class="line">Exit code: <span class="number">1</span></div><div class="line">Stack trace: ExitCodeException exitCode=<span class="number">1</span>: </div><div class="line">at org.apache.hadoop.util.Shell.runCommand(Shell.java:<span class="number">601</span>)</div><div class="line">at org.apache.hadoop.util.Shell.run(Shell.java:<span class="number">504</span>)</div><div class="line">at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:<span class="number">786</span>)</div><div class="line">at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:<span class="number">213</span>)</div><div class="line">at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:<span class="number">302</span>)</div><div class="line">at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:<span class="number">82</span>)</div><div class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">262</span>)</div><div class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</div><div class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</div><div class="line">at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</div></pre></td></tr></table></figure><blockquote><p>调研的现象如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">12</span>:<span class="number">59</span> INFO cluster.YarnScheduler: Removed TaskSet <span class="number">4.0</span>, whose tasks have all completed, from pool </div><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">12</span>:<span class="number">59</span> INFO scheduler.DAGScheduler: ResultStage <span class="number">4</span> (saveAsTextFile at ReportNatureIncubationCustom.scala:<span class="number">265</span>) finished in <span class="number">0.635</span> s</div><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">12</span>:<span class="number">59</span> INFO scheduler.DAGScheduler: Job <span class="number">2</span> finished: saveAsTextFile at ReportNatureIncubationCustom.scala:<span class="number">265</span>, took <span class="number">3.497685</span> s</div><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">13</span>:<span class="number">01</span> INFO spark.SparkContext: <span class="function">Invoking <span class="title">stop</span><span class="params">()</span> from shutdown hook</span></div></pre></td></tr></table></figure></p><p>测试代码:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">niceCallShell</span><span class="params">(String command)</span> </span>&#123;</div><div class="line">       String result = <span class="string">""</span>;</div><div class="line">       <span class="keyword">try</span> &#123;</div><div class="line">           System.out.println(<span class="string">"cmd start"</span>);</div><div class="line">           Process p = Runtime.getRuntime().exec(command);  <span class="comment">//调用Linux的相关命令</span></div><div class="line">           <span class="keyword">new</span> RunThread(p.getInputStream(), <span class="string">"INFO"</span>).start();</div><div class="line">           <span class="keyword">new</span> RunThread(p.getErrorStream(), <span class="string">"ERROR"</span>).start();</div><div class="line">           <span class="keyword">int</span> value = p.waitFor();</div><div class="line">           <span class="keyword">if</span> (value == <span class="number">0</span>)</div><div class="line">               result = <span class="string">"complete"</span>;</div><div class="line">           <span class="keyword">else</span></div><div class="line">               result = <span class="string">"failed"</span>;</div><div class="line">       &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">           e.printStackTrace();</div><div class="line">       &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">           e.printStackTrace();</div><div class="line">       &#125;</div><div class="line"></div><div class="line">       <span class="keyword">return</span> result;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RunThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">       InputStream is;</div><div class="line">       String printType;</div><div class="line"></div><div class="line">       RunThread(InputStream is, String printType) &#123;</div><div class="line">           <span class="keyword">this</span>.is = is;</div><div class="line">           <span class="keyword">this</span>.printType = printType;</div><div class="line">       &#125;</div><div class="line"></div><div class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">           <span class="keyword">try</span> &#123;</div><div class="line">               InputStreamReader isr = <span class="keyword">new</span> InputStreamReader(is);</div><div class="line">               BufferedReader br = <span class="keyword">new</span> BufferedReader(isr);</div><div class="line">               String line = <span class="keyword">null</span>;</div><div class="line">               <span class="keyword">while</span> ((line = br.readLine()) != <span class="keyword">null</span>)</div><div class="line">                   System.out.println(printType + <span class="string">"&gt;"</span> + line);</div><div class="line">           &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</div><div class="line">               ioe.printStackTrace();</div><div class="line">           &#125;</div><div class="line">       &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="不改java代码"><a href="#不改java代码" class="headerlink" title="不改java代码"></a>不改java代码</h3><blockquote><p>该解决方案为把spark-submit的日志重定向到一个独立文件中,就不会发生与java交互的Input/Error,方案如下:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">master yarn-client $deployPath/tourism-data-1.0.jar $&#123;reportId&#125; &gt; spark_cumstom_$&#123;reportId&#125;.log 2&gt;&amp;1</div></pre></td></tr></table></figure><h3 id="改动java代码"><a href="#改动java代码" class="headerlink" title="改动java代码"></a>改动java代码</h3><blockquote><p>这部分实则就是改动下之前的测试代码,将标准输入和标准错误放到不同的线程中,然后分发日志到logback中.</p></blockquote><h3 id="比较与总结"><a href="#比较与总结" class="headerlink" title="比较与总结"></a>比较与总结</h3><blockquote><p>第一种方法相比较与第二种方法而言,对于后期排查问题而言,可以更加直观,可以在shell文件的同级目录下找到所有的执行log,便于排查问题.<br>第二种则需要在系统级别的log中找到需要的信息,比较繁琐,如果数据较大,同时并发度很大,则嵌入的日志很大.但是相比较来说第二种,比较传统,也更接近java 的系统调用的使用习惯.当然也可返回shell调用成功的最后一行的flag,但是不方便排查问题.<br>综上:最终选择了第一种方案.</p></blockquote><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><h3 id="快捷排查"><a href="#快捷排查" class="headerlink" title="快捷排查"></a>快捷排查</h3><blockquote><p>怎么通过自带的UI来定位错误信息已经日志信息，已经各个节点上的日志信息预览？</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn application list</div></pre></td></tr></table></figure><blockquote><p>通过以上的命令进而通过我们设定的应用名称从而定位到Tracking-URL，在保证你本地已配置好数据集群的ip和host配置关系以后，通过该地址可以找到以下界面:</p></blockquote><p><img src="/ITWO/assets/spark-task-ui.png" alt="spark ui "></p><blockquote><p>从下图定位到executor</p></blockquote><p><img src="/ITWO/assets/executors.png" alt="executors"></p><blockquote><p>下图为详细信息</p></blockquote><p><img src="/ITWO/assets/error-log.png" alt="executors"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;问题背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在开发过程中遇到了如下的问题:&lt;br&gt;使用shell调用spark-submit提交程序时,不到一分钟跑完所有的流程.&lt;br&gt;但是使用java调用shell进而调用spark-submit就会卡在parttion比较多的步骤,此问题我纠结了四天的时间.&lt;br&gt;可是可的确是弥补了很多知识上的短板.&lt;br&gt;排查过程如下:&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/java/"/>
    
      <category term="spark" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/spark/"/>
    
      <category term="submit" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/submit/"/>
    
  </entry>
  
  <entry>
    <title>cron 使用范例</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/08/13/cron-%E4%BD%BF%E7%94%A8%E8%8C%83%E4%BE%8B/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/08/13/cron-使用范例/</id>
    <published>2018-08-13T07:38:40.000Z</published>
    <updated>2018-08-16T12:34:57.410Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>使用范例如下：</p></blockquote><a id="more"></a><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">一个cron表达式有至少6个（也可能7个）有空格分隔的时间元素。</div><div class="line">按顺序依次为 </div><div class="line">秒（0~59） </div><div class="line">分钟（0~59）</div><div class="line">小时（0~23）</div><div class="line">天（月）（0~31，但是你需要考虑你月的天数）</div><div class="line">月（0~11）</div><div class="line">天（星期）（1~7 1=SUN 或 SUN，MON，TUE，WED，THU，FRI，SAT）</div><div class="line">7.年份（1970－2099）</div><div class="line">其中每个元素可以是一个值(如6),一个连续区间(9-12),一个间隔时间(8-18/4)(/表示每隔4小时),一个列表(1,3,5),通配符。由于"月份中的日期"和"星期中的日期"这两个元素互斥的,必须要对其中一个设置?.</div><div class="line">0 0 10,14,16 * * ? 每天上午10点，下午2点，4点</div><div class="line">0 0/30 9-17 * * ?   朝九晚五工作时间内每半小时</div><div class="line">0 0 12 ? * WED 表示每个星期三中午12点 </div><div class="line">"0 0 12 * * ?" 每天中午12点触发 </div><div class="line">"0 15 10 ? * *" 每天上午10:15触发 </div><div class="line">"0 15 10 * * ?" 每天上午10:15触发 </div><div class="line">"0 15 10 * * ? *" 每天上午10:15触发 </div><div class="line">"0 15 10 * * ? 2005" 2005年的每天上午10:15触发 </div><div class="line">"0 * 14 * * ?" 在每天下午2点到下午2:59期间的每1分钟触发 </div><div class="line">"0 0/5 14 * * ?" 在每天下午2点到下午2:55期间的每5分钟触发 </div><div class="line">"0 0/5 14,18 * * ?" 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 </div><div class="line">"0 0-5 14 * * ?" 在每天下午2点到下午2:05期间的每1分钟触发 </div><div class="line">"0 10,44 14 ? 3 WED" 每年三月的星期三的下午2:10和2:44触发 </div><div class="line">"0 15 10 ? * MON-FRI" 周一至周五的上午10:15触发 </div><div class="line">"0 15 10 15 * ?" 每月15日上午10:15触发 </div><div class="line">"0 15 10 L * ?" 每月最后一日的上午10:15触发 </div><div class="line">"0 15 10 ? * 6L" 每月的最后一个星期五上午10:15触发 </div><div class="line">"0 15 10 ? * 6L 2002-2005" 2002年至2005年的每月的最后一个星期五上午10:15触发 </div><div class="line">"0 15 10 ? * 6#3" 每月的第三个星期五上午10:15触发</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;使用范例如下：&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="spring,cron" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/spring-cron/"/>
    
  </entry>
  
  <entry>
    <title>spark 聚合进化</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/07/27/spark-%E8%81%9A%E5%90%88%E8%BF%9B%E5%8C%96/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/07/27/spark-聚合进化/</id>
    <published>2018-07-27T09:33:00.000Z</published>
    <updated>2018-08-24T08:18:05.952Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><blockquote><p>通过分析流水，然后统计商户维度的以下字段：</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">* 1-交易金额</div><div class="line">* 2-交易笔数,3-交易人数</div><div class="line">* 4-笔单价,5-客单价,6-上午笔数占比</div><div class="line">* 7-午间笔数占比,8-下午笔数占比,9-晚间笔数占比,10-深夜笔数占比</div><div class="line">* （注：上午 00:00-9:59；午间 10:00-12:59；下午 13:00-16:59；晚间 17:00-20:59；深夜 21:00-23:59）</div></pre></td></tr></table></figure><blockquote><p>未完待续</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;需求描述&quot;&gt;&lt;a href=&quot;#需求描述&quot; class=&quot;headerlink&quot; title=&quot;需求描述&quot;&gt;&lt;/a&gt;需求描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;通过分析流水，然后统计商户维度的以下字段：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure c
      
    
    </summary>
    
    
      <category term="spark" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/spark/"/>
    
      <category term="agg" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/agg/"/>
    
      <category term="sql" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/sql/"/>
    
      <category term="pivot" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/pivot/"/>
    
  </entry>
  
  <entry>
    <title>mapreduce 温故</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/07/23/mapredcue%20%E6%B8%A9%E4%B9%A0/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/07/23/mapredcue 温习/</id>
    <published>2018-07-23T06:36:03.322Z</published>
    <updated>2018-07-23T06:36:03.322Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求背景："><a href="#需求背景：" class="headerlink" title="需求背景："></a>需求背景：</h2><blockquote><p>做大数据有一段时间了，梳理下用到mapreduce的一些问题和解决方案。<a id="more"></a></p></blockquote><h2 id="mapreduce"><a href="#mapreduce" class="headerlink" title="mapreduce"></a>mapreduce</h2><blockquote><p>mapreduce:顾名思义，map做映射，reduce做规约。<br>主要分以下步骤：<br>1.输入分块<br>2.map<br>3.shuffer<br>4.reduce</p></blockquote><p><img src="/ITWO/assets/mapreduce01.jpg" alt="mapredcue流程图"><br>重点是shuffer阶段</p><h2 id="reduce个数的计算方法"><a href="#reduce个数的计算方法" class="headerlink" title="reduce个数的计算方法:"></a>reduce个数的计算方法:</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">double</span> bytes = Math.max(totalInputFileSize, bytesPerReducer);</div><div class="line"><span class="keyword">int</span> reducers = (<span class="keyword">int</span>) Math.ceil(bytes / bytesPerReducer);</div><div class="line">reducers = Math.max(<span class="number">1</span>, reducers);</div><div class="line">reducers = Math.min(maxReducers, reducers);</div></pre></td></tr></table></figure><blockquote><p>　从计算逻辑可以看出该量由输入文件的大小以及设置的每个reduce可以处理的字节数大小决定．</p></blockquote><p><img src="/ITWO/assets/mapreduce02.png" alt="shuffer流程图"></p><h2 id="流程细节："><a href="#流程细节：" class="headerlink" title="流程细节："></a>流程细节：</h2><h3 id="map输出过程："><a href="#map输出过程：" class="headerlink" title="map输出过程："></a>map输出过程：</h3><blockquote><p>&ensp;&ensp;&ensp;&ensp;如果没有reduce阶段，则直接输出到hdfs上，如果有reduce作业，则每个map方法的输出在写磁盘前先在内存中缓存。每个map task都有一个环状的内存缓冲区，存储着map的输出结果，默认100m，在写磁盘时，根据reduce的数量把数据划分为相应的分区(使用默认的分区算法（对输入文件的kv中对key hash后再对reduce task数量取模(reduce个数的算法见前文)),默认的hashPartioner只会作用默认分隔符分割以后的key，如果需要自定义分区，则需要你自定义二次分区比如keyfieldParttioner来实现,在每个分区中数据进行内排序，分区的个数和reduce的个数是一致的，在每次当缓冲区快满的时候由一个独立的线程将缓冲区的数据以一个溢出文件的方式存放到磁盘(这个溢写是由单独线程来完成，不影响往缓冲区写map结果的线程。溢写线程启动时不应该阻止map的结果输出，所以整个缓冲区有个溢写的比例spill.percent。这个比例默认是0.8，也就是当缓冲区的数据已经达到阈值（buffer size <em> spill percent = 100MB </em> 0.8 = 80MB），溢写线程启动，锁定这80MB的内存，执行溢写过程。Map task的输出结果还可以往剩下的20MB内存中写，互不影响。)，当整个map task结束后再对磁盘中这个map task产生的所有溢出文件做合并，被合并成已分区且已排序的输出文件。然后reduce开始fetch（拉取）map端合并好对应分区的数据，然后在reduce端合并（因为会有很多map的输出，需要合并），此时在reduce端也会进行一次sort,确保所有map的输出都排序并合并成完成以后，才会启动reduce task,所以怎么才能确保你在reduce逻辑处理时拿到的是你要的排序后的数据配合你的处理就至关重要了。</p></blockquote><h3 id="reducer如何知道要从哪个tasktracker取得map输出呢？"><a href="#reducer如何知道要从哪个tasktracker取得map输出呢？" class="headerlink" title="reducer如何知道要从哪个tasktracker取得map输出呢？"></a>reducer如何知道要从哪个tasktracker取得map输出呢？</h3><blockquote><p>&ensp;&ensp;&ensp;&ensp;map任务成功完成以后，他们会通知其父tasktracker状态已更新，然后taskTracker进而通知jobTracker。这些通知在前面的心跳机制中传输。因此，对于指定作业，jobTracker知道map输出和taskTracker之间的映射关系。reducer中的一个线程定期询问jobTracher以便获取map输出的位置,直到它获得所有输出位置。</p></blockquote><h3 id="map和reduce如何合理控制自己的个数？"><a href="#map和reduce如何合理控制自己的个数？" class="headerlink" title="map和reduce如何合理控制自己的个数？"></a>map和reduce如何合理控制自己的个数？</h3><blockquote><p>&ensp;&ensp;&ensp;&ensp;map的个数是由dfs.block.size控制，该配置可以在执行程序之前由参数（见下文）控制，默认配置位于hdfs-site.xml中dfs.block.size控制，1.x的默认配置为64m,2.x的默认配置为128m,</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"> <span class="keyword">long</span> goalSize = totalSize / (numSplits == <span class="number">0</span> ? <span class="number">1</span> : numSplits);</div><div class="line"> <span class="keyword">long</span> minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.</div><div class="line">    FileInputFormat.SPLIT_MINSIZE, <span class="number">1</span>), minSplitSize);</div><div class="line"><span class="keyword">long</span> blockSize = file.getBlockSize();</div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">computeSplitSize</span><span class="params">(<span class="keyword">long</span> goalSize, <span class="keyword">long</span> minSize,</span></span></div><div class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> blockSize)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> Math.max(minSize, Math.min(goalSize, blockSize));</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>&ensp;&ensp;&ensp;&ensp;从上面可以看出，最终的split size是由三个因素决定，goalsize为map输入数据除以用户自己设置的map个数（默认为1）得到的;minsize为mapred-site.xml配置的mapred.min.split.size决定，因为minSplitSize为1;第三个影响因素为blocksize,这个看配置，最终我们可以得出,如果不设置min.size,则由blocksize决定，如果设置了，则是由这两者中大的一个决定。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="built_in">set</span> mapred.min.split.size=256000000;        -- 决定每个map处理的最大的文件大小，单位为B</div><div class="line"></div><div class="line">方法1</div><div class="line"><span class="built_in">set</span> mapred.reduce.tasks=10;  -- 设置reduce的数量</div><div class="line">方法2</div><div class="line"><span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=1073741824 -- 每个reduce处理的数据量,默认1GB</div></pre></td></tr></table></figure><p>block_size : hdfs的文件块大小，默认为64M，可以通过参数dfs.block.size设置<br>total_size : 输入文件整体的大小<br>input_file_num : 输入文件的个数</p><p>（1）默认map个数</p><blockquote><p>如果不进行任何设置，默认的map个数是和blcok_size相关的。<br>   default_num = total_size / block_size;</p></blockquote><p>（2）期望大小</p><blockquote><p>可以通过参数mapred.map.tasks来设置程序员期望的map个数，但是这个个数只有在大于default_num的时候，才会生效。<br>   goal_num = mapred.map.tasks;</p></blockquote><p>（3）设置处理的文件大小</p><blockquote><p>可以通过mapred.min.split.size 设置每个task处理的文件大小，但是这个大小只有在大于block_size的时候才会生效。<br>   split_size = max(mapred.min.split.size, block_size);<br>   split_num = total_size / split_size;</p></blockquote><p>（4）计算的map个数</p><blockquote><p>compute_map_num = min(split_num,  max(default_num, goal_num))</p><p>&ensp;&ensp;&ensp;&ensp;除了这些配置以外，mapreduce还要遵循一些原则。 mapreduce的每一个map处理的数据是不能跨越文件的，也就是说min_map_num &gt;= input_file_num。 所以，最终的map个数应该为：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">final_map_num = max(compute_map_num, input_file_num)</div></pre></td></tr></table></figure><blockquote><p>经过以上的分析，在设置map个数的时候，可以简单的总结为以下几点：<br>（1）如果想增加map个数，则设置mapred.max.split.size为一个较小的值。<br>（2）如果想减小map个数，则设置mapred.min.split.size 为一个较大的值。</p></blockquote><p>reduce个数的设置则相对简单，要么你设置mapred.reduce.tasks的数值，要么你在hive中可以设置每个reduce可以处理的字节数，从而约束reduce的个数。</p><blockquote><p>小技巧</p></blockquote><p>&ensp;&ensp;&ensp;&ensp;在hive中带空的设置参数可以打印出当前该参数的设置值。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hive&gt; set dfs.block.size;</div><div class="line">dfs.block.size=268435456</div><div class="line">hive&gt; set mapred.map.tasks;</div><div class="line">mapred.map.tasks=2</div></pre></td></tr></table></figure><h2 id="mapreduce进度说明"><a href="#mapreduce进度说明" class="headerlink" title="mapreduce进度说明"></a>mapreduce进度说明</h2><h3 id="1-Prepare"><a href="#1-Prepare" class="headerlink" title="1. Prepare"></a>1. Prepare</h3><blockquote><p>准备数据，抓取Map过来的输出（进度：0~33%）</p></blockquote><h3 id="2-Sort"><a href="#2-Sort" class="headerlink" title="2. Sort"></a>2. Sort</h3><blockquote><p>排序阶段（进度：33%~66%）</p></blockquote><h3 id="3-Reduce"><a href="#3-Reduce" class="headerlink" title="3. Reduce"></a>3. Reduce</h3><blockquote><p>真正的reduce计算阶段，执行你所写的reduce代码（进度：66%~100%）.<br>如果前面66%速度很快，后面慢的话就是reduce部分没有写好；否则才是数据量大的问题。</p></blockquote><h2 id="hadoop-yarn-配置的图解"><a href="#hadoop-yarn-配置的图解" class="headerlink" title="hadoop yarn 配置的图解"></a>hadoop yarn 配置的图解</h2><p><img src="/ITWO/assets/hadoop 2.0 yarn 配置项.png" alt="hadoop yarn 配置的图解"></p><h3 id="AM的内存使用错误"><a href="#AM的内存使用错误" class="headerlink" title="AM的内存使用错误"></a>AM的内存使用错误</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Diagnostics: Container [pid=<span class="number">21387</span>,containerID=container_e33_1532170420957_0001_02_000001] is running beyond physical memory limits. </div><div class="line">Current usage: <span class="number">1.1</span> GB of <span class="number">1</span> GB physical memory used; <span class="number">2.7</span> GB of <span class="number">2.1</span> GB virtual memory used. Killing container.</div><div class="line">Dump of the process-tree <span class="keyword">for</span> container_e33_1532170420957_0001_02_000001 :</div><div class="line">        |- <span class="function">PID PPID PGRPID SESSID CMD_NAME <span class="title">USER_MODE_TIME</span><span class="params">(MILLIS)</span> <span class="title">SYSTEM_TIME</span><span class="params">(MILLIS)</span> <span class="title">VMEM_USAGE</span><span class="params">(BYTES)</span> <span class="title">RSSMEM_USAGE</span><span class="params">(PAGES)</span> FULL_CMD_LINE</span></div><div class="line"><span class="function">        |- 21399 21387 21387 21387 <span class="params">(java)</span> 14478 467 2856710144 281207 /usr/lib/jvm/java-8-oracle/bin/java </span></div><div class="line"><span class="function">-Dlog4j.configuration</span>=container-log4j.properties </div><div class="line">-Dyarn.app.container.log.dir=/data/dev/sdb1/yarn/container-logs/application_1532170420957_0001/container_e33_1532170420957_0001_02_000001 </div><div class="line">-Dyarn.app.container.log.filesize=<span class="number">0</span> -Dhadoop.root.logger=INFO,CLA </div><div class="line">-Dhadoop.root.logfile=syslog </div><div class="line">-Djava.net.preferIPv4Stack=<span class="keyword">true</span> -Xmx825955249 org.apache.hadoop.mapreduce.v2.app.MRAppMaster</div></pre></td></tr></table></figure><blockquote><p>仔细预览以上的错误可以定位到以下的信息</p></blockquote><ol><li>AppMaster报出的错误</li><li>-Xmx825955249 设置了运行的参数值</li></ol><blockquote><p>结合图示我们找下应该去集群找那些配置来定位问题</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">上限参数:yarn.app.mapreduce.am.resource.mb</div><div class="line">运行参数:yarn.app.mapreduce.am.command-opts</div></pre></td></tr></table></figure><blockquote><p>以上的这两参数肯定少不了，后来从集群中的确也定位到的确是是yarn.app.mapreduce.am.resource.mb该参数差的设定过小为1G，同时yarn.app.mapreduce.am.command-opts为报错中的展示信息，需要更改，因为这两项更改的都是yarn-site.xml中的配置，cdh中改完之后保存分发这些信息，然后重启集群。</p></blockquote><table><thead><tr><th>配置文件</th><th>配置项</th><th>设置值</th></tr></thead><tbody><tr><td>yarn-site.xml</td><td>yarn.nodemanager.resource.memory-mb</td><td>Container数量 * 每个Container的内存大小</td></tr><tr><td>yarn-site.xml</td><td>yarn.scheduler.minimum-allocation-mb</td><td>每个Container的内存大小</td></tr><tr><td>yarn-site.xml</td><td>yarn.scheduler.maximum-allocation-mb</td><td>Container数量 * 每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.map.memory.mb</td><td>每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.reduce.memory.mb</td><td>2 * 每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.map.java.opts</td><td>0.8 * 每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.reduce.java.opts</td><td>0.8 <em> 2 </em> 每个Container的内存大小</td></tr><tr><td>yarn-site.xml (check)</td><td>yarn.app.mapreduce.am.resource.mb</td><td>2 * 每个Container的内存大小</td></tr><tr><td>yarn-site.xml (check)</td><td>yarn.app.mapreduce.am.command-opts</td><td>0.8 <em> 2 </em> 每个Container的内存大小</td></tr></tbody></table><blockquote><p>以上为各配置的位置以及建议的设置值。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">例如：</div><div class="line">集群的节点有 12 CPU cores, 48 GB RAM, and 12 磁盘.</div><div class="line">预留内存= 6 GB 系统预留 + 8 GB HBase预留</div><div class="line">最小Container内存大小 = 2 GB</div><div class="line"></div><div class="line">如果不安装 HBase:</div><div class="line"><span class="meta">#</span><span class="bash">Container数 = min (2*12, 1.8* 12, (48-6)/2) = min (24, 21.6, 21) = 21</span></div><div class="line">每个Container的内存大小 = max (2, (48-6)/21) = max (2, 2) = 2</div><div class="line"></div><div class="line">如果安装 Hbase：</div><div class="line"><span class="meta">#</span><span class="bash">Container数 = min (2*12, 1.8* 12, (48-6-8)/2) = min (24, 21.6, 17) = 17</span></div><div class="line">每个Container的内存大小 = max (2, (48-6-8)/17) = max (2, 2) = 2</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求背景：&quot;&gt;&lt;a href=&quot;#需求背景：&quot; class=&quot;headerlink&quot; title=&quot;需求背景：&quot;&gt;&lt;/a&gt;需求背景：&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;做大数据有一段时间了，梳理下用到mapreduce的一些问题和解决方案。
    
    </summary>
    
    
      <category term="mapreduce" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/mapreduce/"/>
    
      <category term="shuffer" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/shuffer/"/>
    
  </entry>
  
  <entry>
    <title>使用hive/mapreduce给大数据全局排序，同时巧用该方法实现hbase的预分区</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/07/18/%E4%BD%BF%E7%94%A8hive-mapreduce%E7%BB%99%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F%EF%BC%8C%E5%90%8C%E6%97%B6%E5%B7%A7%E7%94%A8%E8%AF%A5%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0hbase%E7%9A%84%E9%A2%84%E5%88%86%E5%8C%BA/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/07/18/使用hive-mapreduce给大数据全局排序，同时巧用该方法实现hbase的预分区/</id>
    <published>2018-07-18T01:50:44.000Z</published>
    <updated>2018-07-19T08:22:12.040Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><blockquote><p>完成排序，打行号，然后根据分位数找到分界点。</p></blockquote><a id="more"></a><h2 id="hive篇"><a href="#hive篇" class="headerlink" title="hive篇"></a>hive篇</h2><h3 id="造测试数据"><a href="#造测试数据" class="headerlink" title="造测试数据"></a>造测试数据</h3><blockquote><p>直接上代码，如下的代码可以仿造出64位的加密字符串，达到模拟某种加密的方式，如此方式造了100w的数据用于测试。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">key = <span class="string">""</span>.join(random.choice(<span class="string">"0123456789ABCDEF"</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">64</span>))</div></pre></td></tr></table></figure><h3 id="导数据"><a href="#导数据" class="headerlink" title="导数据"></a>导数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">use</span> koulb;</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> t_card_info (<span class="keyword">key</span> <span class="keyword">string</span>)</div><div class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></div><div class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span></div><div class="line">Location <span class="string">'/user/koulingbo/cardInfo'</span>;</div></pre></td></tr></table></figure><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_card_info_row <span class="keyword">as</span> </div><div class="line"><span class="keyword">select</span> row_number() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">key</span>) <span class="keyword">as</span> rn,<span class="keyword">key</span> <span class="keyword">from</span> t_card_info;</div><div class="line"></div><div class="line"> number of reducers: 1</div></pre></td></tr></table></figure><blockquote><p>众所周知 hive 中的order by 适用于全局排序，所以它只能是给到一个reduce来完成，因为不同的parttion来分区到不同的reduce就决定了只能reduce内部有序，如果你想达到全局排序只能够是一个reduce。</p></blockquote><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><blockquote><p>思路：使用分位数函数来定位切割点，然后转置→行转列，与之前的行号join拿到最终的分界点。当然最初你要根据tsv 的大小、snappy压缩比、以及region的大小（根据hfile以及其个数确定）来确定要分成几个region,本文暂定为100个分区来做演示。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">var="1/100"</div><div class="line">for i in &#123;2..99&#125;</div><div class="line">do</div><div class="line">        var="$var,$i/100"</div><div class="line">done</div><div class="line">echo $var</div><div class="line"></div><div class="line">hive -S -e "use koulb;create table koulb.t_card_info_res as select k.key from \</div><div class="line">(select explode(percentile_approx(rn,array($&#123;var&#125;),2168727))as keyRange \</div><div class="line">from koulb.t_card_info_row) r join koulb.t_card_info_row k on floor(r.keyRange)=k.rn;" </div><div class="line"></div><div class="line">hive -S -e "select * from koulb.t_card_info_res"&gt;res</div></pre></td></tr></table></figure><h3 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create 'card_quota_test_koulb', &#123;NAME =&gt; 'n', VERSIONS =&gt; 1, COMPRESSION =&gt; 'SNAPPY'&#125;,  &#123;SPLITS_FILE =&gt; 'res'&#125;</div></pre></td></tr></table></figure><h2 id="mapreduce部分"><a href="#mapreduce部分" class="headerlink" title="mapreduce部分"></a>mapreduce部分</h2><p>==未完待续==</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;完成排序，打行号，然后根据分位数找到分界点。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="mapreduce" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/mapreduce/"/>
    
      <category term="hive" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/hive/"/>
    
      <category term="python" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/python/"/>
    
      <category term="row_number" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/row-number/"/>
    
      <category term="percentile" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/percentile/"/>
    
      <category term="explode" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/explode/"/>
    
  </entry>
  
  <entry>
    <title>hbase/es load 问题总结</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/07/06/hbase-load-%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/07/06/hbase-load-问题总结/</id>
    <published>2018-07-06T01:48:49.000Z</published>
    <updated>2018-07-11T09:54:50.301Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>公司指标2.0开发了很多新的指标，数据量很客观，需要导入到列式存储数据库中，实现毫秒级别的响应查询，之前也有一版本的导入是导入到hbase中，但是hbase对于高并发的响应不是很理想，但凡高并发上来以后，时效性就会有影响。</p></blockquote><a id="more"></a><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><h3 id="HBase部分"><a href="#HBase部分" class="headerlink" title="HBase部分"></a>HBase部分</h3><blockquote><p>因为数据量大的缘故，使用的是将多个HDFS文件下的数据切割然后组合成tsv，再使用PUT元素转换为HFile文件，进而使用bulkload导入hbase中。</p></blockquote><h3 id="ES部分"><a href="#ES部分" class="headerlink" title="ES部分"></a>ES部分</h3><blockquote><p>复用之前生成好的tsv文件，组装好MapWritable，然后使用EsOutputFormat完成格式化输出。</p></blockquote><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><blockquote><p>这部分时间耗费在本地调试过渡到集群跑批，因为在本地集群单节点测试，你再怎么折腾也不出现配置文件找不到的问题，当然这里的前提是我使用了Properties文件做为传递配置参数的载体，在多节点测试服务器跑批的时候就会出现找不到配置文件的问题，因为该配置文件只会存在client端，而不会分发到各个其他的节点，所以会有找不到配置文件的问题出现。当然这部分也因为在使用的是ToolRunner.run(conf, new BootApplication(), args)，所以考虑过使用-files#filelink,具体用法参考字典文件分发的那篇文章，但是使用的时候，并没有达到达到预期效果，打开方式不对？<br>后来的做法是先用Properties对象解析外部的绝对路径的配置问价，将拿到的配置放到一直在框架中的上下文对象Context中的Configuration中，这样只要在client端提交任务的地方，传值给它，那么无论在框架运行的什么阶段都可以读到外部配置文件中的配置项。</p></blockquote><h3 id="HA的开启"><a href="#HA的开启" class="headerlink" title="HA的开启"></a>HA的开启</h3><blockquote><p>在本地的测试过程中，因为本地没有开启NM的HA，所以只需要配置如下内容就可以完成程序和集群的对接：</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fs.defaultFS=hdfs://hostname:8020</div></pre></td></tr></table></figure><blockquote><p>当然如果没有配置，也可以做本地文件的测试。</p><p>要对接开启了NM的HA的集群除了以上的配置还需要配置如下的内容:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">fs.nameservices=nameservice</div><div class="line"><span class="meta">#</span><span class="bash">指定nameservice服务下有几个namenode</span></div><div class="line">fs.ha.namenodes.nameservice=namenode33,namenode134</div><div class="line"><span class="meta">#</span><span class="bash">指定各个namenode节点的访问链接</span></div><div class="line">fs.namenode.rpc-address.nameservice.namenode33=node-01.upsmart.com:8020</div><div class="line">fs.namenode.rpc-address.nameservice.namenode134=node-02.upsmart.com:8020</div><div class="line">fs.client.failover.proxy.provider.nameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</div></pre></td></tr></table></figure><h3 id="habse-依赖问题"><a href="#habse-依赖问题" class="headerlink" title="habse 依赖问题"></a>habse 依赖问题</h3><blockquote><p>在导入数据到hbase的过程中在一集群导入没有问题，原本以为已经可以收工，但是后来在开启的HA的另一集群测试，出现了少包的问题，这部分可能跟集群安装依赖包的寡众有关系，但是保不齐那个集群就少包了，所以你要做的是把所有的能用到的包都打到jar包里，但是打包的时候又遇到如下的问题：<br>在打包的过程中有个包一直打不进去后来 </p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn -X clean install &gt;log</div></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-hadoop-compat<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0-cdh5.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure><blockquote><p>定位到如下的ERROR</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="string">'dependencies.dependency.version'</span> <span class="keyword">for</span> commons-logging:commons-logging:jar is missing. @</div></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">  <span class="comment">&lt;!-- General dependencies --&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-math<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div></pre></td></tr></table></figure><blockquote><p>原本以为去掉这些依赖就可以万事大吉，但是并没有奏效，后来使用了最彻底的办法依照大版本相同应该改动不大的原则换了版本到1.1.10,然后打包后问题解决。<br>以下方法并没有解决问题：</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></div></pre></td></tr></table></figure><blockquote><p>我的理解是解析pom的时候和打包去除某些依赖是不同的解析顺序</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.htrace&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;htrace-core&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;3.0.4&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line"></div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.htrace&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;htrace-core&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;3.1.0-incubating&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure><blockquote><p>这两个包都要加否则会报错找不到。</p></blockquote><h3 id="mapreduce-过程报错"><a href="#mapreduce-过程报错" class="headerlink" title="mapreduce 过程报错"></a>mapreduce 过程报错</h3><blockquote><p>beyond physical memory limits</p></blockquote><h4 id="map-reduce-阶段报错"><a href="#map-reduce-阶段报错" class="headerlink" title="map reduce  阶段报错"></a>map reduce  阶段报错</h4><blockquote><p>解决方案：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn.scheduler.minimum-allocation-mb 调节大点</div></pre></td></tr></table></figure></p></blockquote><h4 id="如果是只有reduce阶段报错"><a href="#如果是只有reduce阶段报错" class="headerlink" title="如果是只有reduce阶段报错"></a>如果是只有reduce阶段报错</h4><blockquote><p>解决方案：可以通过增大reduce的个数来分散reduce端的处理压力</p></blockquote><h4 id="reduce-100-beyond-physical-memory-limits"><a href="#reduce-100-beyond-physical-memory-limits" class="headerlink" title="reduce 100%  beyond physical memory limits"></a>reduce 100%  beyond physical memory limits</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#9</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:<span class="number">134</span>)</div><div class="line">        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:<span class="number">376</span>)</div><div class="line">        at org.apache.hadoop.mapred.YarnChild$<span class="number">2</span>.run(YarnChild.java:<span class="number">164</span>)</div><div class="line">        at java.security.AccessController.doPrivileged(Native Method)</div><div class="line">        at javax.security.auth.Subject.doAs(Subject.java:<span class="number">422</span>)</div><div class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1920</span>)</div><div class="line">        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<span class="number">158</span>)</div><div class="line">Caused by: java.lang.OutOfMemoryError: Java heap space</div></pre></td></tr></table></figure><blockquote><p>解决方案：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-D mapreduce.reduce.shuffle.memory.limit.percent=0.1</div></pre></td></tr></table></figure></p></blockquote><h3 id="ClassNotFoundException"><a href="#ClassNotFoundException" class="headerlink" title="ClassNotFoundException"></a>ClassNotFoundException</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java.lang.ClassNotFoundException: Class org.elasticsearch.hadoop.mr.EsOutputFormat not found</div></pre></td></tr></table></figure><blockquote><p>解决方案：</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Create job</span></div><div class="line">job.setJarByClass(BootApplication.class);</div></pre></td></tr></table></figure><blockquote><p>问题分析：看代码，一目了然。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setJarByClass</span><span class="params">(Class cls)</span> </span>&#123;</div><div class="line">    String jar = findContainingJar(cls);</div><div class="line">    <span class="keyword">if</span> (jar != <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="keyword">this</span>.setJar(jar);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="es导入"><a href="#es导入" class="headerlink" title="es导入"></a>es导入</h3><h4 id="Limit-of-total-fields-1000-in-index-card-nature-has-been-exceeded"><a href="#Limit-of-total-fields-1000-in-index-card-nature-has-been-exceeded" class="headerlink" title="Limit of total fields [1000] in index [card_nature] has been exceeded"></a>Limit of total fields [1000] in index [card_nature] has been exceeded</h4><blockquote><p>解决方案：</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">curl  -H "Content-Type: application/json"  -XPUT http://192.168.88.126:9200/card_nature/_settings?pretty=true -d '&#123;"settings": </div><div class="line">&#123;"index.mapping.total_fields.limit": 100000&#125;&#125;'</div></pre></td></tr></table></figure><h4 id="建立索引的时候报错：-usr-bin-curl-Argument-list-too-long"><a href="#建立索引的时候报错：-usr-bin-curl-Argument-list-too-long" class="headerlink" title="建立索引的时候报错：/usr/bin/curl: Argument list too long"></a>建立索引的时候报错：/usr/bin/curl: Argument list too long</h4><blockquote><p>解决方案<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">curl -H 'content-type: application/json' -XPUT \</div><div class="line">  -d @- 'http://localhost:9200/card_nature' &lt;&lt;CURL_DATA</div><div class="line">&#123;</div><div class="line">    "settings": &#123;</div><div class="line">                "number_of_replicas": 0,</div><div class="line">                "number_of_shards": 6,</div><div class="line">                "refresh_interval": "-1",</div><div class="line">                "index.mapping.total_fields.limit": 100000</div><div class="line">    &#125;,</div><div class="line">        "mappings": &#123;</div><div class="line">            "card_nature": &#123;</div><div class="line">                'properties': &#123;</div><div class="line">                    "CP0124":&#123;"type": "date","format": "yyyy-mm", "index": "false"&#125;,</div><div class="line">                    "CP0125":&#123;"type": "date","format": "yyyy-mm", "index": "false"&#125;,</div><div class="line">                    "CP0126":&#123;"type": "keyword", "index": "false"&#125;,</div><div class="line">                    "CP0127":&#123;"type": "keyword", "index": "false"&#125;,</div><div class="line">                    "CP0128":&#123;"type": "keyword", "index": "false"&#125;,</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">&#125;</div><div class="line">CURL_DATA</div><div class="line"></div><div class="line">curl -H "Content-Type: application/json"  -XPUT http://192.168.88.126:9200/card_nature/_settings?pretty=true -d '&#123;"settings": &#123;"refresh_interval": "5s","number_of_replicas":1&#125;&#125;'</div><div class="line">curl -XPOST  http://192.168.88.126:9200/card_nature/_refresh</div></pre></td></tr></table></figure></p></blockquote><h4 id="建索引的时候报错"><a href="#建索引的时候报错" class="headerlink" title="建索引的时候报错"></a>建索引的时候报错</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">"type": "mapper_parsing_exception",</div><div class="line">"reason": "No handler for type [string] declared on field [CP0125]"</div></pre></td></tr></table></figure><blockquote><p>解决方案:5.x以上已经没有string类型。如果需要分词的话使用text，不需要分词使用keyword。</p></blockquote><h3 id="es建立索引总结"><a href="#es建立索引总结" class="headerlink" title="es建立索引总结"></a>es建立索引总结</h3><blockquote><p>建立索引的时候关闭索引更新，别设置副本，如果字段超过1000，您就按照上面那样设置。<br>数据导入完成以后要么您开启五秒间隔更新，为了防止以后小批量的数据导入。<br>要么您每次导入数据之后手动使用最下面手动更新索引。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求背景&quot;&gt;&lt;a href=&quot;#需求背景&quot; class=&quot;headerlink&quot; title=&quot;需求背景&quot;&gt;&lt;/a&gt;需求背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;公司指标2.0开发了很多新的指标，数据量很客观，需要导入到列式存储数据库中，实现毫秒级别的响应查询，之前也有一版本的导入是导入到hbase中，但是hbase对于高并发的响应不是很理想，但凡高并发上来以后，时效性就会有影响。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="hbase" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/hbase/"/>
    
      <category term="bulkload" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/bulkload/"/>
    
      <category term="es" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/es/"/>
    
  </entry>
  
  <entry>
    <title>比较两个文件内容的不同</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/06/08/%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E7%9A%84%E4%B8%8D%E5%90%8C/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/06/08/比较两个文件内容的不同/</id>
    <published>2018-06-08T02:29:06.000Z</published>
    <updated>2019-01-03T12:48:03.174Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>比较两个文件的不同</p></blockquote><a id="more"></a><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">koulb@koulb-ubantu:~/testdata$ more a</div><div class="line">1</div><div class="line">a</div><div class="line">b</div><div class="line">d</div><div class="line">c</div><div class="line">koulb@koulb-ubantu:~/testdata$ more b</div><div class="line">a</div><div class="line">b</div></pre></td></tr></table></figure><blockquote><p>这时你去比较</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">koulb@koulb-ubantu:~/testdata$ comm -23 a b</div><div class="line">1</div><div class="line">f</div><div class="line">comm: 文件1 没有被正确排序</div><div class="line">e</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div></pre></td></tr></table></figure><blockquote><p>你需要做的是:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">koulb@koulb-ubantu:~/testdata$ sort -u a &gt;c</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -23 c b</div><div class="line">1</div><div class="line">c</div><div class="line">d</div></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">只显示file1独有的行：</div><div class="line">需要把第2列和第3列去掉：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -2 -3 file1 file2</div><div class="line">只显示file2独有的行：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -1 -3 file1 file2</div><div class="line"></div><div class="line">只显示两者重复的行：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -1 -2 file1 file2</div><div class="line">只显示两者不重复的行：</div><div class="line">后面的sed是将以\t开头的\t去掉：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -3 file1 file2 | sed 's/^\t//'</div></pre></td></tr></table></figure><h2 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h2><ul><li>使用该命令一定要先排序去重，否则不生效，切记。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景描述&quot;&gt;&lt;a href=&quot;#背景描述&quot; class=&quot;headerlink&quot; title=&quot;背景描述&quot;&gt;&lt;/a&gt;背景描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;比较两个文件的不同&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="shell" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/shell/"/>
    
      <category term="file" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/file/"/>
    
      <category term="comm" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/comm/"/>
    
  </entry>
  
  <entry>
    <title>安装es遇到的问题和解决方案</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/05/28/%E5%AE%89%E8%A3%85es%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/05/28/安装es遇到的问题和解决方案/</id>
    <published>2018-05-28T01:03:14.000Z</published>
    <updated>2018-05-28T01:24:00.749Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>在安装es过程中遇到的问题总结。</p></blockquote><a id="more"></a><h2 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h2><blockquote><ol><li>max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]</li></ol></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/sysctl.conf</div><div class="line">在最后一行加入如下配置</div><div class="line">vm.max_map_count=262144</div></pre></td></tr></table></figure><hr><h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bootstrap.memory_lock: true</div></pre></td></tr></table></figure><blockquote><p>开起如上配置启动报错如下</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="number">2</span>. bootstrap checks failed  memory locking requested <span class="keyword">for</span> elasticsearch process but memory is not locked</div><div class="line"></div><div class="line">These can be adjusted by modifying /etc/security/limits.conf, <span class="keyword">for</span> example:</div><div class="line">#allow user 'upsmart' mlockall</div><div class="line">upsmart soft memlock unlimited</div><div class="line">upsmart hard memlock unlimited</div><div class="line">If you are logged in interactively, you will have to re-login <span class="keyword">for</span> the <span class="keyword">new</span> limits to take effect.</div><div class="line">These can be adjusted by modifying /etc/security/limits.conf, <span class="keyword">for</span> example:</div><div class="line">#allow user 'upsmart' mlockall</div><div class="line">upsmart soft memlock unlimited</div><div class="line">upsmart hard memlock unlimited</div><div class="line">If you are logged in interactively, you will have to re-login <span class="keyword">for</span> the <span class="keyword">new</span> limits to take effect.</div></pre></td></tr></table></figure><blockquote><p>根据以上提示要修改以下内容</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">sudo vim /etc/security/limits.conf</div><div class="line"><span class="meta">#</span><span class="bash">allow user <span class="string">'upsmart'</span> mlockall</span></div><div class="line">upsmart soft memlock unlimited</div><div class="line">upsmart hard memlock unlimited</div></pre></td></tr></table></figure><hr><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>改的过程中发现启动程序不起作用，后来发现提示下面还有一句话提示的是如果不起作用，需要重新建立登录，后来关闭该会话，然后重启程序。（细节很重要！！！）</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求背景&quot;&gt;&lt;a href=&quot;#需求背景&quot; class=&quot;headerlink&quot; title=&quot;需求背景&quot;&gt;&lt;/a&gt;需求背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在安装es过程中遇到的问题总结。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="es" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/es/"/>
    
  </entry>
  
  <entry>
    <title>mongo查询慢排查</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/05/23/mongo%E6%9F%A5%E8%AF%A2%E6%85%A2%E6%8E%92%E6%9F%A5/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/05/23/mongo查询慢排查/</id>
    <published>2018-05-23T06:11:34.000Z</published>
    <updated>2018-05-23T07:30:24.257Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><blockquote><p>线上建模结果缓存在mongo中，之前由于数据量较少，进来一段时间由于老系统业务迁移过来，数据量也上来了，随之而来暴露出来一个问题.</p></blockquote><a id="more"></a><blockquote><p>查询很慢，但是只是个别客户的账号有问题，起初以为是客户建模的数据（客户部分代码有异常）有问题导致，但是从日志来看也有正常返回的数据但是也会有超时，后来把该客户的数据导入到开发集群来排查问题。</p></blockquote><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><blockquote><p>之前接口层面建的索引执行计划给出执行过程</p></blockquote><p><img src="/ITWO/assets/index_01.png" alt="之前接口层面建的索引执行计划给出执行过程"></p><blockquote><p>分解图示：<br>Explain部分分为</p></blockquote><ol><li>IXSCAN（检索索引）<br>  耗费250ms,排查（examined）文档965978个，该步骤返回文档965978个，用到的索引是account_1_analysisId_1，该索引匹配到的数据965978.</li><li>FETCH（拉取数据）<br> 耗时660ms,排查（examined）文档965978个，该步骤返回文档１个，遍历加判断最终拿到想要的结果，这步耗时也是最多的一步。</li><li>KEEP_MUTATIONS（暂时不知道是干嘛的）</li></ol><blockquote><p>其实仔细看已经看出端倪了，这边提示的是Index account_1_analysisId_1 was used to find matching values for account,<strong>analysisId</strong>，还有looking for these criteria: {<strong>“analysis_id”.</strong>:{“$eq”:”bc70380f-47b0-40f9-9e24-f54d61ce8bd6”}}，复合索引中的字段并不是我们检索的mongo字段，后来翻查代码，</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Document</span>(collection = <span class="string">"bill_analysis_info"</span>)</div><div class="line"><span class="meta">@CompoundIndexes</span>(&#123; <span class="meta">@CompoundIndex</span>(name = <span class="string">"query_index"</span>, def = <span class="string">"&#123;account : 1, analysisId : 1&#125;"</span>) &#125;)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BillAnalysisInfo</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;……&#125;</div></pre></td></tr></table></figure><blockquote><p>找到如上的根源。</p></blockquote><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><blockquote><p>手动建立针对这两个业务字段的复合索引</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.bill_analysis_info.ensureIndex(&#123;"account":1,"analysis_id":1&#125;)</div></pre></td></tr></table></figure><blockquote><p>再次查看同样查询的执行计划</p></blockquote><p><img src="/ITWO/assets/index_02.png" alt="重建索引执行计划给出执行过程"></p><blockquote><p><strong>效果很明显</strong></p></blockquote><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>mongo中原本以为会对建立索引过程中的字段是否为该集合的字段做判断，但此次排查下来明显没有，引以为戒。<br>细节，认真。<br>可视化工具用到的是dbKoda，要求mongo3.0版本以上。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;线上建模结果缓存在mongo中，之前由于数据量较少，进来一段时间由于老系统业务迁移过来，数据量也上来了，随之而来暴露出来一个问题.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="shell" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/shell/"/>
    
      <category term="mongo" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/mongo/"/>
    
      <category term="dbKoda" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/dbKoda/"/>
    
  </entry>
  
  <entry>
    <title>hadoop streaming 配置文件和字典文件分发方式</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/05/10/hadoop-streaming-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%92%8C%E5%AD%97%E5%85%B8%E6%96%87%E4%BB%B6%E5%88%86%E5%8F%91%E6%96%B9%E5%BC%8F/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/05/10/hadoop-streaming-配置文件和字典文件分发方式/</id>
    <published>2018-05-10T12:48:07.000Z</published>
    <updated>2018-05-14T01:48:11.952Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>通常情况下我们在hadoop streaming中通过input来设置我们需要处理的数据,然后逐条遍历打标记,从而在reduce端可以区别对待做聚合或者join操作.但是我们需要用到一些配置文件怎么办?</p></blockquote><a id="more"></a><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><blockquote><p>这里使用python来实现,我们的第一思路是:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">python test.py dict.txt</div><div class="line">-file dict.txt</div></pre></td></tr></table></figure><blockquote><p>当然这种方案只可以针对本地文件,一方面这样的文件每次都要分发带来很大的局限性(如果文件很大怎么办?是不是会很耗费性能?显然是的),另一方面如果我们需要使用的文件在hdfs上怎么实施?<br>先贴下官网的普及文档</p></blockquote><h3 id="Hadoop-Streaming中的大文件和档案"><a href="#Hadoop-Streaming中的大文件和档案" class="headerlink" title="Hadoop Streaming中的大文件和档案"></a>Hadoop Streaming中的大文件和档案</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">任务使用-cacheFile和-cacheArchive选项在集群中分发文件和档案，选项的参数是用户已上传至HDFS的文件或档案的URI。这些文件和档案在不同的作业间缓存。用户可以通过fs.default.name.config配置参数的值得到文件所在的host和fs_port。</div><div class="line"></div><div class="line">这个是使用-cacheFile选项的例子：</div><div class="line"></div><div class="line">-cacheFile hdfs://host:fs_port/user/testfile.txt#testlink</div><div class="line">在上面的例子里，url中#后面的部分是建立在任务当前工作目录下的符号链接的名字。这里的任务的当前工作目录下有一个“testlink”符号链接，它指向testfile.txt文件在本地的拷贝。如果有多个文件，选项可以写成：</div><div class="line"></div><div class="line">-cacheFile hdfs://host:fs_port/user/testfile1.txt#testlink1 -cacheFile hdfs://host:fs_port/user/testfile2.txt#testlink2</div><div class="line">-cacheArchive选项用于把jar文件拷贝到任务当前工作目录并自动把jar文件解压缩。例如：</div><div class="line"></div><div class="line">-cacheArchive hdfs://host:fs_port/user/testfile.jar#testlink3</div><div class="line">在上面的例子中，testlink3是当前工作目录下的符号链接，它指向testfile.jar解压后的目录。</div><div class="line"></div><div class="line">下面是使用-cacheArchive选项的另一个例子。其中，input.txt文件有两行内容，分别是两个文件的名字：testlink/cache.txt和testlink/cache2.txt。“testlink”是指向档案目录（jar文件解压后的目录）的符号链接，这个目录下有“cache.txt”和“cache2.txt”两个文件。</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/bin/hadoop  jar <span class="variable">$HADOOP_HOME</span>/hadoop-streaming.jar \</span></div><div class="line">                  -input "/user/me/samples/cachefile/input.txt"  \</div><div class="line">                  -mapper "xargs cat"  \</div><div class="line">                  -reducer "cat"  \</div><div class="line">                  -output "/user/me/samples/cachefile/out" \  </div><div class="line">                  -cacheArchive 'hdfs://hadoop-nn1.example.com/user/me/samples/cachefile/cachedir.jar#testlink' \  </div><div class="line">                  -jobconf mapred.map.tasks=1 \</div><div class="line">                  -jobconf mapred.reduce.tasks=1 \ </div><div class="line">                  -jobconf mapred.job.name="Experiment"</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> ls test_jar/</span></div><div class="line">cache.txt  cache2.txt</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> jar cvf cachedir.jar -C test_jar/ .</span></div><div class="line">added manifest</div><div class="line">adding: cache.txt(in = 30) (out= 29)(deflated 3%)</div><div class="line">adding: cache2.txt(in = 37) (out= 35)(deflated 5%)</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -put cachedir.jar samples/cachefile</span></div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -cat /user/me/samples/cachefile/input.txt</span></div><div class="line">testlink/cache.txt</div><div class="line">testlink/cache2.txt</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> cat test_jar/cache.txt </span></div><div class="line">This is just the cache string</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> cat test_jar/cache2.txt </span></div><div class="line">This is just the second cache string</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -ls /user/me/samples/cachefile/out      </span></div><div class="line">Found 1 items</div><div class="line">/user/me/samples/cachefile/out/part-00000 </div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -cat /user/me/samples/cachefile/out/part-00000</span></div><div class="line">This is just the cache string   </div><div class="line">This is just the second cache string</div></pre></td></tr></table></figure><blockquote><p>以上的demo可以看出可以帮助我们通过这种途径去预览分发后的hdfs配置文件.</p></blockquote><h3 id="实践校验"><a href="#实践校验" class="headerlink" title="实践校验"></a>实践校验</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line"></div><div class="line">hadoop fs -rmr $&#123;2&#125;</div><div class="line"></div><div class="line">hadoop jar /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/hadoop-streaming-2.6.0-mr1-cdh5.4.0.jar \</div><div class="line">        -files testSymlink.py,hdfs:///user/upsmart/koulb/dict.txt#test \</div><div class="line"><span class="meta">#</span><span class="bash"> -file testSymlink.py \</span></div><div class="line"><span class="meta">#</span><span class="bash"> -cacheFile ,hdfs:///user/upsmart/koulb/dict.txt<span class="comment">#test \</span></span></div><div class="line">        -input $&#123;1&#125; \</div><div class="line">        -output $&#123;2&#125; \</div><div class="line">        -mapper "cat" \</div><div class="line">        -reducer "python testSymlink.py" \</div><div class="line">        -jobconf mapred.reduce.tasks=1 \</div><div class="line">        -jobconf mapred.job.name="testSymlink"</div></pre></td></tr></table></figure><blockquote><p>tips:此处的files等价于file + cacheFile,其实官网有很长一段时间的版本已经在推崇这样的做法,但是还是在兼容这样的模式用法,file用来上传分发本地的文件到集群,cacheFile顾名思义用的是集群上已经现存的资源.<br>-file option is deprecated, please use generic option -files instead.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line"></div><div class="line"><span class="comment"># 打开一个文件</span></div><div class="line"><span class="comment"># 通过软链接去访问配置文件</span></div><div class="line">fo = open(<span class="string">"test"</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"文件名: "</span>, fo.name</div><div class="line"></div><div class="line"><span class="comment"># 遍历文件打印每行的数据</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fo:</div><div class="line">        <span class="keyword">print</span> line.strip()</div><div class="line"></div><div class="line"><span class="comment"># 关闭打开的文件</span></div><div class="line">fo.close()</div></pre></td></tr></table></figure></p></blockquote><h2 id="细节描述"><a href="#细节描述" class="headerlink" title="细节描述"></a>细节描述</h2><h3 id="map使用细节"><a href="#map使用细节" class="headerlink" title="map使用细节"></a>map使用细节</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">-mapper "python testSymlink.py" \</div><div class="line">-jobconf mapred.reduce.tasks=0 \</div></pre></td></tr></table></figure><blockquote><p>看细节:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">JobSubmitter: number of splits:3</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">  配置文件结果输出</span></div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div></pre></td></tr></table></figure><blockquote><p>从上可以看出我们使用的配置文件打印了三次,和我么你的splits个数一致.也就是说和map个数一致.</p></blockquote><h3 id="recude使用细节"><a href="#recude使用细节" class="headerlink" title="recude使用细节"></a>recude使用细节</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">-reducer "python testSymlink.py" \</div><div class="line">-jobconf mapred.reduce.tasks=1 \</div></pre></td></tr></table></figure><blockquote><p>看细节</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 配置文件输出</span></div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div></pre></td></tr></table></figure><blockquote><p>同样可以得出输出的次数和reduce个数完全一致</p></blockquote><h3 id="使用总结"><a href="#使用总结" class="headerlink" title="使用总结"></a>使用总结</h3><blockquote><p>综上可得,完全达到了配置文件分发的目的,可以保证每个map和reduce都可以使用到所需的配置文件.</p><p>tips:<strong>JobSubmitter: number of splits:3</strong>,<br><strong>3</strong>  = <strong>files:2</strong> + <strong>input1</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景描述&quot;&gt;&lt;a href=&quot;#背景描述&quot; class=&quot;headerlink&quot; title=&quot;背景描述&quot;&gt;&lt;/a&gt;背景描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;通常情况下我们在hadoop streaming中通过input来设置我们需要处理的数据,然后逐条遍历打标记,从而在reduce端可以区别对待做聚合或者join操作.但是我们需要用到一些配置文件怎么办?&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="hadoop streaming" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/hadoop-streaming/"/>
    
      <category term="python" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/python/"/>
    
      <category term="cacheFile" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/cacheFile/"/>
    
      <category term="file" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/file/"/>
    
      <category term="files" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/files/"/>
    
  </entry>
  
  <entry>
    <title>chrome 浏览器页面乱码问题</title>
    <link href="https://www.tangyuxiaoyao.club/ITWO/2018/05/09/chrome-%E6%B5%8F%E8%A7%88%E5%99%A8%E9%A1%B5%E9%9D%A2%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/"/>
    <id>https://www.tangyuxiaoyao.club/ITWO/2018/05/09/chrome-浏览器页面乱码问题/</id>
    <published>2018-05-09T01:51:20.000Z</published>
    <updated>2018-05-09T02:16:27.818Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>在做es分词的时候用到了ik分词器要用热分词,要用到一个web容器来搭建在线词库,遇到了以下的问题.<br><a id="more"></a></p><p>建立词库的时候原本打算是在服务器上建立的后来,无法确认它的编码格式,后来在本地用文本建立的词典,同时也另存为了utf-8格式,然后传到了tomcat服务器的ROOT目录下,然后启动在页面预览,但是出现了乱码.</p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><blockquote><p>原本下意识的解决思路是修改tomcat自带的server.xml配置,但是改了以后于事无补,在页面预览还是乱码.<br>后来考虑到是不是浏览器自己的编码格式问题,使用了curl直接访问这个文本静态文件,没有乱码的问题出现,从而定位去修改浏览器的默认格式问题,但是最新版本的chrome浏览器没有提供直接修改默认编码的通道,后来在chrome商店有搜到有以下这款插件可以解决问题.<br>ps:(A Google Chrome extension used to modify the page default encoding for Google Chrome 55+.)<br>55版本以后已经不支持在自定义字体里面修改.<br><a href="https://chrome.google.com/webstore/detail/oenllhgkiiljibhfagbfogdbchhdchml" target="_blank" rel="external">Charset</a></p></blockquote><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>后来发现其实跟server.xml的配置没关系,是不是新版本已经没有该问题了?(apache-tomcat-8.5.31)</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景描述&quot;&gt;&lt;a href=&quot;#背景描述&quot; class=&quot;headerlink&quot; title=&quot;背景描述&quot;&gt;&lt;/a&gt;背景描述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在做es分词的时候用到了ik分词器要用热分词,要用到一个web容器来搭建在线词库,遇到了以下的问题.&lt;br&gt;
    
    </summary>
    
    
      <category term="chrome" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/chrome/"/>
    
      <category term="ubantu" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/ubantu/"/>
    
      <category term="utf-8" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/utf-8/"/>
    
      <category term="tomcat" scheme="https://www.tangyuxiaoyao.club/ITWO/tags/tomcat/"/>
    
  </entry>
  
</feed>
