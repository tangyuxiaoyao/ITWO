<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>利用python seek 实现实时监控vpn多次尝试失败账号</title>
      <link href="/ITWO/2019/06/06/%E5%88%A9%E7%94%A8python-seek-%E5%AE%9E%E7%8E%B0%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7vpn%E5%A4%9A%E6%AC%A1%E5%B0%9D%E8%AF%95%E5%A4%B1%E8%B4%A5%E8%B4%A6%E5%8F%B7/"/>
      <url>/ITWO/2019/06/06/%E5%88%A9%E7%94%A8python-seek-%E5%AE%9E%E7%8E%B0%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7vpn%E5%A4%9A%E6%AC%A1%E5%B0%9D%E8%AF%95%E5%A4%B1%E8%B4%A5%E8%B4%A6%E5%8F%B7/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><ul><li>运维那边有个要求，需要实时监控openvpn账号的登录状况，如果某个账号登录次数过多，需要备案提醒。</li></ul><a id="more"></a><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><ul><li>根据需求，我们需要先分析下vpn客户端和服务器端交互的日志，分析得到哪行的日志数据带有代表性，经分析得到如下的日志具有代表性：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">AUTH-PAM: BACKGROUND: user foo failed to authenticate: Cannot make/remove an entry for the specified session</div></pre></td></tr></table></figure><ul><li>从上面的关键日志我们可以拿到以上登录的账号名，然后把该名称记录下来然后发邮件去提醒就可以了。</li></ul><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><h3 id="shell-实现"><a href="#shell-实现" class="headerlink" title="shell 实现"></a>shell 实现</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tail -100f   /home/koulb/data/a.txt |grep <span class="string">"failed to authenticate"</span>  |awk -F <span class="string">'user'</span> <span class="string">'&#123;print $2&#125;'</span> |cut -d<span class="string">' '</span> -f2</div></pre></td></tr></table></figure><h3 id="python-实现"><a href="#python-实现" class="headerlink" title="python 实现"></a>python 实现</h3><ul><li><p>shell 的实现方式并不能实现实时,tail -f 的方式管道过多,就会失去了原有的实时效能.</p></li><li><p>python 实现脚本如下:</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- encoding: utf8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 用open打开文件</span></div><div class="line"><span class="comment"># 用seek文件指针，跳到文件最后面</span></div><div class="line"><span class="comment"># while True进行循环</span></div><div class="line"><span class="comment"># 持续不停的readline，如果能读到内容，打印出来即可</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tail_one</span><span class="params">(log_file, failed_file, failed_limit)</span>:</span></div><div class="line">    failed_users = &#123;&#125;</div><div class="line">    <span class="keyword">with</span> open(log_file, <span class="string">"r"</span>) <span class="keyword">as</span> r:</div><div class="line">        r.seek(<span class="number">0</span>, <span class="number">2</span>)</div><div class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">            line = r.readline()</div><div class="line">            <span class="keyword">if</span> line:</div><div class="line">                <span class="keyword">if</span> <span class="string">"failed to authenticate"</span> <span class="keyword">in</span> line.strip():</div><div class="line">                    tempDetail = line.split(<span class="string">"user"</span>)</div><div class="line">                    finalDetail = tempDetail[<span class="number">1</span>].split(<span class="string">" "</span>)</div><div class="line">                    failed_user = finalDetail[<span class="number">1</span>]</div><div class="line"></div><div class="line">                    <span class="keyword">if</span> (failed_user <span class="keyword">in</span> failed_users.keys()):</div><div class="line">                        cnt = failed_users[failed_user]</div><div class="line">                        failed_users[failed_user] = cnt + <span class="number">1</span></div><div class="line">                    <span class="keyword">else</span>:</div><div class="line">                        failed_users[failed_user] = <span class="number">1</span></div><div class="line">                    <span class="keyword">for</span> key <span class="keyword">in</span> failed_users.keys():</div><div class="line">                        <span class="keyword">if</span> (failed_users[key] &gt;= failed_limit):</div><div class="line">                            <span class="keyword">with</span> open(failed_file, <span class="string">"a+"</span>) <span class="keyword">as</span> w:</div><div class="line">                                w.write(key + <span class="string">"\n"</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">"usage: python SeekFile.py 要监控的vpn日志 多次尝试登录失败的人员名单文件 失败次数"</span></div><div class="line">        exit(<span class="number">-1</span>)</div><div class="line">    log_file = sys.argv[<span class="number">1</span>]</div><div class="line">    failed_file = sys.argv[<span class="number">2</span>]</div><div class="line">    failed_limit = int(sys.argv[<span class="number">3</span>])</div><div class="line">    <span class="keyword">print</span>   <span class="string">"要监控的vpn日志: "</span> + log_file</div><div class="line">    <span class="keyword">print</span>   <span class="string">"人员名单文件: "</span> + failed_file</div><div class="line">    tail_one(log_file, failed_file, failed_limit)</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>对于python io 的api 了解还不是很透彻,很多东西不能即拿即用,需要进一步加强.</li></ul>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> seek </tag>
            
            <tag> vpn </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hexo yilla 和github 结合搭建个人博客</title>
      <link href="/ITWO/2019/05/29/hexo%20yilia%20github%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/ITWO/2019/05/29/hexo%20yilia%20github%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h1 id="为什么考虑这样的搭配方式"><a href="#为什么考虑这样的搭配方式" class="headerlink" title="为什么考虑这样的搭配方式?"></a>为什么考虑这样的搭配方式?</h1><h2 id="构建需求"><a href="#构建需求" class="headerlink" title="构建需求"></a>构建需求</h2><blockquote><p>现阶段有很多的技术网站都带有给想要展示自己的一些技术入门以及技术研究的平台,也就常见的技术博客.<br>  但是大多都不满足于个性化定制,偶然间接触到markdown,当然简书等这样的平台也支持markdown,但是出于个人的独占情节,还是更倾向于搭建一个独立的自己可控的blog.<br><a id="more"></a></p><h2 id="技术实现-快速搭建"><a href="#技术实现-快速搭建" class="headerlink" title="技术实现(快速搭建)"></a>技术实现(快速搭建)</h2><p>考虑到如果从零开始,买空间,选域名,构建主体框架,渲染静态页面,一套走下来,未免本末倒置,博客注重的应该是文章的可读性以及质量,当然ui需要一定的可观瞻性.幸运的是遇到了hexo,给人一种转角遇到爱的小确幸.<br>      ps:Hexo is a fast, simple &amp; powerful blog framework powered by Node.js.<br>      从官网的解释可以看出,我们需要安装Node.js,当然要和gitbub结合,你需要申请一个github账号,申请账号的步骤,此处就不再累述.<br>      笔者使用的系统是ubantu 16.04</p><p>传送门:<a href="https://github.com/join" target="_blank" rel="external">github账号申请</a></p></blockquote><h3 id="现在演示安装Node-js"><a href="#现在演示安装Node-js" class="headerlink" title="现在演示安装Node.js."></a>现在演示安装Node.js.</h3><blockquote><p>在 Github 上获取 Node.js 源码：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo git <span class="built_in">clone</span> https://github.com/nodejs/node.git</div></pre></td></tr></table></figure><p> 1.修改目录权限：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ sudo chmod -R 755 node</div><div class="line">$ <span class="built_in">cd</span> node</div><div class="line">$ node -v</div></pre></td></tr></table></figure></p><p> 2.使用 ./configure 创建编译文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo ./configure</div></pre></td></tr></table></figure></p><p> 3.这一步，可能时间有点长，耐心等待<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo make</div></pre></td></tr></table></figure></p><p> 4.最后<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo make</div></pre></td></tr></table></figure></p><blockquote><p>install 查看版本</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ node -v</div></pre></td></tr></table></figure><blockquote><p>v0.10.25 如果node不是最新的，node有一个模块叫n，是专门用来管理node.js的版本的。使用npm（NPM是随同nodejs一起安装的包管理工具）安装n模块</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo npm install -g n</div></pre></td></tr></table></figure><blockquote><p>然后，升级node.js到最新稳定版</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo n stable</div></pre></td></tr></table></figure><blockquote><p>旧版本的 npm，也可以很容易地通过 npm 命令来升级，命令如下：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo npm install npm -g</div></pre></td></tr></table></figure><h3 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h3><blockquote><p>执行以下的命令:</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ npm install hexo-cli -g</div><div class="line">$ hexo init blog 此处会新建一个新的目录存储hexo的一些初始化的文件.</div><div class="line">$ <span class="built_in">cd</span> blog</div><div class="line">$ npm install</div><div class="line">$ hexo server 此处会生成一个新的本地预览 访问http://localhost:4000 就可以访问本地的默认主题.</div></pre></td></tr></table></figure><h3 id="新建github仓库"><a href="#新建github仓库" class="headerlink" title="新建github仓库"></a>新建github仓库</h3><blockquote><p>新建一个仓库,然后选择public权限(写博客不就是为了别人看,进而监督自己进步么,所以public),指定git分支,使用默认的master分支即可,因为这个仓库就你一个看门的,这里面也是你的.然后记住自己的clone地址.<br>ps:记得保存.</p></blockquote><h3 id="将gitbub仓库和hexo主题绑定"><a href="#将gitbub仓库和hexo主题绑定" class="headerlink" title="将gitbub仓库和hexo主题绑定"></a>将gitbub仓库和hexo主题绑定</h3><blockquote><p>编辑_config.yml:</p></blockquote><figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">type</span>: git</div><div class="line"><span class="attribute">repo</span>: <span class="attribute">https</span>:<span class="comment">//github.com/tangyuxiaoyao/ITWO.git</span></div><div class="line"><span class="attribute">branch</span>: master</div></pre></td></tr></table></figure><blockquote><p>repo配置的地址为上文已经提及过的项目仓库clone地址.<br>而且这里有看到仓库后面带有子资源路径所以参考配置文件中的注释,需要将root对应的配置改为仓库的名称资源路径.</p></blockquote><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># URL</div><div class="line">## If your site <span class="keyword">is</span> <span class="keyword">put</span> in <span class="keyword">a</span> subdirectory, <span class="keyword">set</span> url <span class="keyword">as</span> <span class="string">'http://yoursite.com/child'</span> <span class="built_in">and</span> root <span class="keyword">as</span> <span class="string">'/child/'</span></div><div class="line">roo<span class="variable">t:</span> /ITWO/</div></pre></td></tr></table></figure><h3 id="发布主题到github仓库"><a href="#发布主题到github仓库" class="headerlink" title="发布主题到github仓库"></a>发布主题到github仓库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">npm install hexo-deployer-git --save</div><div class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</div></pre></td></tr></table></figure><ol><li>安装hexo发布模块deploy</li><li>清除缓存</li><li>生成静态页面</li><li>发布到github(每次改完以后也是这么稳妥发布)<h3 id="生成新的文章"><a href="#生成新的文章" class="headerlink" title="生成新的文章"></a>生成新的文章</h3></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> <span class="built_in">source</span>/_posts/</div><div class="line">$ hexo new <span class="string">"shell在指定行插入文本"</span></div></pre></td></tr></table></figure><blockquote><p>然后就会生成一个为该名称的md文件,根据md语法编辑内容,完成以后发布即可.<br>ps:可以用hexo clean &amp;&amp; hexo g &amp;&amp; hexo s在本地生成预览效果,避免发布到github上的效果不尽人意.</p></blockquote><p><img src="/ITWO/assets/jscy.jpg" alt="古人笑比庭中树,一日秋风一日疏"></p>]]></content>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> yilla </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop HDFS 数据自动平衡</title>
      <link href="/ITWO/2019/05/29/%20Hadoop%20HDFS%20%E6%95%B0%E6%8D%AE%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1/"/>
      <url>/ITWO/2019/05/29/%20Hadoop%20HDFS%20%E6%95%B0%E6%8D%AE%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1/</url>
      <content type="html"><![CDATA[<h2 id="Hadoop-HDFS-数据自动平衡脚本使用方法"><a href="#Hadoop-HDFS-数据自动平衡脚本使用方法" class="headerlink" title="Hadoop HDFS 数据自动平衡脚本使用方法"></a>Hadoop HDFS 数据自动平衡脚本使用方法</h2><blockquote><p>在Hadoop中，包含一个start-balancer.sh脚本，通过运行这个工具，启动HDFS数据均衡服务。该工具可以做到热插拔，即无须重启计算机和 Hadoop 服务。HadoopHome/bin目录下的start−balancer.sh脚本就是该任务的启动脚本。启动命令为：‘HadoopHome/bin目录下的start−balancer.sh脚本就是该任务的启动脚本。启动命令为：‘Hadoop_home/bin/start-balancer.sh –threshold`<br><a id="more"></a></p></blockquote><h2 id="影响Balancer的几个参数："><a href="#影响Balancer的几个参数：" class="headerlink" title="影响Balancer的几个参数："></a>影响Balancer的几个参数：</h2><p>-threshold</p><blockquote><p>默认设置：10，参数取值范围：0-100<br>参数含义：判断集群是否平衡的阈值。理论上，该参数设置的越小，整个集群就越平衡<br>dfs.balance.bandwidthPerSec<br>默认设置：1048576（1M/S）<br>参数含义：Balancer运行时允许占用的带宽<br>示例如下：</p></blockquote><p>#启动数据均衡，默认阈值为 10%<br>$Hadoop_home/bin/start-balancer.sh</p><p>#启动数据均衡，阈值 5%<br>bin/start-balancer.sh –threshold 5</p><p>#停止数据均衡<br>$Hadoop_home/bin/stop-balancer.sh<br>在hdfs-site.xml文件中可以设置数据均衡占用的网络带宽限制</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.balance.bandwidthPerSec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span> Specifies the maximum bandwidth that each datanode can utilize for the balancing purpose in term of the number of bytes per second. <span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> hdfs </tag>
            
            <tag> balancer </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mapreduce 温故</title>
      <link href="/ITWO/2019/05/29/mapredcue%20%E6%B8%A9%E4%B9%A0/"/>
      <url>/ITWO/2019/05/29/mapredcue%20%E6%B8%A9%E4%B9%A0/</url>
      <content type="html"><![CDATA[<h2 id="需求背景："><a href="#需求背景：" class="headerlink" title="需求背景："></a>需求背景：</h2><blockquote><p>做大数据有一段时间了，梳理下用到mapreduce的一些问题和解决方案。<a id="more"></a></p></blockquote><h2 id="mapreduce"><a href="#mapreduce" class="headerlink" title="mapreduce"></a>mapreduce</h2><blockquote><p>mapreduce:顾名思义，map做映射，reduce做规约。<br>主要分以下步骤：<br>1.输入分块<br>2.map<br>3.shuffer<br>4.reduce</p></blockquote><p><img src="/ITWO/assets/mapreduce01.jpg" alt="mapredcue流程图"><br>重点是shuffer阶段</p><h2 id="reduce个数的计算方法"><a href="#reduce个数的计算方法" class="headerlink" title="reduce个数的计算方法:"></a>reduce个数的计算方法:</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">double</span> bytes = Math.max(totalInputFileSize, bytesPerReducer);</div><div class="line"><span class="keyword">int</span> reducers = (<span class="keyword">int</span>) Math.ceil(bytes / bytesPerReducer);</div><div class="line">reducers = Math.max(<span class="number">1</span>, reducers);</div><div class="line">reducers = Math.min(maxReducers, reducers);</div></pre></td></tr></table></figure><blockquote><p>　从计算逻辑可以看出该量由输入文件的大小以及设置的每个reduce可以处理的字节数大小决定．</p></blockquote><p><img src="/ITWO/assets/mapreduce02.png" alt="shuffer流程图"></p><h2 id="流程细节："><a href="#流程细节：" class="headerlink" title="流程细节："></a>流程细节：</h2><h3 id="map输出过程："><a href="#map输出过程：" class="headerlink" title="map输出过程："></a>map输出过程：</h3><blockquote><p>&ensp;&ensp;&ensp;&ensp;如果没有reduce阶段，则直接输出到hdfs上，如果有reduce作业，则每个map方法的输出在写磁盘前先在内存中缓存。每个map task都有一个环状的内存缓冲区，存储着map的输出结果，默认100m，在写磁盘时，根据reduce的数量把数据划分为相应的分区(使用默认的分区算法（对输入文件的kv中对key hash后再对reduce task数量取模(reduce个数的算法见前文)),默认的hashPartioner只会作用默认分隔符分割以后的key，如果需要自定义分区，则需要你自定义二次分区比如keyfieldParttioner来实现,在每个分区中数据进行内排序，分区的个数和reduce的个数是一致的，在每次当缓冲区快满的时候由一个独立的线程将缓冲区的数据以一个溢出文件的方式存放到磁盘(这个溢写是由单独线程来完成，不影响往缓冲区写map结果的线程。溢写线程启动时不应该阻止map的结果输出，所以整个缓冲区有个溢写的比例spill.percent。这个比例默认是0.8，也就是当缓冲区的数据已经达到阈值（buffer size <em> spill percent = 100MB </em> 0.8 = 80MB），溢写线程启动，锁定这80MB的内存，执行溢写过程。Map task的输出结果还可以往剩下的20MB内存中写，互不影响。)，当整个map task结束后再对磁盘中这个map task产生的所有溢出文件做合并，被合并成已分区且已排序的输出文件。然后reduce开始fetch（拉取）map端合并好对应分区的数据，然后在reduce端合并（因为会有很多map的输出，需要合并），此时在reduce端也会进行一次sort,确保所有map的输出都排序并合并成完成以后，才会启动reduce task,所以怎么才能确保你在reduce逻辑处理时拿到的是你要的排序后的数据配合你的处理就至关重要了。</p></blockquote><h3 id="reducer如何知道要从哪个tasktracker取得map输出呢？"><a href="#reducer如何知道要从哪个tasktracker取得map输出呢？" class="headerlink" title="reducer如何知道要从哪个tasktracker取得map输出呢？"></a>reducer如何知道要从哪个tasktracker取得map输出呢？</h3><blockquote><p>&ensp;&ensp;&ensp;&ensp;map任务成功完成以后，他们会通知其父tasktracker状态已更新，然后taskTracker进而通知jobTracker。这些通知在前面的心跳机制中传输。因此，对于指定作业，jobTracker知道map输出和taskTracker之间的映射关系。reducer中的一个线程定期询问jobTracher以便获取map输出的位置,直到它获得所有输出位置。</p></blockquote><h3 id="map和reduce如何合理控制自己的个数？"><a href="#map和reduce如何合理控制自己的个数？" class="headerlink" title="map和reduce如何合理控制自己的个数？"></a>map和reduce如何合理控制自己的个数？</h3><blockquote><p>&ensp;&ensp;&ensp;&ensp;map的个数是由dfs.block.size控制，该配置可以在执行程序之前由参数（见下文）控制，默认配置位于hdfs-site.xml中dfs.block.size控制，1.x的默认配置为64m,2.x的默认配置为128m,</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"> <span class="keyword">long</span> goalSize = totalSize / (numSplits == <span class="number">0</span> ? <span class="number">1</span> : numSplits);</div><div class="line"> <span class="keyword">long</span> minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.</div><div class="line">    FileInputFormat.SPLIT_MINSIZE, <span class="number">1</span>), minSplitSize);</div><div class="line"><span class="keyword">long</span> blockSize = file.getBlockSize();</div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">computeSplitSize</span><span class="params">(<span class="keyword">long</span> goalSize, <span class="keyword">long</span> minSize,</span></span></div><div class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> blockSize)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> Math.max(minSize, Math.min(goalSize, blockSize));</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>&ensp;&ensp;&ensp;&ensp;从上面可以看出，最终的split size是由三个因素决定，goalsize为map输入数据除以用户自己设置的map个数（默认为1）得到的;minsize为mapred-site.xml配置的mapred.min.split.size决定，因为minSplitSize为1;第三个影响因素为blocksize,这个看配置，最终我们可以得出,如果不设置min.size,则由blocksize决定，如果设置了，则是由这两者中大的一个决定。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="built_in">set</span> mapred.min.split.size=256000000;        -- 决定每个map处理的最大的文件大小，单位为B</div><div class="line"></div><div class="line">方法1</div><div class="line"><span class="built_in">set</span> mapred.reduce.tasks=10;  -- 设置reduce的数量</div><div class="line">方法2</div><div class="line"><span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=1073741824 -- 每个reduce处理的数据量,默认1GB</div></pre></td></tr></table></figure><p>block_size : hdfs的文件块大小，默认为64M，可以通过参数dfs.block.size设置<br>total_size : 输入文件整体的大小<br>input_file_num : 输入文件的个数</p><p>（1）默认map个数</p><blockquote><p>如果不进行任何设置，默认的map个数是和blcok_size相关的。<br>   default_num = total_size / block_size;</p></blockquote><p>（2）期望大小</p><blockquote><p>可以通过参数mapred.map.tasks来设置程序员期望的map个数，但是这个个数只有在大于default_num的时候，才会生效。<br>   goal_num = mapred.map.tasks;</p></blockquote><p>（3）设置处理的文件大小</p><blockquote><p>可以通过mapred.min.split.size 设置每个task处理的文件大小，但是这个大小只有在大于block_size的时候才会生效。<br>   split_size = max(mapred.min.split.size, block_size);<br>   split_num = total_size / split_size;</p></blockquote><p>（4）计算的map个数</p><blockquote><p>compute_map_num = min(split_num,  max(default_num, goal_num))</p><p>&ensp;&ensp;&ensp;&ensp;除了这些配置以外，mapreduce还要遵循一些原则。 mapreduce的每一个map处理的数据是不能跨越文件的，也就是说min_map_num &gt;= input_file_num。 所以，最终的map个数应该为：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">final_map_num = max(compute_map_num, input_file_num)</div></pre></td></tr></table></figure><blockquote><p>经过以上的分析，在设置map个数的时候，可以简单的总结为以下几点：<br>（1）如果想增加map个数，则设置mapred.max.split.size为一个较小的值。<br>（2）如果想减小map个数，则设置mapred.min.split.size 为一个较大的值。</p></blockquote><p>reduce个数的设置则相对简单，要么你设置mapred.reduce.tasks的数值，要么你在hive中可以设置每个reduce可以处理的字节数，从而约束reduce的个数。</p><blockquote><p>小技巧</p></blockquote><p>&ensp;&ensp;&ensp;&ensp;在hive中带空的设置参数可以打印出当前该参数的设置值。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hive&gt; set dfs.block.size;</div><div class="line">dfs.block.size=268435456</div><div class="line">hive&gt; set mapred.map.tasks;</div><div class="line">mapred.map.tasks=2</div></pre></td></tr></table></figure><h2 id="mapreduce进度说明"><a href="#mapreduce进度说明" class="headerlink" title="mapreduce进度说明"></a>mapreduce进度说明</h2><h3 id="1-Prepare"><a href="#1-Prepare" class="headerlink" title="1. Prepare"></a>1. Prepare</h3><blockquote><p>准备数据，抓取Map过来的输出（进度：0~33%）</p></blockquote><h3 id="2-Sort"><a href="#2-Sort" class="headerlink" title="2. Sort"></a>2. Sort</h3><blockquote><p>排序阶段（进度：33%~66%）</p></blockquote><h3 id="3-Reduce"><a href="#3-Reduce" class="headerlink" title="3. Reduce"></a>3. Reduce</h3><blockquote><p>真正的reduce计算阶段，执行你所写的reduce代码（进度：66%~100%）.<br>如果前面66%速度很快，后面慢的话就是reduce部分没有写好；否则才是数据量大的问题。</p></blockquote><h2 id="hadoop-yarn-配置的图解"><a href="#hadoop-yarn-配置的图解" class="headerlink" title="hadoop yarn 配置的图解"></a>hadoop yarn 配置的图解</h2><p><img src="/ITWO/assets/hadoop 2.0 yarn 配置项.png" alt="hadoop yarn 配置的图解"></p><h3 id="AM的内存使用错误"><a href="#AM的内存使用错误" class="headerlink" title="AM的内存使用错误"></a>AM的内存使用错误</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Diagnostics: Container [pid=<span class="number">21387</span>,containerID=container_e33_1532170420957_0001_02_000001] is running beyond physical memory limits. </div><div class="line">Current usage: <span class="number">1.1</span> GB of <span class="number">1</span> GB physical memory used; <span class="number">2.7</span> GB of <span class="number">2.1</span> GB virtual memory used. Killing container.</div><div class="line">Dump of the process-tree <span class="keyword">for</span> container_e33_1532170420957_0001_02_000001 :</div><div class="line">        |- <span class="function">PID PPID PGRPID SESSID CMD_NAME <span class="title">USER_MODE_TIME</span><span class="params">(MILLIS)</span> <span class="title">SYSTEM_TIME</span><span class="params">(MILLIS)</span> <span class="title">VMEM_USAGE</span><span class="params">(BYTES)</span> <span class="title">RSSMEM_USAGE</span><span class="params">(PAGES)</span> FULL_CMD_LINE</span></div><div class="line"><span class="function">        |- 21399 21387 21387 21387 <span class="params">(java)</span> 14478 467 2856710144 281207 /usr/lib/jvm/java-8-oracle/bin/java </span></div><div class="line"><span class="function">-Dlog4j.configuration</span>=container-log4j.properties </div><div class="line">-Dyarn.app.container.log.dir=/data/dev/sdb1/yarn/container-logs/application_1532170420957_0001/container_e33_1532170420957_0001_02_000001 </div><div class="line">-Dyarn.app.container.log.filesize=<span class="number">0</span> -Dhadoop.root.logger=INFO,CLA </div><div class="line">-Dhadoop.root.logfile=syslog </div><div class="line">-Djava.net.preferIPv4Stack=<span class="keyword">true</span> -Xmx825955249 org.apache.hadoop.mapreduce.v2.app.MRAppMaster</div></pre></td></tr></table></figure><blockquote><p>仔细预览以上的错误可以定位到以下的信息</p></blockquote><ol><li>AppMaster报出的错误</li><li>-Xmx825955249 设置了运行的参数值</li></ol><blockquote><p>结合图示我们找下应该去集群找那些配置来定位问题</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">上限参数:yarn.app.mapreduce.am.resource.mb</div><div class="line">运行参数:yarn.app.mapreduce.am.command-opts</div></pre></td></tr></table></figure><blockquote><p>以上的这两参数肯定少不了，后来从集群中的确也定位到的确是是yarn.app.mapreduce.am.resource.mb该参数差的设定过小为1G，同时yarn.app.mapreduce.am.command-opts为报错中的展示信息，需要更改，因为这两项更改的都是yarn-site.xml中的配置，cdh中改完之后保存分发这些信息，然后重启集群。</p></blockquote><table><thead><tr><th>配置文件</th><th>配置项</th><th>设置值</th></tr></thead><tbody><tr><td>yarn-site.xml</td><td>yarn.nodemanager.resource.memory-mb</td><td>Container数量 * 每个Container的内存大小</td></tr><tr><td>yarn-site.xml</td><td>yarn.scheduler.minimum-allocation-mb</td><td>每个Container的内存大小</td></tr><tr><td>yarn-site.xml</td><td>yarn.scheduler.maximum-allocation-mb</td><td>Container数量 * 每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.map.memory.mb</td><td>每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.reduce.memory.mb</td><td>2 * 每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.map.java.opts</td><td>0.8 * 每个Container的内存大小</td></tr><tr><td>mapred-site.xml</td><td>mapreduce.reduce.java.opts</td><td>0.8 <em> 2 </em> 每个Container的内存大小</td></tr><tr><td>yarn-site.xml (check)</td><td>yarn.app.mapreduce.am.resource.mb</td><td>2 * 每个Container的内存大小</td></tr><tr><td>yarn-site.xml (check)</td><td>yarn.app.mapreduce.am.command-opts</td><td>0.8 <em> 2 </em> 每个Container的内存大小</td></tr></tbody></table><blockquote><p>以上为各配置的位置以及建议的设置值。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">例如：</div><div class="line">集群的节点有 12 CPU cores, 48 GB RAM, and 12 磁盘.</div><div class="line">预留内存= 6 GB 系统预留 + 8 GB HBase预留</div><div class="line">最小Container内存大小 = 2 GB</div><div class="line"></div><div class="line">如果不安装 HBase:</div><div class="line"><span class="meta">#</span><span class="bash">Container数 = min (2*12, 1.8* 12, (48-6)/2) = min (24, 21.6, 21) = 21</span></div><div class="line">每个Container的内存大小 = max (2, (48-6)/21) = max (2, 2) = 2</div><div class="line"></div><div class="line">如果安装 Hbase：</div><div class="line"><span class="meta">#</span><span class="bash">Container数 = min (2*12, 1.8* 12, (48-6-8)/2) = min (24, 21.6, 17) = 17</span></div><div class="line">每个Container的内存大小 = max (2, (48-6-8)/17) = max (2, 2) = 2</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> mapreduce </tag>
            
            <tag> shuffer </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>线上mongo查询过慢排查总结</title>
      <link href="/ITWO/2019/05/29/%E7%BA%BF%E4%B8%8Amongo%E6%9F%A5%E8%AF%A2%E8%BF%87%E6%85%A2%E6%8E%92%E6%9F%A5%E6%80%BB%E7%BB%93/"/>
      <url>/ITWO/2019/05/29/%E7%BA%BF%E4%B8%8Amongo%E6%9F%A5%E8%AF%A2%E8%BF%87%E6%85%A2%E6%8E%92%E6%9F%A5%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="现象描述"><a href="#现象描述" class="headerlink" title="现象描述"></a>现象描述</h2><blockquote><p>日志监控系统提示mongo查询耗时过长，提示信息如下</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">【app】银联智惠监控中心</div><div class="line">项目: goblin#01-&gt;mongo</div><div class="line">主机: lrma02</div><div class="line">时间: 2019-02-27 15:30:00</div><div class="line">详情: mongo响应时间超过阈值,1分钟内响应时间超过1000ms占比大于10.0%,当前占比:12.20%,总请求次数:164</div></pre></td></tr></table></figure><a id="more"></a><h2 id="排查思路"><a href="#排查思路" class="headerlink" title="排查思路"></a>排查思路</h2><blockquote><p>针对以上提示，可以定位到中间件为mongo，相关人员第一时间要通知到运维查看mongo的操作日志，从而在后台定位到查询耗时过长的是那张表以及查询条件是什么？日志表象如下:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="number">2019</span>-<span class="number">02</span>-<span class="number">27</span>T15:<span class="number">21</span>:<span class="number">07.038</span>+<span class="number">0800</span> I COMMAND  [conn25570] command clearing.fee_detail command: find &#123; find: <span class="string">"fee_detail"</span>, filter: &#123; account: <span class="string">"F1130004"</span>, interfacePath: <span class="string">"/index/personal"</span>, smartOrderId: <span class="string">"91dce17a-bd66-4eeb-959c-57f961802a72"</span> &#125;, limit: <span class="number">1</span>, singleBatch: <span class="keyword">true</span> &#125; planSummary: IXSCAN &#123; account: <span class="number">1</span>, interface_path: <span class="number">1</span>, batch: <span class="number">1</span> &#125; keysExamined:<span class="number">351130</span> docsExamined:<span class="number">351130</span> cursorExhausted:<span class="number">1</span> numYields:<span class="number">2750</span> nreturned:<span class="number">0</span> reslen:<span class="number">107</span> locks:&#123; Global: &#123; acquireCount: &#123; r: <span class="number">5502</span> &#125; &#125;, Database: &#123; acquireCount: &#123; r: <span class="number">2751</span> &#125; &#125;, Collection: &#123; acquireCount: &#123; r: <span class="number">2751</span> &#125; &#125; &#125; protocol:op_query <span class="number">1750</span>ms</div></pre></td></tr></table></figure><blockquote><p>从操作日志可定位到表名:fee_detail,查询的条件涉及到的字段: { account: “F1130004”, interfacePath: “/index/personal”, smartOrderId: “91dce17a-bd66-4eeb-959c-57f961802a72” },接下来需要做的就是使用该条件去查询该表并打印它的执行计划，在执行计划中查看<br>命令: db.table.find({ account: “F1130004”, interfacePath: “/index/personal”, smartOrderId: “91dce17a-bd66-4eeb-959c-57f961802a72” }).explain()</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"> db.table.find(&#123;"col":"CYHS1301942"&#125;).explain()</div><div class="line">&#123;</div><div class="line">    "queryPlanner" : &#123;</div><div class="line">        "plannerVersion" : 1,</div><div class="line">        "namespace" : "db.table",    #集合</div><div class="line">        "indexFilterSet" : false,</div><div class="line">        "parsedQuery" : &#123;</div><div class="line">            "b" : &#123;</div><div class="line">                "$eq" : "CYHS1301942"</div><div class="line">            &#125;</div><div class="line">        &#125;,</div><div class="line">        "winningPlan" : &#123;</div><div class="line">            "stage" : "FETCH",</div><div class="line">            "inputStage" : &#123;</div><div class="line">                "stage" : "IXSCAN",     #索引扫描，COLLSCAN表示全表扫描。</div><div class="line">                "keyPattern" : &#123;</div><div class="line">                    "account" : 1,</div><div class="line">                    "interfacePath" : 1</div><div class="line">"smartOrderId" : 1</div><div class="line">                &#125;,</div><div class="line">                "indexName" : "account_1_interfacePath_1_smartOrderId_1", #索引名</div><div class="line">                "isMultiKey" : false,</div><div class="line">                "direction" : "forward",</div><div class="line">                "indexBounds" : &#123;</div><div class="line">                    "account" : [</div><div class="line">                        "[\"CYHS1301942\", \"CYHS1301942\"]"</div><div class="line">                    ],</div><div class="line">                    "interfacePath" : [</div><div class="line">                        "[MinKey, MaxKey]"</div><div class="line">                    ],</div><div class="line">"smartOrderId" : [</div><div class="line"> "[\"91dce17a-bd66-4eeb-959c-57f961802a72\", \"91dce17a-bd66-4eeb-959c-57f961802a73\"]"</div><div class="line">]</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;,</div><div class="line">        "rejectedPlans" : [ ]</div><div class="line">    &#125;,</div><div class="line">    "serverInfo" : &#123;</div><div class="line">        "host" : "mongo1",</div><div class="line">        "port" : 27017,</div><div class="line">        "version" : "3.0.4",</div><div class="line">        "gitVersion" : "0481c958daeb2969800511e7475dc66986fa9ed5"</div><div class="line">    &#125;,</div><div class="line">    "ok" : 1</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>从执行计划中从”stage” : “IXSCAN”该步骤中keyPattern可以看出具体使用的索引内容从而定位到用的复合索引是不是传输所用的索引。下午发现的问题是因为使用的索引并非建立的索引导致的查询缓慢。</p><p>也可以使用查看所有索引的方式来直接定位是不是所用到的索引存在</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">  db.fee_detail.getIndexes()</div><div class="line">[</div><div class="line">     &#123;</div><div class="line">         "v" : 2,</div><div class="line">         "key" : &#123;</div><div class="line">             "_id" : 1</div><div class="line">         &#125;,</div><div class="line">         "name" : "_id_",</div><div class="line">         "ns" : "clearing.fee_detail"</div><div class="line">     &#125;,</div><div class="line">     &#123;</div><div class="line">         "v" : 2,</div><div class="line">         "key" : &#123;</div><div class="line">             "account" : 1,</div><div class="line">             "interface_path" : 1,</div><div class="line">             "batch" : 1</div><div class="line">         &#125;,</div><div class="line">         "name" : "account_path_batch_index",</div><div class="line">         "ns" : "clearing.fee_detail"</div><div class="line">     &#125;,</div><div class="line">     &#123;</div><div class="line">         "v" : 2,</div><div class="line">         "key" : &#123;</div><div class="line">             "createDate" : 1</div><div class="line">         &#125;,</div><div class="line">         "name" : "createDate_expire_index",</div><div class="line">         "ns" : "clearing.fee_detail",</div><div class="line">         "expireAfterSeconds" : NumberLong(31536000)</div><div class="line">     &#125;</div><div class="line">]</div></pre></td></tr></table></figure><blockquote><p>从上可以看出并没有找到要用到的索引。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>定位到问题之后根据查询条件以及业务需要手动地在该表中给该三个字段添加索引。然后观察日志，查询缓慢的问题得到解决。</p><ul><li>添加索引的脚本</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.fee_detail.ensureIndex(&#123;account: 1, interface_path: 1, smartOrderId:1&#125;);</div></pre></td></tr></table></figure><h2 id="方案优化"><a href="#方案优化" class="headerlink" title="方案优化"></a>方案优化</h2><ul><li>待考量的三种方案</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1.account,interface_path,smartOrderId;account,interface_path,batch 两个复合索引</div><div class="line">2.account,interface_path;batch;smartOrderId 三个索引</div><div class="line">3.account;interface_path 两个索引</div></pre></td></tr></table></figure><h2 id="方案跟踪"><a href="#方案跟踪" class="headerlink" title="方案跟踪"></a>方案跟踪</h2><ul><li>方案一:</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.fee_detail.ensureIndex(&#123;account: 1, interface_path: 1, smartOrderId:1&#125;);</div><div class="line">db.fee_detail.ensureIndex(&#123;account: 1, interface_path: 1, batch:1&#125;);</div></pre></td></tr></table></figure><ul><li>方案二</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">db.fee_detail.ensureIndex(&#123;account: 1, interface_path: 1&#125;);</div><div class="line">db.fee_detail.ensureIndex(&#123;batch:1&#125;);</div><div class="line">db.fee_detail.ensureIndex(&#123;smartOrderId:1&#125;);</div></pre></td></tr></table></figure><ul><li>方案三：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.fee_detail.ensureIndex(&#123;account:1&#125;);</div><div class="line">db.fee_detail.ensureIndex(&#123;interface_path:1&#125;);</div></pre></td></tr></table></figure><ul><li>测试步骤</li></ul><hr><ol><li>准备mongo存量数据,分别100W,500W,1000W。</li><li>并发请求接口，造４要素的数据确保４要素不会重复，这样每次都会调用第三方不走缓存＝＞每次都会insert和update mongo库。</li><li>获取系统的日志记录的插入mongo库和更新mongo库的时间解析，计算插入和更新mongo库的平均响应时间。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">        　　com.unionpaysmart.goblin.service.MongoService[<span class="number">83</span>]:middleware_opt|mongo|<span class="number">5573</span>|success|插入mongo 成功日志=&gt;<span class="number">5573</span></div></pre></td></tr></table></figure><hr><ul><li>比较结果见下图</li></ul><p><img src="/ITWO/assets/mongo-data.png" alt="mongo 执行比较"></p><h2 id="进一步跟踪"><a href="#进一步跟踪" class="headerlink" title="进一步跟踪"></a>进一步跟踪</h2><blockquote><p>既然第二种和第三种查询速率不分伯仲，望再帮忙看下，这两种分别建立的索引占的空间大小。<br>命令如下:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.sys_request_info.stats(1024*1024)</div><div class="line">查看totalIndexSize的大小 单位是M</div></pre></td></tr></table></figure><ul><li>结果如下:</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">２种方案创建的索引大小如下，请参考：</div><div class="line"></div><div class="line">方案一:</div><div class="line">db.fee_detail.ensureIndex(&#123;account: 1, interface_path: 1, smartOrderId:1&#125;);</div><div class="line">db.fee_detail.ensureIndex(&#123;account: 1, interface_path: 1, batch:1&#125;);</div><div class="line"><span class="meta">PRIMARY&gt;</span><span class="bash">  db.fee_detail.stats(1024*1024)</span></div><div class="line">&#123;</div><div class="line">"totalIndexSize" : 2100,</div><div class="line">"indexSizes" : &#123;</div><div class="line">"_id_" : 573,</div><div class="line">"createDate_expire_index" : 492,</div><div class="line">"account_1_interface_path_1_smartOrderId_1" : 648,</div><div class="line">"account_1_interface_path_1_batch_1" : 386</div><div class="line">&#125;,</div><div class="line">"ok" : 1</div><div class="line">&#125;</div><div class="line"></div><div class="line">方案二:</div><div class="line">db.fee_detail.ensureIndex(&#123;account: 1, interface_path: 1&#125;);</div><div class="line">db.fee_detail.ensureIndex(&#123;batch:1&#125;);</div><div class="line">db.fee_detail.ensureIndex(&#123;smartOrderId:1&#125;);</div><div class="line"><span class="meta">PRIMARY&gt;</span><span class="bash">  db.fee_detail.stats(1024*1024)</span></div><div class="line">&#123;</div><div class="line">"totalIndexSize" : 2145,</div><div class="line">"indexSizes" : &#123;</div><div class="line">"_id_" : 573,</div><div class="line">"createDate_expire_index" : 492,</div><div class="line">"account_1_interface_path_1" : 267,</div><div class="line">"batch_1" : 277,</div><div class="line">"smartOrderId_1" : 535</div><div class="line">&#125;,</div><div class="line">"ok" : 1</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> mongo </tag>
            
            <tag> explain </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>通过shell来实现任务状态汇报</title>
      <link href="/ITWO/2019/05/29/%E9%80%9A%E8%BF%87shell%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%BB%BB%E5%8A%A1%E7%8A%B6%E6%80%81%E6%B1%87%E6%8A%A5/"/>
      <url>/ITWO/2019/05/29/%E9%80%9A%E8%BF%87shell%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%BB%BB%E5%8A%A1%E7%8A%B6%E6%80%81%E6%B1%87%E6%8A%A5/</url>
      <content type="html"><![CDATA[<h2 id="业务背景"><a href="#业务背景" class="headerlink" title="业务背景"></a>业务背景</h2><blockquote><p>三台机器负责接受分发的数据然后运行各自的逻辑，完成之后发送信号给主节点，然后继续后续的数据分发以及跑批任务。</p></blockquote><a id="more"></a><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><blockquote><p>如果是传统的java/python程序去处理的话可以考虑到和zookeeper结合利用zk的心跳机制完成任务的定时上报和任务完成信号的汇报，shell的话怎么办？</p></blockquote><ul><li>思路：在主节点配置一个监听服务器等待接受任务节点的信号，并定时轮训接受信号的文件当第一批次的任务信号接受完成，置空该信号文件并继续分发下一次批次数据给任务节点，依次类推。</li></ul><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/usr/bin/env bash</span></div><div class="line"></div><div class="line"></div><div class="line">master:</div><div class="line">nohup  nc -l -k 10000 &gt;signalFile &amp;</div><div class="line"></div><div class="line"><span class="function"><span class="title">monitorDataNode</span></span>()&#123;</div><div class="line">  susseedCnt=`grep <span class="variable">$1</span> signalFile |wc -l`</div><div class="line">  <span class="built_in">return</span> susseedCnt</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">hive -f get_inner.sql</div><div class="line"><span class="keyword">if</span> [ $? != 0 ];</div><div class="line"><span class="keyword">then</span></div><div class="line"><span class="built_in">echo</span> <span class="string">"get_inner failed"</span></div><div class="line"><span class="built_in">exit</span> 2</div><div class="line"><span class="keyword">else</span></div><div class="line"><span class="built_in">echo</span> <span class="string">"get_inner succeed"</span></div><div class="line">  hive -f stanard_inner.sh</div><div class="line">  <span class="keyword">if</span> [ $? != 0 ];</div><div class="line">  <span class="keyword">then</span></div><div class="line">  <span class="built_in">echo</span> <span class="string">"stanard_inner failed"</span></div><div class="line">  <span class="built_in">exit</span> 2</div><div class="line">  <span class="keyword">else</span></div><div class="line">  <span class="built_in">echo</span> <span class="string">"stanard_inner succeed"</span></div><div class="line">    hive -f merge_inner.sql &amp;&amp; bash  deal_out.sh</div><div class="line">    <span class="keyword">if</span> [ $? != 0 ];</div><div class="line">      <span class="keyword">then</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"merge_inner &amp;&amp; deal_out failed"</span></div><div class="line">          <span class="built_in">exit</span> 2</div><div class="line">    <span class="keyword">else</span></div><div class="line">      <span class="built_in">echo</span> <span class="string">"merge_inner &amp;&amp; deal_out succeed"</span></div><div class="line">      monitorDataNode 0_do_get</div><div class="line">      <span class="keyword">if</span> [ $? == 3 ];</div><div class="line">        <span class="keyword">then</span></div><div class="line">          <span class="built_in">echo</span> <span class="string">'0_do_get succeed'</span></div><div class="line">          bash  1_do_reindex.sh</div><div class="line">          .</div><div class="line">          .</div><div class="line">          .</div><div class="line">      <span class="keyword">else</span></div><div class="line">        monitorDataNode 0_do_get</div><div class="line">      <span class="keyword">fi</span></div><div class="line">    <span class="keyword">fi</span></div><div class="line">  <span class="keyword">fi</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">dataNode:</div><div class="line"></div><div class="line">bash  0_do_get.sh</div><div class="line"><span class="keyword">if</span> [ $? != 0 ];</div><div class="line">     <span class="keyword">then</span></div><div class="line">         <span class="built_in">echo</span> <span class="string">"0_do_get failed"</span></div><div class="line">          <span class="built_in">exit</span> 2</div><div class="line"><span class="keyword">else</span></div><div class="line">   <span class="built_in">echo</span> <span class="string">"0_do_get succeed"</span> |  netcat master 10000</div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> netcat </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker use</title>
      <link href="/ITWO/2019/01/15/docker-use/"/>
      <url>/ITWO/2019/01/15/docker-use/</url>
      <content type="html"><![CDATA[<hr><p>docker的使用总结</p><hr><a id="more"></a><ul><li>指定镜像启动容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">docker run -P tomcat //随机端口访问 将tomcat容器的8080端口映射到宿主机的随机端口</div><div class="line">docker run -p 80:8080 tomcat //指定端口访问 将tomcat容器的8080端口映射到宿主机的80端口</div></pre></td></tr></table></figure><ul><li>编辑正在访问的容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker exec -it CONTAINER ID bash //进入容器的命令行式交互式界面</div></pre></td></tr></table></figure><ul><li>停止正在运行的容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">docker kill cid/cname</div><div class="line">docker stop cid/cname</div></pre></td></tr></table></figure><ul><li>继承并定制化自己风格的容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">mkdir empty</div><div class="line">cd empty</div><div class="line">vi Dockerfile</div><div class="line">FROM tomcat</div><div class="line">RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/local/tomcat/webapps/ROOT/index.jsp</div><div class="line"></div><div class="line">docker build -t tomcat:hello .</div><div class="line"></div><div class="line">~/docker/testDocker$ docker images</div><div class="line">REPOSITORY   TAG                 IMAGE ID            CREATED              SIZE</div><div class="line">tomcat       hello               a5ed8e716cce        About a minute ago   462MB</div></pre></td></tr></table></figure><ul><li>本地文件打包部署到容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">TODO</div></pre></td></tr></table></figure><ul><li>清除掉归档状态的容器(status=Exited)</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">docker container prune //删除全部</div><div class="line">docker rm cid/cname //删除指定的容器</div></pre></td></tr></table></figure><ul><li>使用数据卷实现宿主项目挂载到容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -p 8081:8080  -v /home/user/docker/testDocker/vtest:/usr/local/tomcat/webapps/ROOT --name tomcat2 -d tomcat</div></pre></td></tr></table></figure><ul><li>部署mysql指定版本容器</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">docker run -p 3306:3306 --name mysql \</div><div class="line">-v $PWD/conf:/etc/mysql/conf.d \</div><div class="line">-v $PWD/logs:/logs \</div><div class="line">-v $PWD/data:/var/lib/mysql \</div><div class="line">-e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7.22</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数据特殊join</title>
      <link href="/ITWO/2019/01/03/%E6%95%B0%E6%8D%AE%E7%89%B9%E6%AE%8Ajoin/"/>
      <url>/ITWO/2019/01/03/%E6%95%B0%E6%8D%AE%E7%89%B9%E6%AE%8Ajoin/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>有两份计费数据一份是测试账号的，一份是正式账号，现计费策略如下：</p></blockquote><ul><li>测试账号调用过的key如果在正式账号调用记录中出现:<ol><li>测试账号调用该key的次数大于等于正式账号，则计费次数为测试出现的次数减去正式账号出现该key的次数。</li><li>测试账号调用该key的次数如果小于正式账号，则计费次数为正式账号调用的次数。</li></ol></li><li>测试账号和正式账号的没有重复的则分别计费即可。</li></ul><a id="more"></a><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ul><li>相同部分不好计费，需要特殊计费通过Python来实现。</li><li>不同部分通过awk追加到一个文件中，然后使用sort|uniq -c 来统计词频即可。（此处不能使用comm，使用该命令一定要先排序去重，那计费数据不就丢了？）</li></ul><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">step1:compute the key cnt with tag</div><div class="line"></div><div class="line">sort Tcard &gt; s_tcard</div><div class="line">sort Fcard &gt; s_fcard</div><div class="line"></div><div class="line">cat s_tcard|uniq -c |awk -F' ' '&#123;print $2"\tT_"$1&#125;' &gt;tag_tcard</div><div class="line">cat s_fcard|uniq -c |awk -F' ' '&#123;print $2"\tF_"$1&#125;' &gt;tag_Fcard</div><div class="line"></div><div class="line"></div><div class="line">step2: handle the common part</div><div class="line"></div><div class="line">sort tag* |python handleCnt.py &gt;common.tsv</div><div class="line"></div><div class="line"></div><div class="line">step3:handle the diff part</div><div class="line"></div><div class="line"></div><div class="line">awk  'NR==FNR&#123;a[$0]&#125;NR&gt;FNR&#123; if(!($1 in a)) print $0&#125;' s_tcard s_fcard &gt;diff_temp</div><div class="line">awk  'NR==FNR&#123;a[$0]&#125;NR&gt;FNR&#123; if(!($1 in a)) print $0&#125;' s_fcard s_tcard &gt;&gt; diff_temp</div><div class="line"></div><div class="line"></div><div class="line">sort diff_temp |uniq -c |awk -F' ' '&#123;print $2"\t"$1&#125;' &gt;diff.tsv</div><div class="line"></div><div class="line"></div><div class="line">step4:cat comm and diff to final.tsv</div><div class="line"></div><div class="line">cat common.tsv diff.tsv &gt;final.tsv</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># vim: set fileencoding=utf-8</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator = <span class="string">'\t'</span>)</span>:</span></div><div class="line">    initDict = &#123;&#125;</div><div class="line">    card = <span class="keyword">None</span></div><div class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> sys.stdin:</div><div class="line">        detail = data.strip().split(separator)</div><div class="line">        <span class="keyword">if</span>(detail[<span class="number">1</span>].startswith(<span class="string">"F"</span>)):</div><div class="line">            card = detail[<span class="number">0</span>]</div><div class="line">            cnt = detail[<span class="number">1</span>].split(<span class="string">"_"</span>)[<span class="number">1</span>]</div><div class="line">            initDict[card] = cnt</div><div class="line">        <span class="keyword">elif</span>(detail[<span class="number">0</span>] <span class="keyword">in</span>  initDict.keys() <span class="keyword">and</span> detail[<span class="number">1</span>].startswith(<span class="string">"T_"</span>)):</div><div class="line">            cnt =  detail[<span class="number">1</span>].split(<span class="string">"_"</span>,<span class="number">1</span>)[<span class="number">1</span>]</div><div class="line">            <span class="keyword">if</span>(initDict[card]&gt;=cnt):</div><div class="line">                <span class="keyword">print</span> card+separator+initDict[card]</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="keyword">print</span> card+separator+str(int(cnt)-int(initDict[card]))</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> python </tag>
            
            <tag> comm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python中-1的妙用</title>
      <link href="/ITWO/2018/11/12/python%E4%B8%AD-1%E7%9A%84%E5%A6%99%E7%94%A8/"/>
      <url>/ITWO/2018/11/12/python%E4%B8%AD-1%E7%9A%84%E5%A6%99%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>在浏览HadoopStreaming官网时，有看到如下的用法也可以实现截取一行的数据。</p></blockquote><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateLongCountToken</span><span class="params">(id)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="string">"LongValueSum:"</span> + id + <span class="string">"\t"</span> + <span class="string">"1"</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv)</span>:</span></div><div class="line">    line = sys.stdin.readline();</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        <span class="keyword">while</span> line:</div><div class="line">            line = line[:<span class="number">-1</span>];</div><div class="line">            fields = line.split(<span class="string">"\t"</span>);</div><div class="line">            <span class="keyword">print</span> generateLongCountToken(fields[<span class="number">0</span>]);</div><div class="line">            line = sys.stdin.readline();</div><div class="line">    <span class="keyword">except</span> <span class="string">"end of file"</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">     main(sys.argv)</div></pre></td></tr></table></figure><h2 id="调研过程"><a href="#调研过程" class="headerlink" title="调研过程"></a>调研过程</h2><blockquote><p>很好奇这样的用法作用与字符串会有什么效果，就有了如下的调研。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line"><span class="keyword">print</span> line</div><div class="line"><span class="keyword">print</span> line[:<span class="number">-1</span>]</div><div class="line"><span class="keyword">print</span> line.strip()</div><div class="line"></div><div class="line">a = <span class="string">'   '</span></div><div class="line"><span class="keyword">print</span> len(a)</div><div class="line"><span class="keyword">print</span> len(a[:<span class="number">-1</span>])</div><div class="line"><span class="keyword">print</span> len(a.strip())</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">main()</div></pre></td></tr></table></figure><ul><li>输出如下：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1,2,3,4</div><div class="line"></div><div class="line">1,2,3,4</div><div class="line">1,2,3,4</div><div class="line">3</div><div class="line">2</div><div class="line">0</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote><p>从上可以得出如下的结论：</p></blockquote><ol><li>-1可以去除数据行后面的换行符或者最后的空格或者tab等单个字符</li><li>但是不可以去除多个空格或者多个无用字符</li><li>此类的场景还是推荐使用strip()来保证万无一失,当然在获得完整的一行的数据的场景,该用法完全够用。</li></ol>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> strip </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 下怎么使用命令制作U盘启动盘</title>
      <link href="/ITWO/2018/10/24/linux-%E4%B8%8B%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E5%88%B6%E4%BD%9CU%E7%9B%98%E5%90%AF%E5%8A%A8%E7%9B%98/"/>
      <url>/ITWO/2018/10/24/linux-%E4%B8%8B%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E5%88%B6%E4%BD%9CU%E7%9B%98%E5%90%AF%E5%8A%A8%E7%9B%98/</url>
      <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>ubantu自带的工具没有响应,后来查到可以使用命令的方式来格式化u盘和制作装机盘.</p></blockquote><a id="more"></a><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">unmout the mount pan</span></div><div class="line">sudo umount /dev/sdb</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">format u pan</span></div><div class="line">sudo mkfs.vfat /dev/sdb –I</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">make u pan to a pan <span class="built_in">which</span> can play as a bootpan</span></div><div class="line">sudo dd if=~/iso/deepin-15.7-amd64.iso of=/dev/sdb</div></pre></td></tr></table></figure>]]></content>
      
      
    </entry>
    
    <entry>
      <title>ssh 免密码登录以及多种用途共存</title>
      <link href="/ITWO/2018/10/12/ssh-%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E4%BB%A5%E5%8F%8A%E5%A4%9A%E7%A7%8D%E7%94%A8%E9%80%94%E5%85%B1%E5%AD%98/"/>
      <url>/ITWO/2018/10/12/ssh-%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E4%BB%A5%E5%8F%8A%E5%A4%9A%E7%A7%8D%E7%94%A8%E9%80%94%E5%85%B1%E5%AD%98/</url>
      <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>在日常使用ssh时,我们有以下几种使用场景</p></blockquote><ol><li>ssh 远程登录远端的机器</li><li>scp 与其他的主机 上传或者下载数据</li><li>ssh 生成邮箱的公钥用于免密拉取git的项目</li></ol><a id="more"></a><h2 id="实现和原理分析"><a href="#实现和原理分析" class="headerlink" title="实现和原理分析"></a>实现和原理分析</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">（1）在HOSTA机器上产生公钥和私钥</div><div class="line">   ssh-keygen -t rsa</div><div class="line">   </div><div class="line">（2）需要将HOSTA机器的公钥复制给HOSTB机器</div><div class="line">  ssh-copy-id -i .ssh/id_rsa.pub root@HOSTB</div></pre></td></tr></table></figure><ul><li>图解</li></ul><p><img src="/ITWO/assets/ssh-rsa.png" alt="详细交互过程"></p><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>既然ssh生成的公钥可以用来这么多用途,那么怎样让用于免密码登录/拷贝的公钥和用来拉取git项目的公钥共存呢?</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> man ssh-add</span></div><div class="line">NAME</div><div class="line">     ssh-add — adds private key identities to the authentication agent</div><div class="line">     ssh-add adds private key identities to the authentication agent, ssh-agent(1).  When run</div><div class="line">     without arguments, it adds the files ~/.ssh/id_rsa, ~/.ssh/id_dsa, ~/.ssh/id_ecdsa,</div><div class="line">     ~/.ssh/id_ed25519 and ~/.ssh/identity.  After loading a private key, ssh-add will try to load</div><div class="line">     corresponding certificate information from the filename obtained by appending -cert.pub to</div><div class="line">     the name of the private key file.  Alternative file names can be given on the command line.</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 从以上的解释可以看出通过该命令可以解决此问题</span></div><div class="line">ssh-add ~/.ssh/*_rsa</div></pre></td></tr></table></figure><ul><li>ssh-add操作<br><img src="/ITWO/assets/ssh-add.png" alt="ssh-add 操作过程"></li></ul><ul><li>过程测试<br><img src="/ITWO/assets/ssh-git.png" alt="ssh-add 操作过程"></li></ul><blockquote><p>ps: 用作一种用途时,生成id_rsa和id_rsa.pub之后记得重命名,然后使用ssh-add添加该密钥.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> git </tag>
            
            <tag> scp </tag>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ubantu unzip或手动解压文件乱码</title>
      <link href="/ITWO/2018/10/08/ubantu-unzip%E6%88%96%E6%89%8B%E5%8A%A8%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/"/>
      <url>/ITWO/2018/10/08/ubantu-unzip%E6%88%96%E6%89%8B%E5%8A%A8%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/</url>
      <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>从云盘下载的zip包中包含中文,解压出来的文件夹和文件均是乱码.<br><img src="/ITWO/assets/unziperror.png" alt="中文乱码"></p></blockquote><a id="more"></a><hr><h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p><img src="/ITWO/assets/ziphelp.png" alt="查看unzip的帮助命令"></p><blockquote><p>得到 -O 可以使用 windows或者dos的编码格式去解压文件.</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">unzip -O GBK 笔记.zip</div></pre></td></tr></table></figure><p><img src="/ITWO/assets/unzipsuccess.png" alt="解压的时候已经没有乱码了"></p>]]></content>
      
      
        <tags>
            
            <tag> ubantu </tag>
            
            <tag> unzip </tag>
            
            <tag> 乱码 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java mr lzo 支持</title>
      <link href="/ITWO/2018/09/13/java-mr-lzo-%E6%94%AF%E6%8C%81/"/>
      <url>/ITWO/2018/09/13/java-mr-lzo-%E6%94%AF%E6%8C%81/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>lzo格式有很大的压缩比,相对于Hdfs文件而言有很大优势,支持分片,默认是不支持splitable的，需要为其添加索引文件，才能支持多个map并行对lzo文件进行处理.先阶段来说为了节约存储空间,lzo格式的文件存储随处可见,所以在mapreduce中怎么读取和存储lzo文件就很有必要了解下.</p></blockquote><a id="more"></a><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>如果希望mr输出的是lzo格式的文件，添加下面的语句</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">FileOutputFormat.setCompressOutput(job, <span class="keyword">true</span>);</div><div class="line">FileOutputFormat.setOutputCompressorClass(job, LzopCodec.class);</div><div class="line"><span class="keyword">int</span> result = job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</div><div class="line"><span class="comment">//上面的语句执行完成后，会生成最后的输出文件，需要在此基础上添加lzo的索引</span></div><div class="line">LzoIndexer lzoIndexer = <span class="keyword">new</span> LzoIndexer(conf);</div><div class="line">lzoIndexer.index(<span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div></pre></td></tr></table></figure><blockquote><p>如果已经存在lzo文件，但没有添加索引，可以采用下面的方法，在输入路径的文件上上添加lzo索引<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop jar $HADOOP_HOME/lib/hadoop-lzo-0.4.17.jar com.hadoop.compression.lzo.LzoIndexer hdf://inputpath</div></pre></td></tr></table></figure></p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> mapreduce </tag>
            
            <tag> java </tag>
            
            <tag> lzo </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>scala 使用遇到的问题</title>
      <link href="/ITWO/2018/09/13/scala-match-%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/ITWO/2018/09/13/scala-match-%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h2 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h2><blockquote><p>在使用spark来跑统计报告任务是,有使用scala,会遇到如下的问题.</p></blockquote><a id="more"></a><p>+用多个开关去控制不同的使用逻辑</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> dimensionCode = args(<span class="number">2</span>).toInt</div><div class="line">dimensionCode <span class="keyword">match</span> &#123;</div><div class="line"> <span class="keyword">case</span> <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getCode =&gt; &#123;</div><div class="line">   println(<span class="string">"正在生成报告的维度为"</span>, <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getDimensions)</div><div class="line">   <span class="comment">//  D0(0, "行业大类,行业小类")</span></div><div class="line"> &#125;</div></pre></td></tr></table></figure><ul><li>报错</li></ul><blockquote><p> 如上的用法会出现以下的错误：</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="type">Error</span>:(<span class="number">38</span>, <span class="number">33</span>) stable identifier required, but <span class="type">D0</span>.getCode found.</div><div class="line">    <span class="keyword">case</span> <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getCode =&gt; &#123;</div></pre></td></tr></table></figure><blockquote><p>必须要使用常量</p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><blockquote><p> 改动成如下的表达式就可以通过：</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">dimensionCode.toString.toInt <span class="keyword">match</span> &#123;</div><div class="line">  <span class="keyword">case</span> dimensionCode <span class="keyword">if</span> <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getCode == dimensionCode =&gt; &#123;</div><div class="line">    println(<span class="string">"正在生成报告的维度为:"</span>, <span class="type">AnalysisDimension</span>.<span class="type">D0</span>.getDimensions)</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> scala </tag>
            
            <tag> match </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java/scala 怎么给可变参数传值</title>
      <link href="/ITWO/2018/09/07/java-scala-%E6%80%8E%E4%B9%88%E7%BB%99%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0%E4%BC%A0%E5%80%BC/"/>
      <url>/ITWO/2018/09/07/java-scala-%E6%80%8E%E4%B9%88%E7%BB%99%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0%E4%BC%A0%E5%80%BC/</url>
      <content type="html"><![CDATA[<h2 id="业务背景"><a href="#业务背景" class="headerlink" title="业务背景"></a>业务背景</h2><blockquote><p>java和scala 分别怎么给可变参数传值?</p></blockquote><a id="more"></a><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><ul><li>java</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">String[] args = <span class="string">"1,2,3"</span>.split(<span class="string">","</span>, -<span class="number">1</span>)</div><div class="line">testString(args);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testString</span><span class="params">(String... args)</span> </span>&#123;</div><div class="line">      <span class="keyword">for</span> (String arg : args) &#123;</div><div class="line">          System.out.println(arg);</div><div class="line">      &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure><ul><li>scala</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> test = <span class="string">"1,2,3,4"</span>.split(<span class="string">","</span>)</div><div class="line"></div><div class="line">  testArgs(test: _*)</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testArgs</span></span>(paths: <span class="type">String</span>*) = &#123;</div><div class="line">  paths.foreach(println(_))</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> scala </tag>
            
            <tag> string* </tag>
            
            <tag> string... </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用elasticSearch 实现商户名称的模糊匹配</title>
      <link href="/ITWO/2018/09/07/%E4%BD%BF%E7%94%A8elasticSearch-%E5%AE%9E%E7%8E%B0%E5%95%86%E6%88%B7%E5%90%8D%E7%A7%B0%E7%9A%84%E6%A8%A1%E7%B3%8A%E5%8C%B9%E9%85%8D/"/>
      <url>/ITWO/2018/09/07/%E4%BD%BF%E7%94%A8elasticSearch-%E5%AE%9E%E7%8E%B0%E5%95%86%E6%88%B7%E5%90%8D%E7%A7%B0%E7%9A%84%E6%A8%A1%E7%B3%8A%E5%8C%B9%E9%85%8D/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>总公司那边不允许输出流水中的刷卡地址,所以应对的方案是允许客户输入商户的关键字然后模糊匹配刷卡地址中是否存在</p></blockquote><a id="more"></a><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><blockquote><p>先从数据量着手选择技术,mysql 通过like来匹配肯定不能满足如此大的数据量,存量数据量来看已经有六千万之多,所以mysql技术不行,而且mysql仅仅是解决了包含的匹配关系,对于关键词和查询词组的相关度支持有限,另一方面考虑到数据的复用行,另一项目中数据已经存于es中.</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>开始之初,选择的是已经做好IK 分词的刷卡地址,但是无论使用wildcardQuery还是fuzzyQuery亦或prefixQuery热词还好,但是出现了冷门词语(是否包含与既定的分词包中),就会出现某个汉字多排名就考前的弊病,而且默认返回十条,这样就限制了包含模糊查询的二次匹配,次路不通.<br>后来鉴于上文提及的已做好分词命中不固定的原因,选择增加一个字段数据导入的时候不做分词(keyword)</p></blockquote><ul><li>知识点<blockquote><p>5.x以上已经没有string类型。如果需要分词的话使用text，不需要分词使用keyword。但是生成索引的时候你会看到后面还有一个关键词:index,默认为true,如果设置为false,该字段将不能被索引,keyword是整个文档被索引,text根据指定的分词器被索引(不指定的话默认的分词器是standard),<br>keyword,index:true=&gt;doc被每个term切词并与doc建立索引，可以用于模糊匹配， keyword,index:fals则doc不被切词，所以你要做的就是要么使用keyword,index:true的字段模糊匹配或者使用text类型的字段的全文检索匹配过滤，然后这些不被切词（查询项（二次查找（schame）））和被切词的字段作为查询项返回.<br>使用了keyword和index:false,该字段只能是作为查询项来返回,用法如下:</p></blockquote></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">MatchQueryBuilder termQueryBuilder = QueryBuilders.</div><div class="line">matchQuery(<span class="string">"content"</span>, <span class="string">"中国渔船"</span>).analyzer(<span class="string">"ik_max_word"</span>);</div><div class="line">String indexes = <span class="string">"CP5178,CP5177,CP5176"</span>;</div><div class="line">String[] includesIndexes = indexes.split(<span class="string">","</span>);</div><div class="line">String[] excludesIndexes = <span class="keyword">new</span> String[]&#123;&#125;;</div><div class="line">SearchResponse searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(termQueryBuilder)</div><div class="line">.setFetchSource(includesIndexes, excludesIndexes).execute().actionGet();</div></pre></td></tr></table></figure><blockquote><p>综上所述我们需要得到的最终技术实现</p></blockquote><ol><li>使用keyword,index:true配合wildcardQuery实现模糊匹配的查找(like “%key%”)</li><li>使用text字段配合分词器实现长关键词的二次匹配,搜索的关键词越长,关联度越高.</li></ol><ul><li>上代码</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">String mid = <span class="string">"A4816456E30D07B17C23B8D16FC26CCEC0E7EBE10A7554732A25753EBE533569"</span>;</div><div class="line"> String searchKey = <span class="string">"南通新时代电器科技有限公司"</span>;</div><div class="line"></div><div class="line"> MatchQueryBuilder merId = QueryBuilders.matchQuery(<span class="string">"mid"</span>, mid);</div><div class="line"></div><div class="line"></div><div class="line"> BoolQueryBuilder midMust = QueryBuilders.boolQuery().must(merId);</div><div class="line"></div><div class="line"></div><div class="line"> SearchResponse searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(midMust).execute().actionGet();</div><div class="line"></div><div class="line"> SearchHit[] hits = searchResponse.getHits().getHits();</div><div class="line"> String msg = <span class="string">"未找到"</span>;</div><div class="line"></div><div class="line"> <span class="keyword">if</span> (<span class="number">0</span> &lt; hits.length) &#123;</div><div class="line">     WildcardQueryBuilder mchntName = QueryBuilders.wildcardQuery(<span class="string">"name"</span>, <span class="string">"*"</span> + searchKey + <span class="string">"*"</span>);</div><div class="line">     QueryBuilders.prefixQuery()</div><div class="line">     BoolQueryBuilder mchntNameMust = QueryBuilders.boolQuery().must(merId).must(mchntName);</div><div class="line">     searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(mchntNameMust).execute().actionGet();</div><div class="line">     hits = searchResponse.getHits().getHits();</div><div class="line">     <span class="keyword">if</span> (<span class="number">0</span> &lt; hits.length) &#123;</div><div class="line">         <span class="keyword">for</span> (SearchHit searchHit : hits) &#123;</div><div class="line">             System.out.println(searchHit.getSourceAsMap().get(<span class="string">"name"</span>));</div><div class="line">         &#125;</div><div class="line">         msg = <span class="string">"匹配成功"</span>;</div><div class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">4</span> &lt; searchKey.length()) &#123;</div><div class="line">         MatchQueryBuilder nameQuery = QueryBuilders.</div><div class="line">                 matchQuery(<span class="string">"name_term"</span>, searchKey).analyzer(<span class="string">"ik_max_word"</span>);</div><div class="line">         BoolQueryBuilder nameMust = QueryBuilders.boolQuery().must(merId).must(nameQuery);</div><div class="line">         searchResponse = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(nameMust).execute().actionGet();</div><div class="line">         hits = searchResponse.getHits().getHits();</div><div class="line">         <span class="keyword">if</span> (<span class="number">0</span> &lt; hits.length) &#123;</div><div class="line">             <span class="keyword">for</span> (SearchHit searchHit : hits) &#123;</div><div class="line">                 System.out.println(searchHit.getSourceAsMap().get(<span class="string">"name_term"</span>));</div><div class="line">             &#125;</div><div class="line">             msg = <span class="string">"匹配成功"</span>;</div><div class="line">         &#125;</div><div class="line"></div><div class="line">     &#125;</div><div class="line"> &#125; <span class="keyword">else</span> &#123;</div><div class="line">     System.out.println(<span class="string">"未匹配到商户名"</span>);</div><div class="line"> &#125;</div><div class="line"></div><div class="line"> System.out.println(msg);</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> es </tag>
            
            <tag> elasticSearch </tag>
            
            <tag> term </tag>
            
            <tag> ik </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java 调用spark-submit填坑</title>
      <link href="/ITWO/2018/08/24/java-%E8%B0%83%E7%94%A8spark-submit%E5%A1%AB%E5%9D%91/"/>
      <url>/ITWO/2018/08/24/java-%E8%B0%83%E7%94%A8spark-submit%E5%A1%AB%E5%9D%91/</url>
      <content type="html"><![CDATA[<h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><blockquote><p>在开发过程中遇到了如下的问题:<br>使用shell调用spark-submit提交程序时,不到一分钟跑完所有的流程.<br>但是使用java调用shell进而调用spark-submit就会卡在parttion比较多的步骤,此问题我纠结了四天的时间.<br>可是可的确是弥补了很多知识上的短板.<br>排查过程如下:</p></blockquote><a id="more"></a><h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><h3 id="集群问题"><a href="#集群问题" class="headerlink" title="集群问题"></a>集群问题</h3><blockquote><p>首先怀疑的是集群问题,搜索度娘和谷哥有很多人告知是因为内存不够或者是分配给的内核不够,但是此类问题在过滤后台的日志来看是不存在的,</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">426.2 MB of 1 GB physical memory used; 2.2 GB of 2.1 GB virtual memory used</div></pre></td></tr></table></figure><h3 id="代码问题"><a href="#代码问题" class="headerlink" title="代码问题"></a>代码问题</h3><blockquote><p>后来怀疑是代码问题，因为使用python去调用该程序也是没问题的．<br>代码如下:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">runShell</span><span class="params">(String command)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">    String result = <span class="string">""</span>;</div><div class="line">    Process process = Runtime.getRuntime().exec(command);</div><div class="line">    <span class="comment">// 获取shell返回流</span></div><div class="line">    BufferedInputStream bufferedInputStream = <span class="keyword">new</span> BufferedInputStream(process.getInputStream());</div><div class="line">    <span class="comment">// 字符流转换字节流</span></div><div class="line">    BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(bufferedInputStream));</div><div class="line"></div><div class="line">    String line;</div><div class="line">    <span class="keyword">while</span> ((line = bufferedReader.readLine()) != <span class="keyword">null</span>)</div><div class="line">        result = line;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        process.waitFor();</div><div class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        <span class="comment">// 关闭输入流</span></div><div class="line">        bufferedInputStream.close();</div><div class="line">        bufferedReader.close();</div><div class="line">        process.destroy();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> result;</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>首先来解释一下 waitFor() 方法的意义， waitFor() 表示当前 Process 所在的子线程处于等待状态，如有必要，一直要等到由该 Process 对象表示的进程已经终止，官网说如果我们在调用此方法时，如果不注意的话，很容易出现主线程阻塞， Process 也挂起的情况。这就是我遇到的问题.解决办法是，在调用 waitFor() 的时候， Process 需要向主线程汇报运行状况，所以要注意清空缓存区，即 InputStream 和 ErrorStream ，注意这里 InputStream 和 ErrorStream 都需要清空。<br>但是上面的方式只是解决了标准输入流的读取，并且打印最后一行，并没有处理标准错误流，后来经过如下代码的测试，spark-submit提交的日志竟然打印在标准错误流中，所以也就解释了之前为什么会卡在partiion比较多的地方,因为该部分日志较多,达到了缓存区的上限,所以流程不能继续.<br>错误的表象:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">Container marked as failed: container_1535013730755_0026_01_000007 on host: rocket04.kylin.com. Exit status: <span class="number">1</span>. Diagnostics: Exception from container-launch.</div><div class="line">Container id: container_1535013730755_0026_01_000007</div><div class="line">Exit code: <span class="number">1</span></div><div class="line">Stack trace: ExitCodeException exitCode=<span class="number">1</span>: </div><div class="line">at org.apache.hadoop.util.Shell.runCommand(Shell.java:<span class="number">601</span>)</div><div class="line">at org.apache.hadoop.util.Shell.run(Shell.java:<span class="number">504</span>)</div><div class="line">at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:<span class="number">786</span>)</div><div class="line">at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:<span class="number">213</span>)</div><div class="line">at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:<span class="number">302</span>)</div><div class="line">at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:<span class="number">82</span>)</div><div class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">262</span>)</div><div class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</div><div class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</div><div class="line">at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</div></pre></td></tr></table></figure><blockquote><p>调研的现象如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">12</span>:<span class="number">59</span> INFO cluster.YarnScheduler: Removed TaskSet <span class="number">4.0</span>, whose tasks have all completed, from pool </div><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">12</span>:<span class="number">59</span> INFO scheduler.DAGScheduler: ResultStage <span class="number">4</span> (saveAsTextFile at ReportNatureIncubationCustom.scala:<span class="number">265</span>) finished in <span class="number">0.635</span> s</div><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">12</span>:<span class="number">59</span> INFO scheduler.DAGScheduler: Job <span class="number">2</span> finished: saveAsTextFile at ReportNatureIncubationCustom.scala:<span class="number">265</span>, took <span class="number">3.497685</span> s</div><div class="line">ERROR&gt;<span class="number">18</span>/<span class="number">08</span>/<span class="number">27</span> <span class="number">16</span>:<span class="number">13</span>:<span class="number">01</span> INFO spark.SparkContext: <span class="function">Invoking <span class="title">stop</span><span class="params">()</span> from shutdown hook</span></div></pre></td></tr></table></figure></p><p>测试代码:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">niceCallShell</span><span class="params">(String command)</span> </span>&#123;</div><div class="line">       String result = <span class="string">""</span>;</div><div class="line">       <span class="keyword">try</span> &#123;</div><div class="line">           System.out.println(<span class="string">"cmd start"</span>);</div><div class="line">           Process p = Runtime.getRuntime().exec(command);  <span class="comment">//调用Linux的相关命令</span></div><div class="line">           <span class="keyword">new</span> RunThread(p.getInputStream(), <span class="string">"INFO"</span>).start();</div><div class="line">           <span class="keyword">new</span> RunThread(p.getErrorStream(), <span class="string">"ERROR"</span>).start();</div><div class="line">           <span class="keyword">int</span> value = p.waitFor();</div><div class="line">           <span class="keyword">if</span> (value == <span class="number">0</span>)</div><div class="line">               result = <span class="string">"complete"</span>;</div><div class="line">           <span class="keyword">else</span></div><div class="line">               result = <span class="string">"failed"</span>;</div><div class="line">       &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">           e.printStackTrace();</div><div class="line">       &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">           e.printStackTrace();</div><div class="line">       &#125;</div><div class="line"></div><div class="line">       <span class="keyword">return</span> result;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RunThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">       InputStream is;</div><div class="line">       String printType;</div><div class="line"></div><div class="line">       RunThread(InputStream is, String printType) &#123;</div><div class="line">           <span class="keyword">this</span>.is = is;</div><div class="line">           <span class="keyword">this</span>.printType = printType;</div><div class="line">       &#125;</div><div class="line"></div><div class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">           <span class="keyword">try</span> &#123;</div><div class="line">               InputStreamReader isr = <span class="keyword">new</span> InputStreamReader(is);</div><div class="line">               BufferedReader br = <span class="keyword">new</span> BufferedReader(isr);</div><div class="line">               String line = <span class="keyword">null</span>;</div><div class="line">               <span class="keyword">while</span> ((line = br.readLine()) != <span class="keyword">null</span>)</div><div class="line">                   System.out.println(printType + <span class="string">"&gt;"</span> + line);</div><div class="line">           &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</div><div class="line">               ioe.printStackTrace();</div><div class="line">           &#125;</div><div class="line">       &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="不改java代码"><a href="#不改java代码" class="headerlink" title="不改java代码"></a>不改java代码</h3><blockquote><p>该解决方案为把spark-submit的日志重定向到一个独立文件中,就不会发生与java交互的Input/Error,方案如下:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">master yarn-client $deployPath/tourism-data-1.0.jar $&#123;reportId&#125; &gt; spark_cumstom_$&#123;reportId&#125;.log 2&gt;&amp;1</div></pre></td></tr></table></figure><h3 id="改动java代码"><a href="#改动java代码" class="headerlink" title="改动java代码"></a>改动java代码</h3><blockquote><p>这部分实则就是改动下之前的测试代码,将标准输入和标准错误放到不同的线程中,然后分发日志到logback中.</p></blockquote><h3 id="比较与总结"><a href="#比较与总结" class="headerlink" title="比较与总结"></a>比较与总结</h3><blockquote><p>第一种方法相比较与第二种方法而言,对于后期排查问题而言,可以更加直观,可以在shell文件的同级目录下找到所有的执行log,便于排查问题.<br>第二种则需要在系统级别的log中找到需要的信息,比较繁琐,如果数据较大,同时并发度很大,则嵌入的日志很大.但是相比较来说第二种,比较传统,也更接近java 的系统调用的使用习惯.当然也可返回shell调用成功的最后一行的flag,但是不方便排查问题.<br>综上:最终选择了第一种方案.</p></blockquote><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><h3 id="快捷排查"><a href="#快捷排查" class="headerlink" title="快捷排查"></a>快捷排查</h3><blockquote><p>怎么通过自带的UI来定位错误信息已经日志信息，已经各个节点上的日志信息预览？</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn application list</div></pre></td></tr></table></figure><blockquote><p>通过以上的命令进而通过我们设定的应用名称从而定位到Tracking-URL，在保证你本地已配置好数据集群的ip和host配置关系以后，通过该地址可以找到以下界面:</p></blockquote><p><img src="/ITWO/assets/spark-task-ui.png" alt="spark ui "></p><blockquote><p>从下图定位到executor</p></blockquote><p><img src="/ITWO/assets/executors.png" alt="executors"></p><blockquote><p>下图为详细信息</p></blockquote><p><img src="/ITWO/assets/error-log.png" alt="executors"></p>]]></content>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> spark </tag>
            
            <tag> submit </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>cron 使用范例</title>
      <link href="/ITWO/2018/08/13/cron-%E4%BD%BF%E7%94%A8%E8%8C%83%E4%BE%8B/"/>
      <url>/ITWO/2018/08/13/cron-%E4%BD%BF%E7%94%A8%E8%8C%83%E4%BE%8B/</url>
      <content type="html"><![CDATA[<blockquote><p>使用范例如下：</p></blockquote><a id="more"></a><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">一个cron表达式有至少6个（也可能7个）有空格分隔的时间元素。</div><div class="line">按顺序依次为 </div><div class="line">秒（0~59） </div><div class="line">分钟（0~59）</div><div class="line">小时（0~23）</div><div class="line">天（月）（0~31，但是你需要考虑你月的天数）</div><div class="line">月（0~11）</div><div class="line">天（星期）（1~7 1=SUN 或 SUN，MON，TUE，WED，THU，FRI，SAT）</div><div class="line">7.年份（1970－2099）</div><div class="line">其中每个元素可以是一个值(如6),一个连续区间(9-12),一个间隔时间(8-18/4)(/表示每隔4小时),一个列表(1,3,5),通配符。由于"月份中的日期"和"星期中的日期"这两个元素互斥的,必须要对其中一个设置?.</div><div class="line">0 0 10,14,16 * * ? 每天上午10点，下午2点，4点</div><div class="line">0 0/30 9-17 * * ?   朝九晚五工作时间内每半小时</div><div class="line">0 0 12 ? * WED 表示每个星期三中午12点 </div><div class="line">"0 0 12 * * ?" 每天中午12点触发 </div><div class="line">"0 15 10 ? * *" 每天上午10:15触发 </div><div class="line">"0 15 10 * * ?" 每天上午10:15触发 </div><div class="line">"0 15 10 * * ? *" 每天上午10:15触发 </div><div class="line">"0 15 10 * * ? 2005" 2005年的每天上午10:15触发 </div><div class="line">"0 * 14 * * ?" 在每天下午2点到下午2:59期间的每1分钟触发 </div><div class="line">"0 0/5 14 * * ?" 在每天下午2点到下午2:55期间的每5分钟触发 </div><div class="line">"0 0/5 14,18 * * ?" 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 </div><div class="line">"0 0-5 14 * * ?" 在每天下午2点到下午2:05期间的每1分钟触发 </div><div class="line">"0 10,44 14 ? 3 WED" 每年三月的星期三的下午2:10和2:44触发 </div><div class="line">"0 15 10 ? * MON-FRI" 周一至周五的上午10:15触发 </div><div class="line">"0 15 10 15 * ?" 每月15日上午10:15触发 </div><div class="line">"0 15 10 L * ?" 每月最后一日的上午10:15触发 </div><div class="line">"0 15 10 ? * 6L" 每月的最后一个星期五上午10:15触发 </div><div class="line">"0 15 10 ? * 6L 2002-2005" 2002年至2005年的每月的最后一个星期五上午10:15触发 </div><div class="line">"0 15 10 ? * 6#3" 每月的第三个星期五上午10:15触发</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> spring,cron </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark 聚合进化</title>
      <link href="/ITWO/2018/07/27/spark-%E8%81%9A%E5%90%88%E8%BF%9B%E5%8C%96/"/>
      <url>/ITWO/2018/07/27/spark-%E8%81%9A%E5%90%88%E8%BF%9B%E5%8C%96/</url>
      <content type="html"><![CDATA[<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><blockquote><p>通过分析流水，然后统计商户维度的以下字段：</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">* 1-交易金额</div><div class="line">* 2-交易笔数,3-交易人数</div><div class="line">* 4-笔单价,5-客单价,6-上午笔数占比</div><div class="line">* 7-午间笔数占比,8-下午笔数占比,9-晚间笔数占比,10-深夜笔数占比</div><div class="line">* （注：上午 00:00-9:59；午间 10:00-12:59；下午 13:00-16:59；晚间 17:00-20:59；深夜 21:00-23:59）</div></pre></td></tr></table></figure><blockquote><p>未完待续</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> agg </tag>
            
            <tag> sql </tag>
            
            <tag> pivot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用hive/mapreduce给大数据全局排序，同时巧用该方法实现hbase的预分区</title>
      <link href="/ITWO/2018/07/18/%E4%BD%BF%E7%94%A8hive-mapreduce%E7%BB%99%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F%EF%BC%8C%E5%90%8C%E6%97%B6%E5%B7%A7%E7%94%A8%E8%AF%A5%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0hbase%E7%9A%84%E9%A2%84%E5%88%86%E5%8C%BA/"/>
      <url>/ITWO/2018/07/18/%E4%BD%BF%E7%94%A8hive-mapreduce%E7%BB%99%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F%EF%BC%8C%E5%90%8C%E6%97%B6%E5%B7%A7%E7%94%A8%E8%AF%A5%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0hbase%E7%9A%84%E9%A2%84%E5%88%86%E5%8C%BA/</url>
      <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><blockquote><p>完成排序，打行号，然后根据分位数找到分界点。</p></blockquote><a id="more"></a><h2 id="hive篇"><a href="#hive篇" class="headerlink" title="hive篇"></a>hive篇</h2><h3 id="造测试数据"><a href="#造测试数据" class="headerlink" title="造测试数据"></a>造测试数据</h3><blockquote><p>直接上代码，如下的代码可以仿造出64位的加密字符串，达到模拟某种加密的方式，如此方式造了100w的数据用于测试。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">key = <span class="string">""</span>.join(random.choice(<span class="string">"0123456789ABCDEF"</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">64</span>))</div></pre></td></tr></table></figure><h3 id="导数据"><a href="#导数据" class="headerlink" title="导数据"></a>导数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">use</span> koulb;</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> t_card_info (<span class="keyword">key</span> <span class="keyword">string</span>)</div><div class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></div><div class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span></div><div class="line">Location <span class="string">'/user/koulingbo/cardInfo'</span>;</div></pre></td></tr></table></figure><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_card_info_row <span class="keyword">as</span> </div><div class="line"><span class="keyword">select</span> row_number() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">key</span>) <span class="keyword">as</span> rn,<span class="keyword">key</span> <span class="keyword">from</span> t_card_info;</div><div class="line"></div><div class="line"> number of reducers: 1</div></pre></td></tr></table></figure><blockquote><p>众所周知 hive 中的order by 适用于全局排序，所以它只能是给到一个reduce来完成，因为不同的parttion来分区到不同的reduce就决定了只能reduce内部有序，如果你想达到全局排序只能够是一个reduce。</p></blockquote><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><blockquote><p>思路：使用分位数函数来定位切割点，然后转置→行转列，与之前的行号join拿到最终的分界点。当然最初你要根据tsv 的大小、snappy压缩比、以及region的大小（根据hfile以及其个数确定）来确定要分成几个region,本文暂定为100个分区来做演示。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">var="1/100"</div><div class="line">for i in &#123;2..99&#125;</div><div class="line">do</div><div class="line">        var="$var,$i/100"</div><div class="line">done</div><div class="line">echo $var</div><div class="line"></div><div class="line">hive -S -e "use koulb;create table koulb.t_card_info_res as select k.key from \</div><div class="line">(select explode(percentile_approx(rn,array($&#123;var&#125;),2168727))as keyRange \</div><div class="line">from koulb.t_card_info_row) r join koulb.t_card_info_row k on floor(r.keyRange)=k.rn;" </div><div class="line"></div><div class="line">hive -S -e "select * from koulb.t_card_info_res"&gt;res</div></pre></td></tr></table></figure><h3 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create 'card_quota_test_koulb', &#123;NAME =&gt; 'n', VERSIONS =&gt; 1, COMPRESSION =&gt; 'SNAPPY'&#125;,  &#123;SPLITS_FILE =&gt; 'res'&#125;</div></pre></td></tr></table></figure><h2 id="mapreduce部分"><a href="#mapreduce部分" class="headerlink" title="mapreduce部分"></a>mapreduce部分</h2><p>==未完待续==</p>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> mapreduce </tag>
            
            <tag> hive </tag>
            
            <tag> row_number </tag>
            
            <tag> percentile </tag>
            
            <tag> explode </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hbase/es load 问题总结</title>
      <link href="/ITWO/2018/07/06/hbase-load-%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
      <url>/ITWO/2018/07/06/hbase-load-%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>公司指标2.0开发了很多新的指标，数据量很客观，需要导入到列式存储数据库中，实现毫秒级别的响应查询，之前也有一版本的导入是导入到hbase中，但是hbase对于高并发的响应不是很理想，但凡高并发上来以后，时效性就会有影响。</p></blockquote><a id="more"></a><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><h3 id="HBase部分"><a href="#HBase部分" class="headerlink" title="HBase部分"></a>HBase部分</h3><blockquote><p>因为数据量大的缘故，使用的是将多个HDFS文件下的数据切割然后组合成tsv，再使用PUT元素转换为HFile文件，进而使用bulkload导入hbase中。</p></blockquote><h3 id="ES部分"><a href="#ES部分" class="headerlink" title="ES部分"></a>ES部分</h3><blockquote><p>复用之前生成好的tsv文件，组装好MapWritable，然后使用EsOutputFormat完成格式化输出。</p></blockquote><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><blockquote><p>这部分时间耗费在本地调试过渡到集群跑批，因为在本地集群单节点测试，你再怎么折腾也不出现配置文件找不到的问题，当然这里的前提是我使用了Properties文件做为传递配置参数的载体，在多节点测试服务器跑批的时候就会出现找不到配置文件的问题，因为该配置文件只会存在client端，而不会分发到各个其他的节点，所以会有找不到配置文件的问题出现。当然这部分也因为在使用的是ToolRunner.run(conf, new BootApplication(), args)，所以考虑过使用-files#filelink,具体用法参考字典文件分发的那篇文章，但是使用的时候，并没有达到达到预期效果，打开方式不对？<br>后来的做法是先用Properties对象解析外部的绝对路径的配置问价，将拿到的配置放到一直在框架中的上下文对象Context中的Configuration中，这样只要在client端提交任务的地方，传值给它，那么无论在框架运行的什么阶段都可以读到外部配置文件中的配置项。</p></blockquote><h3 id="HA的开启"><a href="#HA的开启" class="headerlink" title="HA的开启"></a>HA的开启</h3><blockquote><p>在本地的测试过程中，因为本地没有开启NM的HA，所以只需要配置如下内容就可以完成程序和集群的对接：</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fs.defaultFS=hdfs://hostname:8020</div></pre></td></tr></table></figure><blockquote><p>当然如果没有配置，也可以做本地文件的测试。</p><p>要对接开启了NM的HA的集群除了以上的配置还需要配置如下的内容:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">fs.nameservices=nameservice</div><div class="line"><span class="meta">#</span><span class="bash">指定nameservice服务下有几个namenode</span></div><div class="line">fs.ha.namenodes.nameservice=namenode33,namenode134</div><div class="line"><span class="meta">#</span><span class="bash">指定各个namenode节点的访问链接</span></div><div class="line">fs.namenode.rpc-address.nameservice.namenode33=node-01.upsmart.com:8020</div><div class="line">fs.namenode.rpc-address.nameservice.namenode134=node-02.upsmart.com:8020</div><div class="line">fs.client.failover.proxy.provider.nameservice=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</div></pre></td></tr></table></figure><h3 id="habse-依赖问题"><a href="#habse-依赖问题" class="headerlink" title="habse 依赖问题"></a>habse 依赖问题</h3><blockquote><p>在导入数据到hbase的过程中在一集群导入没有问题，原本以为已经可以收工，但是后来在开启的HA的另一集群测试，出现了少包的问题，这部分可能跟集群安装依赖包的寡众有关系，但是保不齐那个集群就少包了，所以你要做的是把所有的能用到的包都打到jar包里，但是打包的时候又遇到如下的问题：<br>在打包的过程中有个包一直打不进去后来 </p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn -X clean install &gt;log</div></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-hadoop-compat<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0-cdh5.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure><blockquote><p>定位到如下的ERROR</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="string">'dependencies.dependency.version'</span> <span class="keyword">for</span> commons-logging:commons-logging:jar is missing. @</div></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">  <span class="comment">&lt;!-- General dependencies --&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-math<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div></pre></td></tr></table></figure><blockquote><p>原本以为去掉这些依赖就可以万事大吉，但是并没有奏效，后来使用了最彻底的办法依照大版本相同应该改动不大的原则换了版本到1.1.10,然后打包后问题解决。<br>以下方法并没有解决问题：</p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></div></pre></td></tr></table></figure><blockquote><p>我的理解是解析pom的时候和打包去除某些依赖是不同的解析顺序</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.htrace&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;htrace-core&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;3.0.4&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line"></div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.htrace&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;htrace-core&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;3.1.0-incubating&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure><blockquote><p>这两个包都要加否则会报错找不到。</p></blockquote><h3 id="mapreduce-过程报错"><a href="#mapreduce-过程报错" class="headerlink" title="mapreduce 过程报错"></a>mapreduce 过程报错</h3><blockquote><p>beyond physical memory limits</p></blockquote><h4 id="map-reduce-阶段报错"><a href="#map-reduce-阶段报错" class="headerlink" title="map reduce  阶段报错"></a>map reduce  阶段报错</h4><blockquote><p>解决方案：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn.scheduler.minimum-allocation-mb 调节大点</div></pre></td></tr></table></figure></p></blockquote><h4 id="如果是只有reduce阶段报错"><a href="#如果是只有reduce阶段报错" class="headerlink" title="如果是只有reduce阶段报错"></a>如果是只有reduce阶段报错</h4><blockquote><p>解决方案：可以通过增大reduce的个数来分散reduce端的处理压力</p></blockquote><h4 id="reduce-100-beyond-physical-memory-limits"><a href="#reduce-100-beyond-physical-memory-limits" class="headerlink" title="reduce 100%  beyond physical memory limits"></a>reduce 100%  beyond physical memory limits</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#9</div><div class="line">        at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:<span class="number">134</span>)</div><div class="line">        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:<span class="number">376</span>)</div><div class="line">        at org.apache.hadoop.mapred.YarnChild$<span class="number">2</span>.run(YarnChild.java:<span class="number">164</span>)</div><div class="line">        at java.security.AccessController.doPrivileged(Native Method)</div><div class="line">        at javax.security.auth.Subject.doAs(Subject.java:<span class="number">422</span>)</div><div class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1920</span>)</div><div class="line">        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:<span class="number">158</span>)</div><div class="line">Caused by: java.lang.OutOfMemoryError: Java heap space</div></pre></td></tr></table></figure><blockquote><p>解决方案：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-D mapreduce.reduce.shuffle.memory.limit.percent=0.1</div></pre></td></tr></table></figure></p></blockquote><h3 id="ClassNotFoundException"><a href="#ClassNotFoundException" class="headerlink" title="ClassNotFoundException"></a>ClassNotFoundException</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java.lang.ClassNotFoundException: Class org.elasticsearch.hadoop.mr.EsOutputFormat not found</div></pre></td></tr></table></figure><blockquote><p>解决方案：</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Create job</span></div><div class="line">job.setJarByClass(BootApplication.class);</div></pre></td></tr></table></figure><blockquote><p>问题分析：看代码，一目了然。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setJarByClass</span><span class="params">(Class cls)</span> </span>&#123;</div><div class="line">    String jar = findContainingJar(cls);</div><div class="line">    <span class="keyword">if</span> (jar != <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="keyword">this</span>.setJar(jar);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="es导入"><a href="#es导入" class="headerlink" title="es导入"></a>es导入</h3><h4 id="Limit-of-total-fields-1000-in-index-card-nature-has-been-exceeded"><a href="#Limit-of-total-fields-1000-in-index-card-nature-has-been-exceeded" class="headerlink" title="Limit of total fields [1000] in index [card_nature] has been exceeded"></a>Limit of total fields [1000] in index [card_nature] has been exceeded</h4><blockquote><p>解决方案：</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">curl  -H "Content-Type: application/json"  -XPUT http://192.168.88.126:9200/card_nature/_settings?pretty=true -d '&#123;"settings": </div><div class="line">&#123;"index.mapping.total_fields.limit": 100000&#125;&#125;'</div></pre></td></tr></table></figure><h4 id="建立索引的时候报错：-usr-bin-curl-Argument-list-too-long"><a href="#建立索引的时候报错：-usr-bin-curl-Argument-list-too-long" class="headerlink" title="建立索引的时候报错：/usr/bin/curl: Argument list too long"></a>建立索引的时候报错：/usr/bin/curl: Argument list too long</h4><blockquote><p>解决方案<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">curl -H 'content-type: application/json' -XPUT \</div><div class="line">  -d @- 'http://localhost:9200/card_nature' &lt;&lt;CURL_DATA</div><div class="line">&#123;</div><div class="line">    "settings": &#123;</div><div class="line">                "number_of_replicas": 0,</div><div class="line">                "number_of_shards": 6,</div><div class="line">                "refresh_interval": "-1",</div><div class="line">                "index.mapping.total_fields.limit": 100000</div><div class="line">    &#125;,</div><div class="line">        "mappings": &#123;</div><div class="line">            "card_nature": &#123;</div><div class="line">                'properties': &#123;</div><div class="line">                    "CP0124":&#123;"type": "date","format": "yyyy-mm", "index": "false"&#125;,</div><div class="line">                    "CP0125":&#123;"type": "date","format": "yyyy-mm", "index": "false"&#125;,</div><div class="line">                    "CP0126":&#123;"type": "keyword", "index": "false"&#125;,</div><div class="line">                    "CP0127":&#123;"type": "keyword", "index": "false"&#125;,</div><div class="line">                    "CP0128":&#123;"type": "keyword", "index": "false"&#125;,</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">&#125;</div><div class="line">CURL_DATA</div><div class="line"></div><div class="line">curl -H "Content-Type: application/json"  -XPUT http://192.168.88.126:9200/card_nature/_settings?pretty=true -d '&#123;"settings": &#123;"refresh_interval": "5s","number_of_replicas":1&#125;&#125;'</div><div class="line">curl -XPOST  http://192.168.88.126:9200/card_nature/_refresh</div></pre></td></tr></table></figure></p></blockquote><h4 id="建索引的时候报错"><a href="#建索引的时候报错" class="headerlink" title="建索引的时候报错"></a>建索引的时候报错</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">"type": "mapper_parsing_exception",</div><div class="line">"reason": "No handler for type [string] declared on field [CP0125]"</div></pre></td></tr></table></figure><blockquote><p>解决方案:5.x以上已经没有string类型。如果需要分词的话使用text，不需要分词使用keyword。</p></blockquote><h3 id="es建立索引总结"><a href="#es建立索引总结" class="headerlink" title="es建立索引总结"></a>es建立索引总结</h3><blockquote><p>建立索引的时候关闭索引更新，别设置副本，如果字段超过1000，您就按照上面那样设置。<br>数据导入完成以后要么您开启五秒间隔更新，为了防止以后小批量的数据导入。<br>要么您每次导入数据之后手动使用最下面手动更新索引。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hbase </tag>
            
            <tag> bulkload </tag>
            
            <tag> es </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>比较两个文件内容的不同</title>
      <link href="/ITWO/2018/06/08/%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E7%9A%84%E4%B8%8D%E5%90%8C/"/>
      <url>/ITWO/2018/06/08/%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E7%9A%84%E4%B8%8D%E5%90%8C/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>比较两个文件的不同</p></blockquote><a id="more"></a><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">koulb@koulb-ubantu:~/testdata$ more a</div><div class="line">1</div><div class="line">a</div><div class="line">b</div><div class="line">d</div><div class="line">c</div><div class="line">koulb@koulb-ubantu:~/testdata$ more b</div><div class="line">a</div><div class="line">b</div></pre></td></tr></table></figure><blockquote><p>这时你去比较</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">koulb@koulb-ubantu:~/testdata$ comm -23 a b</div><div class="line">1</div><div class="line">f</div><div class="line">comm: 文件1 没有被正确排序</div><div class="line">e</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div></pre></td></tr></table></figure><blockquote><p>你需要做的是:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">koulb@koulb-ubantu:~/testdata$ sort -u a &gt;c</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -23 c b</div><div class="line">1</div><div class="line">c</div><div class="line">d</div></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">只显示file1独有的行：</div><div class="line">需要把第2列和第3列去掉：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -2 -3 file1 file2</div><div class="line">只显示file2独有的行：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -1 -3 file1 file2</div><div class="line"></div><div class="line">只显示两者重复的行：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -1 -2 file1 file2</div><div class="line">只显示两者不重复的行：</div><div class="line">后面的sed是将以\t开头的\t去掉：</div><div class="line">koulb@koulb-ubantu:~/testdata$ comm -3 file1 file2 | sed 's/^\t//'</div></pre></td></tr></table></figure><h2 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h2><ul><li>使用该命令一定要先排序去重，否则不生效，切记。</li></ul>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> file </tag>
            
            <tag> comm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>安装es遇到的问题和解决方案</title>
      <link href="/ITWO/2018/05/28/%E5%AE%89%E8%A3%85es%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/ITWO/2018/05/28/%E5%AE%89%E8%A3%85es%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>在安装es过程中遇到的问题总结。</p></blockquote><a id="more"></a><h2 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h2><blockquote><ol><li>max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]</li></ol></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/sysctl.conf</div><div class="line">在最后一行加入如下配置</div><div class="line">vm.max_map_count=262144</div></pre></td></tr></table></figure><hr><h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bootstrap.memory_lock: true</div></pre></td></tr></table></figure><blockquote><p>开起如上配置启动报错如下</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="number">2</span>. bootstrap checks failed  memory locking requested <span class="keyword">for</span> elasticsearch process but memory is not locked</div><div class="line"></div><div class="line">These can be adjusted by modifying /etc/security/limits.conf, <span class="keyword">for</span> example:</div><div class="line">#allow user 'upsmart' mlockall</div><div class="line">upsmart soft memlock unlimited</div><div class="line">upsmart hard memlock unlimited</div><div class="line">If you are logged in interactively, you will have to re-login <span class="keyword">for</span> the <span class="keyword">new</span> limits to take effect.</div><div class="line">These can be adjusted by modifying /etc/security/limits.conf, <span class="keyword">for</span> example:</div><div class="line">#allow user 'upsmart' mlockall</div><div class="line">upsmart soft memlock unlimited</div><div class="line">upsmart hard memlock unlimited</div><div class="line">If you are logged in interactively, you will have to re-login <span class="keyword">for</span> the <span class="keyword">new</span> limits to take effect.</div></pre></td></tr></table></figure><blockquote><p>根据以上提示要修改以下内容</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">sudo vim /etc/security/limits.conf</div><div class="line"><span class="meta">#</span><span class="bash">allow user <span class="string">'upsmart'</span> mlockall</span></div><div class="line">upsmart soft memlock unlimited</div><div class="line">upsmart hard memlock unlimited</div></pre></td></tr></table></figure><hr><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>改的过程中发现启动程序不起作用，后来发现提示下面还有一句话提示的是如果不起作用，需要重新建立登录，后来关闭该会话，然后重启程序。（细节很重要！！！）</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> es </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mongo查询慢排查</title>
      <link href="/ITWO/2018/05/23/mongo%E6%9F%A5%E8%AF%A2%E6%85%A2%E6%8E%92%E6%9F%A5/"/>
      <url>/ITWO/2018/05/23/mongo%E6%9F%A5%E8%AF%A2%E6%85%A2%E6%8E%92%E6%9F%A5/</url>
      <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><blockquote><p>线上建模结果缓存在mongo中，之前由于数据量较少，进来一段时间由于老系统业务迁移过来，数据量也上来了，随之而来暴露出来一个问题.</p></blockquote><a id="more"></a><blockquote><p>查询很慢，但是只是个别客户的账号有问题，起初以为是客户建模的数据（客户部分代码有异常）有问题导致，但是从日志来看也有正常返回的数据但是也会有超时，后来把该客户的数据导入到开发集群来排查问题。</p></blockquote><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><blockquote><p>之前接口层面建的索引执行计划给出执行过程</p></blockquote><p><img src="/ITWO/assets/index_01.png" alt="之前接口层面建的索引执行计划给出执行过程"></p><blockquote><p>分解图示：<br>Explain部分分为</p></blockquote><ol><li>IXSCAN（检索索引）<br>  耗费250ms,排查（examined）文档965978个，该步骤返回文档965978个，用到的索引是account_1_analysisId_1，该索引匹配到的数据965978.</li><li>FETCH（拉取数据）<br> 耗时660ms,排查（examined）文档965978个，该步骤返回文档１个，遍历加判断最终拿到想要的结果，这步耗时也是最多的一步。</li><li>KEEP_MUTATIONS（暂时不知道是干嘛的）</li></ol><blockquote><p>其实仔细看已经看出端倪了，这边提示的是Index account_1_analysisId_1 was used to find matching values for account,<strong>analysisId</strong>，还有looking for these criteria: {<strong>“analysis_id”.</strong>:{“$eq”:”bc70380f-47b0-40f9-9e24-f54d61ce8bd6”}}，复合索引中的字段并不是我们检索的mongo字段，后来翻查代码，</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Document</span>(collection = <span class="string">"bill_analysis_info"</span>)</div><div class="line"><span class="meta">@CompoundIndexes</span>(&#123; <span class="meta">@CompoundIndex</span>(name = <span class="string">"query_index"</span>, def = <span class="string">"&#123;account : 1, analysisId : 1&#125;"</span>) &#125;)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BillAnalysisInfo</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;……&#125;</div></pre></td></tr></table></figure><blockquote><p>找到如上的根源。</p></blockquote><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><blockquote><p>手动建立针对这两个业务字段的复合索引</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.bill_analysis_info.ensureIndex(&#123;"account":1,"analysis_id":1&#125;)</div></pre></td></tr></table></figure><blockquote><p>再次查看同样查询的执行计划</p></blockquote><p><img src="/ITWO/assets/index_02.png" alt="重建索引执行计划给出执行过程"></p><blockquote><p><strong>效果很明显</strong></p></blockquote><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>mongo中原本以为会对建立索引过程中的字段是否为该集合的字段做判断，但此次排查下来明显没有，引以为戒。<br>细节，认真。<br>可视化工具用到的是dbKoda，要求mongo3.0版本以上。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> mongo </tag>
            
            <tag> dbKoda </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop streaming 配置文件和字典文件分发方式</title>
      <link href="/ITWO/2018/05/10/hadoop-streaming-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%92%8C%E5%AD%97%E5%85%B8%E6%96%87%E4%BB%B6%E5%88%86%E5%8F%91%E6%96%B9%E5%BC%8F/"/>
      <url>/ITWO/2018/05/10/hadoop-streaming-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%92%8C%E5%AD%97%E5%85%B8%E6%96%87%E4%BB%B6%E5%88%86%E5%8F%91%E6%96%B9%E5%BC%8F/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>通常情况下我们在hadoop streaming中通过input来设置我们需要处理的数据,然后逐条遍历打标记,从而在reduce端可以区别对待做聚合或者join操作.但是我们需要用到一些配置文件怎么办?</p></blockquote><a id="more"></a><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><blockquote><p>这里使用python来实现,我们的第一思路是:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">python test.py dict.txt</div><div class="line">-file dict.txt</div></pre></td></tr></table></figure><blockquote><p>当然这种方案只可以针对本地文件,一方面这样的文件每次都要分发带来很大的局限性(如果文件很大怎么办?是不是会很耗费性能?显然是的),另一方面如果我们需要使用的文件在hdfs上怎么实施?<br>先贴下官网的普及文档</p></blockquote><h3 id="Hadoop-Streaming中的大文件和档案"><a href="#Hadoop-Streaming中的大文件和档案" class="headerlink" title="Hadoop Streaming中的大文件和档案"></a>Hadoop Streaming中的大文件和档案</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">任务使用-cacheFile和-cacheArchive选项在集群中分发文件和档案，选项的参数是用户已上传至HDFS的文件或档案的URI。这些文件和档案在不同的作业间缓存。用户可以通过fs.default.name.config配置参数的值得到文件所在的host和fs_port。</div><div class="line"></div><div class="line">这个是使用-cacheFile选项的例子：</div><div class="line"></div><div class="line">-cacheFile hdfs://host:fs_port/user/testfile.txt#testlink</div><div class="line">在上面的例子里，url中#后面的部分是建立在任务当前工作目录下的符号链接的名字。这里的任务的当前工作目录下有一个“testlink”符号链接，它指向testfile.txt文件在本地的拷贝。如果有多个文件，选项可以写成：</div><div class="line"></div><div class="line">-cacheFile hdfs://host:fs_port/user/testfile1.txt#testlink1 -cacheFile hdfs://host:fs_port/user/testfile2.txt#testlink2</div><div class="line">-cacheArchive选项用于把jar文件拷贝到任务当前工作目录并自动把jar文件解压缩。例如：</div><div class="line"></div><div class="line">-cacheArchive hdfs://host:fs_port/user/testfile.jar#testlink3</div><div class="line">在上面的例子中，testlink3是当前工作目录下的符号链接，它指向testfile.jar解压后的目录。</div><div class="line"></div><div class="line">下面是使用-cacheArchive选项的另一个例子。其中，input.txt文件有两行内容，分别是两个文件的名字：testlink/cache.txt和testlink/cache2.txt。“testlink”是指向档案目录（jar文件解压后的目录）的符号链接，这个目录下有“cache.txt”和“cache2.txt”两个文件。</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/bin/hadoop  jar <span class="variable">$HADOOP_HOME</span>/hadoop-streaming.jar \</span></div><div class="line">                  -input "/user/me/samples/cachefile/input.txt"  \</div><div class="line">                  -mapper "xargs cat"  \</div><div class="line">                  -reducer "cat"  \</div><div class="line">                  -output "/user/me/samples/cachefile/out" \  </div><div class="line">                  -cacheArchive 'hdfs://hadoop-nn1.example.com/user/me/samples/cachefile/cachedir.jar#testlink' \  </div><div class="line">                  -jobconf mapred.map.tasks=1 \</div><div class="line">                  -jobconf mapred.reduce.tasks=1 \ </div><div class="line">                  -jobconf mapred.job.name="Experiment"</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> ls test_jar/</span></div><div class="line">cache.txt  cache2.txt</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> jar cvf cachedir.jar -C test_jar/ .</span></div><div class="line">added manifest</div><div class="line">adding: cache.txt(in = 30) (out= 29)(deflated 3%)</div><div class="line">adding: cache2.txt(in = 37) (out= 35)(deflated 5%)</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -put cachedir.jar samples/cachefile</span></div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -cat /user/me/samples/cachefile/input.txt</span></div><div class="line">testlink/cache.txt</div><div class="line">testlink/cache2.txt</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> cat test_jar/cache.txt </span></div><div class="line">This is just the cache string</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> cat test_jar/cache2.txt </span></div><div class="line">This is just the second cache string</div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -ls /user/me/samples/cachefile/out      </span></div><div class="line">Found 1 items</div><div class="line">/user/me/samples/cachefile/out/part-00000 </div><div class="line"></div><div class="line"><span class="meta">$</span><span class="bash"> hadoop dfs -cat /user/me/samples/cachefile/out/part-00000</span></div><div class="line">This is just the cache string   </div><div class="line">This is just the second cache string</div></pre></td></tr></table></figure><blockquote><p>以上的demo可以看出可以帮助我们通过这种途径去预览分发后的hdfs配置文件.</p></blockquote><h3 id="实践校验"><a href="#实践校验" class="headerlink" title="实践校验"></a>实践校验</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line"></div><div class="line">hadoop fs -rmr $&#123;2&#125;</div><div class="line"></div><div class="line">hadoop jar /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/hadoop-streaming-2.6.0-mr1-cdh5.4.0.jar \</div><div class="line">        -files testSymlink.py,hdfs:///user/upsmart/koulb/dict.txt#test \</div><div class="line"><span class="meta">#</span><span class="bash"> -file testSymlink.py \</span></div><div class="line"><span class="meta">#</span><span class="bash"> -cacheFile ,hdfs:///user/upsmart/koulb/dict.txt<span class="comment">#test \</span></span></div><div class="line">        -input $&#123;1&#125; \</div><div class="line">        -output $&#123;2&#125; \</div><div class="line">        -mapper "cat" \</div><div class="line">        -reducer "python testSymlink.py" \</div><div class="line">        -jobconf mapred.reduce.tasks=1 \</div><div class="line">        -jobconf mapred.job.name="testSymlink"</div></pre></td></tr></table></figure><blockquote><p>tips:此处的files等价于file + cacheFile,其实官网有很长一段时间的版本已经在推崇这样的做法,但是还是在兼容这样的模式用法,file用来上传分发本地的文件到集群,cacheFile顾名思义用的是集群上已经现存的资源.<br>-file option is deprecated, please use generic option -files instead.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line"></div><div class="line"><span class="comment"># 打开一个文件</span></div><div class="line"><span class="comment"># 通过软链接去访问配置文件</span></div><div class="line">fo = open(<span class="string">"test"</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"文件名: "</span>, fo.name</div><div class="line"></div><div class="line"><span class="comment"># 遍历文件打印每行的数据</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fo:</div><div class="line">        <span class="keyword">print</span> line.strip()</div><div class="line"></div><div class="line"><span class="comment"># 关闭打开的文件</span></div><div class="line">fo.close()</div></pre></td></tr></table></figure></p></blockquote><h2 id="细节描述"><a href="#细节描述" class="headerlink" title="细节描述"></a>细节描述</h2><h3 id="map使用细节"><a href="#map使用细节" class="headerlink" title="map使用细节"></a>map使用细节</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">-mapper "python testSymlink.py" \</div><div class="line">-jobconf mapred.reduce.tasks=0 \</div></pre></td></tr></table></figure><blockquote><p>看细节:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">JobSubmitter: number of splits:3</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">  配置文件结果输出</span></div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div></pre></td></tr></table></figure><blockquote><p>从上可以看出我们使用的配置文件打印了三次,和我么你的splits个数一致.也就是说和map个数一致.</p></blockquote><h3 id="recude使用细节"><a href="#recude使用细节" class="headerlink" title="recude使用细节"></a>recude使用细节</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">-reducer "python testSymlink.py" \</div><div class="line">-jobconf mapred.reduce.tasks=1 \</div></pre></td></tr></table></figure><blockquote><p>看细节</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 配置文件输出</span></div><div class="line">文件名:  test</div><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">d</div><div class="line">e</div></pre></td></tr></table></figure><blockquote><p>同样可以得出输出的次数和reduce个数完全一致</p></blockquote><h3 id="使用总结"><a href="#使用总结" class="headerlink" title="使用总结"></a>使用总结</h3><blockquote><p>综上可得,完全达到了配置文件分发的目的,可以保证每个map和reduce都可以使用到所需的配置文件.</p><p>tips:<strong>JobSubmitter: number of splits:3</strong>,<br><strong>3</strong>  = <strong>files:2</strong> + <strong>input1</strong></p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> file </tag>
            
            <tag> hadoop streaming </tag>
            
            <tag> cacheFile </tag>
            
            <tag> files </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>chrome 浏览器页面乱码问题</title>
      <link href="/ITWO/2018/05/09/chrome-%E6%B5%8F%E8%A7%88%E5%99%A8%E9%A1%B5%E9%9D%A2%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/"/>
      <url>/ITWO/2018/05/09/chrome-%E6%B5%8F%E8%A7%88%E5%99%A8%E9%A1%B5%E9%9D%A2%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>在做es分词的时候用到了ik分词器要用热分词,要用到一个web容器来搭建在线词库,遇到了以下的问题.<br><a id="more"></a></p><p>建立词库的时候原本打算是在服务器上建立的后来,无法确认它的编码格式,后来在本地用文本建立的词典,同时也另存为了utf-8格式,然后传到了tomcat服务器的ROOT目录下,然后启动在页面预览,但是出现了乱码.</p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><blockquote><p>原本下意识的解决思路是修改tomcat自带的server.xml配置,但是改了以后于事无补,在页面预览还是乱码.<br>后来考虑到是不是浏览器自己的编码格式问题,使用了curl直接访问这个文本静态文件,没有乱码的问题出现,从而定位去修改浏览器的默认格式问题,但是最新版本的chrome浏览器没有提供直接修改默认编码的通道,后来在chrome商店有搜到有以下这款插件可以解决问题.<br>ps:(A Google Chrome extension used to modify the page default encoding for Google Chrome 55+.)<br>55版本以后已经不支持在自定义字体里面修改.<br><a href="https://chrome.google.com/webstore/detail/oenllhgkiiljibhfagbfogdbchhdchml" target="_blank" rel="external">Charset</a></p></blockquote><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>后来发现其实跟server.xml的配置没关系,是不是新版本已经没有该问题了?(apache-tomcat-8.5.31)</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> chrome </tag>
            
            <tag> ubantu </tag>
            
            <tag> utf-8 </tag>
            
            <tag> tomcat </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 实用技巧总结</title>
      <link href="/ITWO/2018/05/04/linux-%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"/>
      <url>/ITWO/2018/05/04/linux-%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<blockquote><p>总结以往在使用linux时,用到的一点小技巧或者命令集合</p></blockquote><a id="more"></a><h2 id="批量图片格式文件转换成一个pdf"><a href="#批量图片格式文件转换成一个pdf" class="headerlink" title="批量图片格式文件转换成一个pdf"></a>批量图片格式文件转换成一个pdf</h2><blockquote><p>convert *.jpg output.pdf<br>ps:就是这么任性</p></blockquote><h2 id="awk-按照某个key分发文件的妙用"><a href="#awk-按照某个key分发文件的妙用" class="headerlink" title="awk 按照某个key分发文件的妙用"></a>awk 按照某个key分发文件的妙用</h2><h3 id="需求背景："><a href="#需求背景：" class="headerlink" title="需求背景："></a>需求背景：</h3><blockquote><p>本来的需求是提取一个月的数据，但是出来以后产品又要拆分为每天的量<br><!--more--></p></blockquote><h3 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h3><blockquote><p>本来打算使用python foreach去解决，但是想到以前用过awk处理过类似的问题，乍一看日期后面还有时分秒，必然又用到了substr，妙的是awk也支持，脚本如下：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">awk -F <span class="string">','</span> <span class="string">'&#123;print $3  &gt;substr($2,1,10)".csv"&#125;'</span> sy*.txt;</div></pre></td></tr></table></figure><blockquote><p>完美的解决了我的问题，第二列是时间(带有时分秒,日期格式为2017-06-13的样式)，第三列为个人标示，唯一标示一条记录，当然你也可以使用$0，完成真正意义上的拆分文件。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">awk -F <span class="string">','</span> <span class="string">'&#123;print $0 &gt;substr($2,1,10)".csv"&#125;'</span>  sy*.txt;</div></pre></td></tr></table></figure><h2 id="awk-批量更改某列的值"><a href="#awk-批量更改某列的值" class="headerlink" title="awk 批量更改某列的值"></a>awk 批量更改某列的值</h2><blockquote><p>需要更改某个文件中的某列值,用python的话很好实现,伪脚本如下</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">    details = line.strip().split(sep)</div><div class="line">details[n] = <span class="string">"new data"</span></div><div class="line"><span class="keyword">print</span> sep.join(details)</div></pre></td></tr></table></figure><blockquote><p>awk 的实现方式如下:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">awk  'BEGIN&#123;FS=OFS=","&#125; $2="ccc"; print $0&#125;' aa</div></pre></td></tr></table></figure><blockquote><p>如上的代码中需要同时制定输入和输出的分隔符,如果输出分隔符不指定的话,会导致print $0的时候默认的分隔符为空格.</p></blockquote><h2 id="awk-实现group-by"><a href="#awk-实现group-by" class="headerlink" title="awk 实现group by"></a>awk 实现group by</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">2018-12-01,1</div><div class="line">2018-12-01,1</div><div class="line">2018-12-03,10</div><div class="line">2018-11-01,11</div><div class="line">2018-12-01,1</div><div class="line">2018-12-01,12</div><div class="line">2018-11-01,1</div><div class="line">2018-12-01,1</div><div class="line">2018-12-01,1</div><div class="line">2018-12-02,1</div><div class="line">2018-11-02,3</div><div class="line">2018-12-01,2</div><div class="line">2018-12-01,1</div><div class="line">2018-12-04,11</div><div class="line">2018-11-03,1</div><div class="line">2018-12-04,1</div></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">awk -F'\t' '&#123;a[substr($1, 1, 7)] += 1&#125;END&#123;for (i in a)&#123;printf "%s %d\n", i, a[i]&#125; &#125;' file</div></pre></td></tr></table></figure><ul><li>以上实现的是根据月份分组统计频次。</li></ul>]]></content>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> convert </tag>
            
            <tag> awk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mapreduce 结果集中在多个reduce输出part中的一个</title>
      <link href="/ITWO/2018/04/27/mapreduce-%E7%BB%93%E6%9E%9C%E9%9B%86%E4%B8%AD%E5%9C%A8%E5%A4%9A%E4%B8%AAreduce%E8%BE%93%E5%87%BA%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA/"/>
      <url>/ITWO/2018/04/27/mapreduce-%E7%BB%93%E6%9E%9C%E9%9B%86%E4%B8%AD%E5%9C%A8%E5%A4%9A%E4%B8%AAreduce%E8%BE%93%E5%87%BA%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>17G的输入数据经过map处理输出,map中只有打标记的处理,然后reduce只有cat操作,但是结果这些结果集中到一个part中</p></blockquote><a id="more"></a><h2 id="细节分析"><a href="#细节分析" class="headerlink" title="细节分析"></a>细节分析</h2><blockquote><p>先贴代码</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashPartitioner</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashPartitioner</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value, <span class="keyword">int</span> numReduceTasks)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> (key.hashCode() &amp; <span class="number">2147483647</span>) % numReduceTasks;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>map.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">sep = <span class="string">"\t"</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">details = line.strip().split(sep)</div><div class="line">card = details[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> card+sep+str(random.random())</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">main()</div></pre></td></tr></table></figure></p><p>start.sh</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/bin/bash</span></div><div class="line"></div><div class="line">hadoop fs -rmr $&#123;<span class="number">2</span>&#125;</div><div class="line">set -x</div><div class="line">hadoop jar /opt/cloudera/parcels/CDH<span class="number">-5.4</span><span class="number">.0</span><span class="number">-1.</span>cdh5<span class="number">.4</span><span class="number">.0</span>.p0<span class="number">.27</span>/jars/hadoop-streaming<span class="number">-2.6</span><span class="number">.0</span>-mr1-cdh5<span class="number">.4</span><span class="number">.0</span>.jar \</div><div class="line">        -input $&#123;<span class="number">1</span>&#125; \</div><div class="line">        -output $&#123;<span class="number">2</span>&#125; \</div><div class="line">        -file map.py \</div><div class="line">        -mapper <span class="string">"python map.py"</span> \</div><div class="line">        -reducer <span class="string">"cat"</span> \</div><div class="line">        -jobconf mapred.reduce.tasks=$&#123;<span class="number">3</span>&#125; \</div><div class="line">        -jobconf mapred.job.name=<span class="string">"reduce_test"</span></div></pre></td></tr></table></figure><blockquote><p>根据默认使用的HashPartitioner可以得出是不是key分布在同一个分区中取决于reduce个数和hashcode,所以我们需要做的就是实现一个程序计算得出这些key是不是会被放到同一个分区中.</p><p>getCode.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_n_bytes</span><span class="params">(n, b)</span>:</span></div><div class="line">    bits = b*<span class="number">8</span></div><div class="line">    <span class="keyword">return</span> (n + <span class="number">2</span>**(bits<span class="number">-1</span>)) % <span class="number">2</span>**bits - <span class="number">2</span>**(bits<span class="number">-1</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_4_bytes</span><span class="params">(n)</span>:</span></div><div class="line">    <span class="keyword">return</span> convert_n_bytes(n, <span class="number">4</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHashCode</span><span class="params">(s)</span>:</span></div><div class="line">    h = <span class="number">0</span></div><div class="line">    n = len(s)</div><div class="line">    <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(s):</div><div class="line">        h = h + ord(c)*<span class="number">31</span>**(n<span class="number">-1</span>-i)</div><div class="line">    <span class="keyword">return</span> convert_4_bytes(h)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">hashCode = getHashCode(line.strip())</div><div class="line"></div><div class="line"><span class="keyword">print</span>  (hashCode &amp; <span class="number">2147483647</span>) % reduceNum</div></pre></td></tr></table></figure><blockquote><p>经过以上的代码验证得出这些key确实是会被放到同一个partition中,后来了解到同事用的是上一个mapreduce计算逻辑的输出中的一个part作为输入,所以也就可以捋顺之前为什么会集中到reduce输出结果中的某一个part中而不分散的缘故.</p></blockquote><h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><blockquote><p>由此可见这样的方法,我们可以预估到这些key是不是交给同一个reduce去处理,但是并不能准确定位到它会出现在reduce输出结果的那个part中,只会是按照排序之后依次向下排序.所以如果所有的key最终如果只会交给一个reduce处理它的结果就只会出现在part0000中.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> mapreduce </tag>
            
            <tag> part </tag>
            
            <tag> reduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spring 优雅地关闭程序</title>
      <link href="/ITWO/2018/04/27/spring-%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E7%A8%8B%E5%BA%8F/"/>
      <url>/ITWO/2018/04/27/spring-%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E7%A8%8B%E5%BA%8F/</url>
      <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><blockquote><p>如何优雅地退出spring容器环境?</p></blockquote><a id="more"></a><h2 id="细节描述"><a href="#细节描述" class="headerlink" title="细节描述"></a>细节描述</h2><h3 id="Spring关闭钩子"><a href="#Spring关闭钩子" class="headerlink" title="Spring关闭钩子"></a>Spring关闭钩子</h3><blockquote><p>Spring在AbstractApplicationContext里维护了一个shutdownHook属性，用来关闭Spring上下文。但这个钩子不是默认生效的，需要手动调用&gt;ApplicationContext.registerShutdownHook()来开启，在自行维护ApplicationContext（而不是托管给tomcat之类的容器时），注意尽量使用&gt;ApplicationContext.registerShutdownHook()或者手动调用ApplicationContext.close()来关闭Spring上下文，否则应用退出时可能会残留资源。</p></blockquote><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><blockquote><p>Runtime.getRuntime().addShutdownHook的方法的意思就是在jvm中增加一个关闭的钩子，当jvm关闭的时候，会执行系统中已设置的所有通过addShutdownHook添加的钩子，当系统执行完这些钩子后，jvm才会关闭。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> registerShutdownHook </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python utc时间转换为本地时间</title>
      <link href="/ITWO/2018/04/27/python-utc%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%9C%AC%E5%9C%B0%E6%97%B6%E9%97%B4/"/>
      <url>/ITWO/2018/04/27/python-utc%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%9C%AC%E5%9C%B0%E6%97%B6%E9%97%B4/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>公司业务mongo库中,存了之前很多日志,但是日志中时间没有预处理,也就是说用的是默认的utc时间,我们现实中用到的东八区的时间,公司报表系统要用到这个业务字段,导出日志的时候用的是mongoexport,后续要对时间做处理,想到了用python脚本来二次处理.</p></blockquote><a id="more"></a><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>因为mongo导出的时间都是字符串,所以预先要考虑的是字符串格式的数据转换为时间格式的,然后对该时间加八小时格式化输出即可.</p></blockquote><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节:"></a>技术细节:</h2><blockquote><p>先贴代码为敬:</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> dateutil <span class="keyword">import</span> parser</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">details = line.strip().split(<span class="string">","</span>)</div><div class="line">time_string = details[<span class="number">0</span>]</div><div class="line">datetime_struct = parser.parse(time_string)</div><div class="line"><span class="comment"># print type(datetime_struct)</span></div><div class="line">o = datetime.timedelta(hours=<span class="number">8</span>)</div><div class="line">details[<span class="number">0</span>] = (datetime_struct+o).strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"\t"</span>.join(details)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">main()</div></pre></td></tr></table></figure><blockquote><p>字符串时间转为时间格式用到的是dateutil里面parser,是不是很像java里面的?这个模块不是Python自带,我们需要使用pip安装名称如下</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo pip install python-dateutil</div></pre></td></tr></table></figure><blockquote><p>然后使用datetime中的timedelta函数格式化八小时增量模块然后与之前的格式化的时间做相加操作,得到最终要的东八区时间.</p></blockquote><h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><blockquote><p>如何打印出从某个日期往后顺延指定个数的日期,枚举出来.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> datetime</div><div class="line">start = datetime.datetime(<span class="number">2017</span>,<span class="number">10</span>,<span class="number">15</span>)</div><div class="line">zone = datetime.timedelta(days=<span class="number">1</span>)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">184</span>):</div><div class="line">    day = start + zone*i</div><div class="line">    <span class="keyword">print</span> datetime.datetime.strftime(day,<span class="string">"%Y-%m-%d"</span>)</div></pre></td></tr></table></figure><blockquote><p>思路:推算之前大概预估下你要统计多久的顺延的日子,然后使用timedelta以此累加,遍历打印就是最终想要的结果.</p><p>ps:以此类推:某个特定小时,某个特定的月份,往后顺延,大同小异.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> utc </tag>
            
            <tag> dateutil </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何在hadoop streaming mapreduce中 使用python第三方包</title>
      <link href="/ITWO/2018/04/11/%E5%A6%82%E4%BD%95%E5%9C%A8hadoop-streaming-mapreduce%E4%B8%AD-%E4%BD%BF%E7%94%A8python%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/"/>
      <url>/ITWO/2018/04/11/%E5%A6%82%E4%BD%95%E5%9C%A8hadoop-streaming-mapreduce%E4%B8%AD-%E4%BD%BF%E7%94%A8python%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>当我们需要在大数据平台使用python第三方包的时候，第一印象是在集群的每台集群都安装该第三方Python包，但是这样需要集群重启，很明显此方案扑街。<br><a id="more"></a></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>我们使用hadoop streaming提供你的压缩文件分发命令来使用我们的第三方Python包。</p></blockquote><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><blockquote><p>我们先了解下该命令：</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-archivesOptionalSpecify comma-separated archives to be unarchived on the compute machines</div></pre></td></tr></table></figure><blockquote><p>字面意思是上传多个以逗号分割的压缩包到集群然后会分发解压到各个计算节点。</p></blockquote><h3 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h3><blockquote><p>打包集成python和第三方python包。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 需要使用第三方库如bs4,numpy等时，需要用到虚拟环境virtualenv</span></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> virtualenv的使用</span></div><div class="line"><span class="meta">#</span><span class="bash"> 安装</span></div><div class="line"></div><div class="line">pip install virtualenv</div><div class="line"><span class="meta">#</span><span class="bash"> 新建虚拟环境</span></div><div class="line"></div><div class="line">virtualenv kxvp</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 使得虚拟环境的路径为相对路径</span></div><div class="line"></div><div class="line">virtualenv --relocatable kxvp</div><div class="line"><span class="meta">#</span><span class="bash"> 激活虚拟环境</span></div><div class="line"></div><div class="line">source kxvp/bin/activate</div><div class="line"><span class="meta">#</span><span class="bash"> 如果想退出，可以使用下面的命令</span></div><div class="line"></div><div class="line">deactivate</div><div class="line"><span class="meta">#</span><span class="bash"> 激活后直接安装各种需要的包</span></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> pip install XXX</span></div><div class="line"><span class="meta">#</span><span class="bash"> 压缩环境包</span></div><div class="line"></div><div class="line">tar -czf kxvp.tar.gz kxvp</div></pre></td></tr></table></figure><blockquote><p>上传到集群客户端</p></blockquote><h3 id="编写测试脚本"><a href="#编写测试脚本" class="headerlink" title="编写测试脚本"></a>编写测试脚本</h3><blockquote><p>test.sh</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line"></div><div class="line">hadoop fs -rmr $&#123;2&#125;</div><div class="line"></div><div class="line">hadoop jar /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/hadoop-streaming-2.6.0-cdh5.4.0.jar \</div><div class="line">        -input $&#123;1&#125;\</div><div class="line">        -output $&#123;2&#125; \</div><div class="line">        -file map.py \</div><div class="line">        -mapper "kx/kxvp/bin/python map.py" \</div><div class="line">-cacheArchive '/user/upsmart/koulb/kxvp.tar.gz#kx'\</div><div class="line">        -jobconf mapred.reduce.tasks=0 \</div><div class="line">        -jobconf mapred.job.name="cache_archive_test"</div></pre></td></tr></table></figure><blockquote><p>map.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator = <span class="string">','</span>)</span>:</span></div><div class="line"><span class="keyword">print</span> np.__version__</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure><blockquote><p>tip:Python的执行路径注意要加上#后面的前缀</p></blockquote><h3 id="结果验证"><a href="#结果验证" class="headerlink" title="结果验证"></a>结果验证</h3><blockquote><p>看下集群客户端的numpy版本</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">upsmart@cluster-8:~/test_tmp$ python</div><div class="line">Python 2.7.6 (default, Oct 26 2016, 20:30:19) </div><div class="line">[GCC 4.8.4] on linux2</div><div class="line">Type "help", "copyright", "credits" or "license" for more information.</div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import numpy</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span> numpy.__version__</span></div><div class="line">1.8.2</div></pre></td></tr></table></figure><blockquote><p>看下mapreduce输出的结果</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">upsmart@cluster-8:~/test_tmp$ hadoop fs -getmerge koulb/test/p* rs</div><div class="line">upsmart@cluster-8:~/test_tmp$ more rs</div><div class="line">1.14.2</div></pre></td></tr></table></figure><blockquote><p>不一样验证通过.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> streaming </tag>
            
            <tag> python </tag>
            
            <tag> mapreduce </tag>
            
            <tag> numpy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>shell 遍历多级目录取文件的第一行</title>
      <link href="/ITWO/2018/04/08/shell-%E9%81%8D%E5%8E%86%E5%A4%9A%E7%BA%A7%E7%9B%AE%E5%BD%95%E5%8F%96%E6%96%87%E4%BB%B6%E7%9A%84%E7%AC%AC%E4%B8%80%E8%A1%8C/"/>
      <url>/ITWO/2018/04/08/shell-%E9%81%8D%E5%8E%86%E5%A4%9A%E7%BA%A7%E7%9B%AE%E5%BD%95%E5%8F%96%E6%96%87%E4%BB%B6%E7%9A%84%E7%AC%AC%E4%B8%80%E8%A1%8C/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>数据取样，从当前目录下去遍历多级目录拿到每个文件的第一行数据输出到一个文件中。<br><a id="more"></a></p></blockquote><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><blockquote><p>当听到该需求时，注意点有两点</p></blockquote><ol><li>多级目录</li><li>取文件的第一行</li></ol><blockquote><p>for循环去递归遍历</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>viewFile.sh<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line">function getdir()&#123;</div><div class="line">    for element in `ls $1`</div><div class="line">    do  </div><div class="line">        dir_or_file=$1"/"$element</div><div class="line">        if [ -d $dir_or_file ]</div><div class="line">        then </div><div class="line">            getdir $dir_or_file</div><div class="line">        else</div><div class="line">           head -1 $dir_or_file</div><div class="line">        fi  </div><div class="line">    done</div><div class="line">&#125;</div><div class="line">root_dir="/home/test/multiFolder"</div><div class="line">getdir $root_dir</div></pre></td></tr></table></figure></p><p>代码如上请笑纳。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> file </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mysql 和mongo 导入数据总结</title>
      <link href="/ITWO/2018/04/04/mysql-%E5%92%8Cmongo-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E6%80%BB%E7%BB%93/"/>
      <url>/ITWO/2018/04/04/mysql-%E5%92%8Cmongo-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>线上系统环境迁移，数据部分mysql和mongo需要迁移，大部分的数据通过dump，已经迁移过去，迁移过程中会有增量的数据产生，这部分数据要怎么做到无缝迁移。<br><a id="more"></a></p><h2 id="实现分析"><a href="#实现分析" class="headerlink" title="实现分析"></a>实现分析</h2><p>因为系统落地之前都会放到队列里面等待消费，然后落库，所以新系统保证服务正常以后，域名解析到新环境，然后流程环节知道队列，等待老版环境队列消费完了而且ngnix中无用户请求记录进来（因为域名解析会有几分钟的时间），我们开始提取增量的数据，mysql记录的是表记录的最大id，mongo记录也是最大的集合objectId，然后批量导出。</p></blockquote><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><h3 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">导出</span></div><div class="line">mysql -uupsmart -p dbname -e 'select * from t where id&gt;max(id)' &gt;new_data.tsv</div><div class="line"><span class="meta">#</span><span class="bash">导入</span></div><div class="line">mysqlimport [options] db_name textfile1 ...</div></pre></td></tr></table></figure><blockquote><p>tip①:max(id)为dump之前记录的最大id。<br>tip②:mysqllimport导入的时候一定要指定-local，当然这部分属于options，或者写的是绝对路径否则会报错，默认找的是和mysqlimport命令同一路径下面的文件<br>tip③:dbname紧贴要导入的文件，而且textfile1的前缀名即为表名（.之前的那货）</p></blockquote><h3 id="mongo"><a href="#mongo" class="headerlink" title="mongo"></a>mongo</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">导出</span></div><div class="line">mongoexport -d dbanme -c collname --type=json -o new_data.csv --query='&#123;"_id":"&#123;"$gt":ObjectId("max(id)")&#125;"&#125;' </div><div class="line"><span class="meta">#</span><span class="bash">导入</span></div><div class="line">mongoimport  -d dbanme -c collname  --type=json --file new_data.csv</div></pre></td></tr></table></figure><blockquote><p>tip:本来打算是导出的时候指定csv格式然后导出，但是使用mongexport制定–type=csv的时候不能导出全部的字段，后来选择了默认的json格式导出。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> mongo </tag>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>清洗流水之去除字段中多余的分隔符</title>
      <link href="/ITWO/2018/03/30/%E6%B8%85%E6%B4%97%E6%B5%81%E6%B0%B4%E4%B9%8B%E5%8E%BB%E9%99%A4%E5%AD%97%E6%AE%B5%E4%B8%AD%E5%A4%9A%E4%BD%99%E7%9A%84%E5%88%86%E9%9A%94%E7%AC%A6/"/>
      <url>/ITWO/2018/03/30/%E6%B8%85%E6%B4%97%E6%B5%81%E6%B0%B4%E4%B9%8B%E5%8E%BB%E9%99%A4%E5%AD%97%E6%AE%B5%E4%B8%AD%E5%A4%9A%E4%BD%99%E7%9A%84%E5%88%86%E9%9A%94%E7%AC%A6/</url>
      <content type="html"><![CDATA[<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><blockquote><p>正常的公司流水是47个字段，在做ETL的时候发现里面用分隔符去切割流水处理发现有超过47长度的，毋庸置疑肯定是其中有个别字段中含有分隔符，后来定位到是商户地址中含有分隔符而且不规则会出现多个，现在需要做的是将商户名称中的分隔符替换为空，然后重新拼装成我们需要的流水输出。<br><a id="more"></a></p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>直接贴代码</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeDirtyData</span><span class="params">(sep=<span class="string">","</span>)</span>:</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">details = line.strip().split(sep,<span class="number">39</span>)</div><div class="line">bad_col = details[<span class="number">39</span>].split(sep)[:<span class="number">-7</span>]</div><div class="line"><span class="keyword">if</span>(len(bad_col)&gt;<span class="number">1</span>):</div><div class="line">fix_col = <span class="string">""</span>.join(bad_col)</div><div class="line"><span class="keyword">print</span> <span class="string">"%s,%s,%s"</span> % (sep.join(details[:<span class="number">39</span>]),fix_col,sep.join(details[<span class="number">39</span>].split(sep)[<span class="number">-7</span>:]))</div><div class="line"><span class="keyword">else</span>:</div><div class="line"><span class="keyword">print</span>  line.strip()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">removeDirtyData()</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">main()</div></pre></td></tr></table></figure><h2 id="细节分析"><a href="#细节分析" class="headerlink" title="细节分析"></a>细节分析</h2><ol><li>先定位到需要的截取字段之前的位置切割，然后把后面的部分单独处理。</li><li>后面部分的数据使用[:-num]的方式，拿到脏数据中的异常字段数组</li><li>通过join的特性用空替换掉里面的分隔符</li><li>分三部分把清洗好的流水拼接起来。</li><li>当然正常的数据不用处理正常输出。</li></ol>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> join </tag>
            
            <tag> split </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hbase 批量 提取数据</title>
      <link href="/ITWO/2018/03/28/%E5%B7%A7%E7%94%A8hbase-shell-%E6%89%B9%E9%87%8F%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE/"/>
      <url>/ITWO/2018/03/28/%E5%B7%A7%E7%94%A8hbase-shell-%E6%89%B9%E9%87%8F%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE/</url>
      <content type="html"><![CDATA[<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><blockquote><p>有一批卡号的需求提取全量的指标数据，这批数据存在于hbase中，所以要考虑去做mapping，来拿到数据，首先考虑的是通过hive sql语句去做join拿到要的数据，当然也是最简单，但是该hbase集群没有装hive，就是这么意外，第二策略是使用Python访问hbase(happybase),但是也要安装很多东西，最后是使用hbase shell 拿到数据以后，再批量拼装。第三种策略则是用mapreduce去读取hbase数据存储到hdfs上.<br><a id="more"></a></p><h2 id="技术分析实现"><a href="#技术分析实现" class="headerlink" title="技术分析实现"></a>技术分析实现</h2></blockquote><h3 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> hive_hbase_test(<span class="keyword">key</span> <span class="built_in">int</span>,<span class="keyword">value</span> <span class="keyword">string</span>)</div><div class="line"><span class="keyword">stored</span> <span class="keyword">by</span> <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span> <span class="keyword">with</span> serdeproperties(<span class="string">"hbase.columns.mapping"</span>=<span class="string">":key,cf1:val"</span>) tblproperties(<span class="string">"hbase.table.name"</span>=<span class="string">"hive_hbase_test"</span>);</div></pre></td></tr></table></figure><blockquote><p>在现有hbase数据的基础上，我们建立一张外表打通hive和hbase数据的映射关系，然后使用我们熟悉的sqljoin然后 通过 hive -e 导出到本地收工。</p></blockquote><ul><li>在操作的时候出现了以下的问题这里标注下：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">org.apache.hadoop.hbase.client.RetriesExhaustedException: Can<span class="string">'t get the locations</span></div><div class="line"><span class="string">        at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:312)</span></div></pre></td></tr></table></figure><blockquote><p>从表象来看是客户端去连接zk拉取region元信息的时候没有找到，所以给出的解决方案是：<br>指定下zk集群</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hive -hiveconf hbase.zookeeper.quorum=slave1,slave2,master</div><div class="line">beeline jdbc:hive2://localhost:10000 -n user -p password --hiveconf hbase.zookeeper.quorum=slave1,slave2,master</div></pre></td></tr></table></figure><blockquote><p>最终经过验证没有问题。</p></blockquote><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><blockquote><p>此种方法没有试过，只是存在与理论中,可以参考此篇文章，优势:可以使用hbase连接池（因为是通过停thift协议通信，tcp通信）。<br><a href="https://my.oschina.net/wolfoxliu/blog/856175" target="_blank" rel="external">Hbase实战教程之happybase</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-</span></div><div class="line"><span class="comment"># !/usr/bin/env python</span></div><div class="line"><span class="keyword">import</span> happybase</div><div class="line"></div><div class="line"><span class="comment"># 初始化链接hbase的连接池</span></div><div class="line">pool = happybase.ConnectionPool(size=<span class="number">3</span>, host=<span class="string">'192.168.88.57'</span>)</div><div class="line"><span class="comment"># 获取连接</span></div><div class="line"><span class="keyword">with</span> pool.connection() <span class="keyword">as</span> connection:</div><div class="line">    <span class="comment"># 建立hbase表的操作客户端</span></div><div class="line">    table = happybase.Table(<span class="string">"xid_card"</span>, connection)</div><div class="line">    <span class="comment"># 查询该表的多个rowkey的所有数据</span></div><div class="line">    rows_dict = dict(table.rows([<span class="string">'AAABAQAAABo+XKvQN57RpLZcfCr/1TC1QOPfi1nx8FSR11qmOA4xfDDqSp0='</span>,</div><div class="line">                                 <span class="string">'AAABAQAAABoK4GyYmbTXOmwNOsGnoYLIHKkGACIizeICK0M52768gSrbQKM='</span>]))</div><div class="line">    <span class="comment"># 解析某个rowkey对应的值中的某个列族中的某一列值</span></div><div class="line">    <span class="keyword">print</span> rows_dict[<span class="string">'AAABAQAAABo+XKvQN57RpLZcfCr/1TC1QOPfi1nx8FSR11qmOA4xfDDqSp0='</span>][<span class="string">'n:card'</span>]</div></pre></td></tr></table></figure><h3 id="hbase，shell-，python"><a href="#hbase，shell-，python" class="headerlink" title="hbase，shell ，python"></a>hbase，shell ，python</h3><blockquote><p>次篇幅的重点介绍的也是这种方法。</p></blockquote><ol><li>利用shell生成要提取的hbase shell语句<blockquote><p>利用shell 拼接字符的方式把所有的查询语句生成到一个文件中，当然如果需要查询的key较多你也可以多生成到几个文件中，此处不再赘述，进而使用hbase shell 语句文件得到解析到结果。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">FILENAME=$1</div><div class="line">cat $FILENAME | while read LINE</div><div class="line">do</div><div class="line">echo "exists '$LINE'" &gt;&gt;temp_get</div><div class="line">echo "get 'card_md5','$LINE'" &gt;&gt;temp_get</div><div class="line">done</div><div class="line">hbase shell temp_get &gt;UDcredit-20180124-1_card_res.csv</div><div class="line"></div><div class="line">if test $? -eq 0</div><div class="line">then</div><div class="line">exit</div><div class="line">fi</div></pre></td></tr></table></figure></blockquote></li></ol><blockquote><p>要点:因为hbase shell查询出的结果中不会有key，所以这里我们需要暂存下key到文件中，并且肯定是要伴随着结果的输出，这样便于我们处理。所以shell逻辑如上。</p></blockquote><ol><li>利用Python处理结果文件为我们要的kv形式</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line">md5_aes=&#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">detail = line.strip()</div><div class="line"><span class="keyword">if</span>(<span class="string">'Table'</span> <span class="keyword">in</span> detail):</div><div class="line">lines = detail.split(<span class="string">" "</span>)</div><div class="line">md5card = lines[<span class="number">1</span>]</div><div class="line">md5_aes[md5card]=<span class="string">''</span></div><div class="line"><span class="keyword">if</span>(<span class="string">"value"</span> <span class="keyword">in</span> detail):</div><div class="line">lines = detail.split(<span class="string">"value="</span>)</div><div class="line">sm3card = lines1</div><div class="line">md5_aes[md5card]=sm3card</div><div class="line"></div><div class="line"><span class="keyword">for</span> key <span class="keyword">in</span> md5_aes.keys():</div><div class="line"><span class="keyword">print</span> key+<span class="string">","</span>+md5_aes[key]</div></pre></td></tr></table></figure><blockquote><p>利用当前行的特殊关键字来分割当前行数据，然后利用字典，拼接kv输出得到我们要的结果。</p></blockquote><h3 id="mapreduce"><a href="#mapreduce" class="headerlink" title="mapreduce"></a>mapreduce</h3><blockquote><p>先贴代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReadHBaseData</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> String[] cols = <span class="keyword">new</span> String[]&#123;&#125;;</div><div class="line"></div><div class="line">    <span class="keyword">static</span> String all = <span class="string">"all"</span>;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">        String tableName = args[<span class="number">0</span>];</div><div class="line">        String startKey = args[<span class="number">1</span>];</div><div class="line">        String endKey = args[<span class="number">2</span>];</div><div class="line">        String outPath = args[<span class="number">3</span>];</div><div class="line">        Configuration conf = getConf();</div><div class="line">        Job job = Job.getInstance(conf, <span class="string">"hbasescan"</span>);</div><div class="line"><span class="comment">//        conf.set("hbase.zookeeper.quorum", "mini-03.upsmart.com,mini-05.upsmart.com,mini-04.upsmart.com");</span></div><div class="line">        conf.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2181"</span>);</div><div class="line">        job.setJarByClass(ReadHBaseData.class);</div><div class="line"></div><div class="line">        Scan scan = <span class="keyword">new</span> Scan();</div><div class="line">        scan.setCaching(<span class="number">200</span>);</div><div class="line">        scan.setCacheBlocks(<span class="keyword">false</span>);</div><div class="line">        scan.setStartRow(startKey.getBytes());</div><div class="line">        scan.setStartRow(endKey.getBytes());</div><div class="line"><span class="comment">//        scan.setStartRow("E26D4A603E56D297135260D34ED168C2AEBFBFCC130D2D9D55D34E36EB4CF16F".getBytes());</span></div><div class="line"><span class="comment">//        scan.setStopRow("E26E1DC81B88821716F8F47670EE95F0CB60386E4743528A43CEF9285AC71D44".getBytes());</span></div><div class="line"></div><div class="line">        TableMapReduceUtil.initTableMapperJob(tableName, scan, HbaseMapper.class, ImmutableBytesWritable.class, Text.class, job);</div><div class="line">        job.setMapOutputKeyClass(ImmutableBytesWritable.class);</div><div class="line">        job.setMapOutputValueClass(Text.class);</div><div class="line">        job.setReducerClass(HbaseReduce.class);</div><div class="line">        job.setOutputKeyClass(Text.class);</div><div class="line">        job.setOutputValueClass(Text.class);</div><div class="line"><span class="comment">//        FileOutputFormat.setOutputPath(job, new Path("test/output"));</span></div><div class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(outPath));</div><div class="line"></div><div class="line">        <span class="comment">//创建目标表对象</span></div><div class="line">        <span class="comment">// Execute job and return status</span></div><div class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">HbaseMapper</span> <span class="keyword">extends</span> <span class="title">TableMapper</span>&lt;<span class="title">ImmutableBytesWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</div><div class="line"></div><div class="line"></div><div class="line">        <span class="comment">//拿到需要的过滤的字段</span></div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">            Configuration conf = context.getConfiguration();</div><div class="line">            cols = conf.getStrings(<span class="string">"cols"</span>);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(ImmutableBytesWritable key, Result value, Context context)</span></span></div><div class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">            <span class="keyword">for</span> (Cell cell : value.rawCells()) &#123;</div><div class="line">                String col = Bytes.toString(CellUtil.cloneQualifier(cell));</div><div class="line">                <span class="keyword">if</span> (Arrays.asList(cols).contains(all) || Arrays.asList(cols).contains(col)) &#123;</div><div class="line">                    context.write(key, <span class="keyword">new</span> Text(Bytes.toString(CellUtil.cloneQualifier(cell))</div><div class="line">                            + GlobalContant.COLON + Bytes.toString(CellUtil.cloneValue(cell))));</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">HbaseReduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">ImmutableBytesWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</div><div class="line"></div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(ImmutableBytesWritable key, Iterable&lt;Text&gt; values,</span></span></div><div class="line"><span class="function"><span class="params">                              Context context)</span></span></div><div class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">            Text text = <span class="keyword">new</span> Text(StringUtils.join(GlobalContant.TAB, values));</div><div class="line">            context.write(<span class="keyword">new</span> Text(key.get()), text);</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        Configuration conf = HBaseConfiguration.create();</div><div class="line">        Integer resCode = ToolRunner.run(conf, <span class="keyword">new</span> ReadHBaseData(), args);</div><div class="line">        <span class="keyword">if</span> (resCode == GlobalContant.SUCCESS_CODE) &#123;</div><div class="line">            System.out.println(<span class="string">"❀❀❀❀❀❀数据查询完成❀❀❀❀❀❀"</span>);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            System.err.println(<span class="string">"❀❀❀❀❀❀数据查询失败❀❀❀❀❀❀"</span>);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p></blockquote><ul><li>核心代码</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">      Scan scan = <span class="keyword">new</span> Scan();</div><div class="line">      scan.setCaching(<span class="number">200</span>);</div><div class="line">      scan.setCacheBlocks(<span class="keyword">false</span>);</div><div class="line">      scan.setStartRow(startKey.getBytes());</div><div class="line">      scan.setStartRow(endKey.getBytes());</div><div class="line">TableMapReduceUtil.initTableMapperJob(tableName, scan, HbaseMapper.class, ImmutableBytesWritable.class, Text.class, job);</div></pre></td></tr></table></figure><ul><li>集成的类</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">HbaseMapper extends TableMapper&lt;ImmutableBytesWritable, Text&gt;</div></pre></td></tr></table></figure><blockquote><p>不同于传统的mapreduce中的行字符偏移量,这里使用的是ImmutableBytesWritable,也就是hbase中的rowkey.<br>不同于传统的关系型数据库,hbase中是存在多行数据属于同一条记录,这就决定了你在map中,只能是去拼装Qualifier和value.(一行的kv处理逻辑)然后在reduce中利用v3=Iterable<t>(v2),将同一个rowkey的所有的kv使用制表符作为分隔符输出到hdfs中,这样的做的好处有二:其一可以用来存储到其他集群的hbase中;其二可以将该数据存储到es中.因为他是通用的tsv结构,而且带有kv.</t></p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> python </tag>
            
            <tag> hbase </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nohup &amp; &gt; 使用解释</title>
      <link href="/ITWO/2018/03/14/nohup-%E4%BD%BF%E7%94%A8%E8%A7%A3%E9%87%8A/"/>
      <url>/ITWO/2018/03/14/nohup-%E4%BD%BF%E7%94%A8%E8%A7%A3%E9%87%8A/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>我们在运行服务或者其他程序的时候经常这样启动进程。<a id="more"></a></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup ls &gt;out.log 2&gt;&amp;1 &amp;</div></pre></td></tr></table></figure><h2 id="细节分析"><a href="#细节分析" class="headerlink" title="细节分析"></a>细节分析</h2><blockquote><p>&amp; 可以免疫SIGINT（sign of interuput），也就是说他可以用于程序后台运行，但是关闭当前shell session就会退出该程序。<br>nohup 的运用是为了免疫SIGHUP信号，可以避免挂起，将程序的输出重定向到nohup.out中，也就是说免疫回话级别的关闭，但是不免疫SIGINT信号，也就是我们所用的Ctrl+C。<br>综上所属我们需要做的就是结合两者的优点，可以这样使用从而真正意义上实现程序后台运行，而且免疫session关闭而导致程序退出。<br>2&gt;&amp;1 的运用是为了将标准出错重定向到标准输出。<br>nohup ls &gt;out.log 2&gt;&amp;1 &amp; 连接起来的意思就是后台挂起ls命令，并且将标准输出和标准出错都作为输出重定向到out.log中，我们可以使用tail -f out.log监控程序的运行过程。<br>tip:当当前session还为关闭，我们可以使用Jobs命令来查看当前会话下面有多少挂起的程序，如果想停止自己启动的程序，可以使用fg %jobnumber的方式，将该任务放到前台执行然后使用Ctrl+C命令终止它的执行。但是如果当前session已经失去，我们就只能通过ps -ef 找到提交的任务然后通过kill来结束程序。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> nohup </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>maven,gradle 问题解决总结</title>
      <link href="/ITWO/2018/03/13/maven,gradle-%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%80%BB%E7%BB%93/"/>
      <url>/ITWO/2018/03/13/maven,gradle-%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="jar包找不到问题"><a href="#jar包找不到问题" class="headerlink" title="jar包找不到问题"></a>jar包找不到问题<a id="more"></a></h2><blockquote><p>遇到此类问题，肯定第一思路是配置正确了，而且去官网私服验证过的确存在的gav，但是还是找不到，此种情况下，你需要做的是把原来的本地仓库下的清理干净，然后重新编译导入一次依赖一般问题就会解决，还有一种<a href="http://mvnrepository.com/" target="_blank" rel="external">官网</a>验证了，的确有但是还是拉不下来，此时在官网下方会给出该包的私服仓库地址，你可以在配置文件中，加入该私服地址，然后还是需要把你本地仓库下的清理干净，然后重新导入一边依赖，依赖包就会拉下来。<br>….未完待续</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> gradle </tag>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>idea 导入gradle项目报错</title>
      <link href="/ITWO/2018/03/13/idea-%E5%AF%BC%E5%85%A5gradle%E9%A1%B9%E7%9B%AE%E6%8A%A5%E9%94%99/"/>
      <url>/ITWO/2018/03/13/idea-%E5%AF%BC%E5%85%A5gradle%E9%A1%B9%E7%9B%AE%E6%8A%A5%E9%94%99/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>在导入一个新的gradle项目进idea时，报错如下：<a id="more"></a></p></blockquote><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Error:com/android/builder/model/AndroidProject : Unsupported major.minor version <span class="number">52.0</span>. Please use JDK <span class="number">8</span> or newer.</div><div class="line">&lt;a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html"&gt;Download JDK 8&lt;/a&gt;&lt;br&gt;&lt;a href="select.jdk"&gt;Select a JDK from the File System&lt;/a&gt;</div></pre></td></tr></table></figure><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><blockquote><p>本来是冲着后面给的错误去解决问题（传统经验害死人），后来该改的都改了，最终还是问题依旧，这才想着从前面开始解决，问了同事，同事也说是gradle的版本问题，其实根本不是，为什么不是呢，贴出官网给的答案</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Gradle runs on all major operating systems and requires only a Java JDK or JRE version 7 or higher to be installed. To check, run java -version:</div><div class="line">$ java -version</div><div class="line">java version <span class="string">"1.8.0_121"</span></div></pre></td></tr></table></figure><blockquote><p>从以上的洋文可以看出，只要是7版本以上就可以，所以就考虑到是不是idea本身的问题，在idea的设置里找了一遭，找到了<strong>它默认开启了Android Support,后来把这项支持点掉</strong>以后，重启idea,问题解决。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> idea </tag>
            
            <tag> gradle </tag>
            
            <tag> android </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>解决ubantu 谷歌浏览器打不开问题</title>
      <link href="/ITWO/2018/03/07/%E8%A7%A3%E5%86%B3ubantu-%E8%B0%B7%E6%AD%8C%E6%B5%8F%E8%A7%88%E5%99%A8%E6%89%93%E4%B8%8D%E5%BC%80%E9%97%AE%E9%A2%98/"/>
      <url>/ITWO/2018/03/07/%E8%A7%A3%E5%86%B3ubantu-%E8%B0%B7%E6%AD%8C%E6%B5%8F%E8%A7%88%E5%99%A8%E6%89%93%E4%B8%8D%E5%BC%80%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>遇到chrome/chromium启动不了</p></blockquote><a id="more"></a><h2 id="定位问题"><a href="#定位问题" class="headerlink" title="定位问题"></a>定位问题</h2><blockquote><p>在/usr/bin/./chromium-browser启动命令，　查看log输出</p><p>log输出如下：<br>[20049:20083:0302/221800.660699:FATAL:nss_util.cc(631)] NSS_VersionCheck(“3.26”) failed. NSS &gt;= 3.26 is required. Please upgrade to the latest NSS, and if you still get this error, contact your distribution maintainer.<br>已放弃 (核心已转储)</p></blockquote><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install libnss3</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> chrome </tag>
            
            <tag> ubantu </tag>
            
            <tag> chromium </tag>
            
            <tag> 打不开 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>shell 合并hdfs文件 分发 并加文件校验和</title>
      <link href="/ITWO/2018/03/06/shell-%E5%90%88%E5%B9%B6hdfs%E6%96%87%E4%BB%B6-%E5%88%86%E5%8F%91-%E5%B9%B6%E5%8A%A0%E6%96%87%E4%BB%B6%E6%A0%A1%E9%AA%8C%E5%92%8C/"/>
      <url>/ITWO/2018/03/06/shell-%E5%90%88%E5%B9%B6hdfs%E6%96%87%E4%BB%B6-%E5%88%86%E5%8F%91-%E5%B9%B6%E5%8A%A0%E6%96%87%E4%BB%B6%E6%A0%A1%E9%AA%8C%E5%92%8C/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>提供一批带有城市标识的商户号，然后在流水中匹配到卡号，最终通过设备号和卡号的映射关系，输出每个城市商户商户对应的设备号。<a id="more"></a></p></blockquote><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">MapDevice</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">MidCard</span>(<span class="params">card: <span class="type">String</span>, mid: <span class="type">String</span></span>)</span></div><div class="line"><span class="class"></span></div><div class="line"><span class="class">  <span class="title">case</span> <span class="title">class</span> <span class="title">CardDevice</span>(<span class="params">card: <span class="type">String</span>, device: <span class="type">String</span></span>)</span></div><div class="line"><span class="class"></span></div><div class="line"><span class="class"></span></div><div class="line"><span class="class">  <span class="title">case</span> <span class="title">class</span> <span class="title">CityMid</span>(<span class="params">city: <span class="type">String</span>, mid: <span class="type">String</span></span>)</span></div><div class="line"><span class="class"></span></div><div class="line"><span class="class">  <span class="title">val</span> <span class="title">comma</span> </span>= <span class="string">","</span></div><div class="line">  <span class="keyword">val</span> tab = <span class="string">"\t"</span></div><div class="line"></div><div class="line">  <span class="comment">// 从业务逻辑来看直接判断分割以后的列数更能够过滤掉脏数据，当然空行也被pass了。</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"商户数据抓取设备号"</span>).setMaster(<span class="string">"local[*]"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">    <span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// .filter(_.matches("\\S+")) 过滤空行</span></div><div class="line">    <span class="comment">// 考虑到只有city和mid的前提下，就会产生重复数据，所以要过滤以后再建表。</span></div><div class="line">    <span class="keyword">import</span> sqlContext.implicits._</div><div class="line">    <span class="keyword">val</span> midFilePath = args(<span class="number">0</span>)</div><div class="line">    <span class="keyword">val</span> cardMids = sc.textFile(midFilePath)</div><div class="line">      .filter(_.trim.split(comma, <span class="number">-1</span>).length == <span class="number">6</span>)</div><div class="line">      .map(line =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> details = line.split(comma, <span class="number">-1</span>)</div><div class="line">        details(<span class="number">0</span>) + comma + details(<span class="number">4</span>)</div><div class="line">      &#125;).distinct().map(line =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> details = line.split(comma, <span class="number">-1</span>)</div><div class="line">      <span class="type">CityMid</span>(details(<span class="number">0</span>), details(<span class="number">1</span>))</div><div class="line">    &#125;).toDF()</div><div class="line"></div><div class="line">    cardMids.registerTempTable(<span class="string">"cityMid"</span>)</div><div class="line"></div><div class="line">    <span class="comment">//    cardMids.show()</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> transFilePath = args(<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> todayMCDF = sc.newAPIHadoopFile[<span class="type">LongWritable</span>, <span class="type">Text</span>, <span class="type">LzoTextInputFormat</span>](transFilePath)</div><div class="line">      .filter(_._2.toString.split(comma, <span class="number">-1</span>).length == <span class="number">47</span>)</div><div class="line">      .map(_._2.toString.split(comma, <span class="number">-1</span>))</div><div class="line">      .map(mpc =&gt; <span class="type">MidCard</span>(mpc(<span class="number">0</span>), mpc(<span class="number">1</span>)))</div><div class="line">      .toDF()</div><div class="line"></div><div class="line">    todayMCDF.registerTempTable(<span class="string">"midcard"</span>)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">val</span> cardDevicePath = args(<span class="number">2</span>)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// .filter(_.trim.length &gt; 0) 过滤空行</span></div><div class="line">    <span class="comment">// _.device.matches("\\S+") 过滤匹配到的设备号为空</span></div><div class="line">    <span class="keyword">val</span> cardDeviceDF = sc.textFile(cardDevicePath)</div><div class="line">      .filter(_.trim.split(tab, <span class="number">-1</span>).length == <span class="number">10</span>)</div><div class="line">      .map(line =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> items = line.split(tab, <span class="number">-1</span>)</div><div class="line">        <span class="keyword">val</span> card = items(<span class="number">0</span>)</div><div class="line">        <span class="keyword">val</span> deviceId = items(<span class="number">3</span>)</div><div class="line">        <span class="type">CardDevice</span>(card, deviceId)</div><div class="line">      &#125;).filter(_.device.matches(<span class="string">"\\S+"</span>)).toDF()</div><div class="line"></div><div class="line"></div><div class="line">    cardDeviceDF.registerTempTable(<span class="string">"carddevice"</span>)</div><div class="line"></div><div class="line">    <span class="comment">//    cardDeviceDF.show(10)</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> resDF = sqlContext.sql(<span class="string">"select city,device from (select card,city from cityMid c  join cardmid m on c.mid=m.mid ) c join carddevice d on d.card=c.card group by city,device"</span>)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">//    resDF.show(5)</span></div><div class="line">    <span class="keyword">val</span> resSavePath = args(<span class="number">3</span>)</div><div class="line"></div><div class="line"></div><div class="line">    resDF.map(value =&gt; value.mkString(comma)).saveAsTextFile(resSavePath)</div><div class="line"></div><div class="line">  &#125;</div></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">#!/usr/bin/env bash</span></div><div class="line"><span class="built_in">set</span> -x</div><div class="line"></div><div class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -ne 4 ]; <span class="keyword">then</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"参数个数为<span class="variable">$#</span>个"</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"请按照如下格式输入参数"</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"bash map-device.sh 商户信息配置路径 hardin流水路径 卡号和设备号对应关系路径 结果文件存放路径"</span></div><div class="line">        <span class="built_in">exit</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># koulb/cardmid/onemid koulb/cardmid/testtrans.lzo* koulb/cardmid/card_device_sm3 koulb/cardmid/out</span></div><div class="line"></div><div class="line">midconfPath=<span class="variable">$1</span></div><div class="line">transPath=<span class="variable">$2</span></div><div class="line">cardDevicePath=<span class="variable">$3</span></div><div class="line">resPath=<span class="variable">$4</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">spark-submit \</div><div class="line">--class com.upsmart.MapDevice  \</div><div class="line">--num-executors 100 \</div><div class="line">--executor-memory 6G \</div><div class="line">--executor-cores 4 \</div><div class="line">--driver-memory 1G \</div><div class="line">--conf spark.default.parallelism=1000 \</div><div class="line">--conf spark.storage.memoryFraction=0.5 \</div><div class="line">--conf spark.shuffle.memoryFraction=0.3 \</div><div class="line">--master yarn-client map-device-1.0.jar <span class="variable">$midconfPath</span> <span class="variable">$transPath</span> <span class="variable">$cardDevicePath</span> <span class="variable">$resPath</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> [ $? -ne 0 ];<span class="keyword">then</span></div><div class="line">   <span class="built_in">exit</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line">fileName=`date -d <span class="string">"1 hour ago"</span>  +<span class="string">"%Y%m%d%H"</span>`</div><div class="line"></div><div class="line">fileFullName=<span class="variable">$fileName</span><span class="string">".csv"</span></div><div class="line">hadoop fs -getmerge <span class="variable">$resPath</span> <span class="variable">$fileFullName</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> [ $? -ne 0 ];<span class="keyword">then</span></div><div class="line">   <span class="built_in">exit</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"></div><div class="line">awk -F <span class="string">','</span> <span class="string">'&#123;print $2  &gt;$1"_""'</span><span class="variable">$fileName</span><span class="string">'"".csv"&#125;'</span> <span class="variable">$fileFullName</span></div><div class="line"></div><div class="line">rm <span class="variable">$fileFullName</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `ls`;</div><div class="line"><span class="keyword">do</span></div><div class="line">fileSuffix=`<span class="built_in">echo</span> <span class="variable">$&#123;i##*_&#125;</span>`</div><div class="line">    <span class="keyword">if</span> [ <span class="variable">$fileSuffix</span> == <span class="variable">$fileFullName</span> ];<span class="keyword">then</span></div><div class="line">    fileSum=`md5sum <span class="variable">$i</span>  |cut -d<span class="string">' '</span> -f1`</div><div class="line">    <span class="built_in">echo</span> <span class="variable">$fileSum</span> &gt;<span class="variable">$i</span><span class="string">".md5"</span></div><div class="line">    <span class="keyword">fi</span></div><div class="line"><span class="keyword">done</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> <span class="built_in">test</span> -e .*.crc</div><div class="line"><span class="keyword">then</span></div><div class="line">    rm -f .*.crc</div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><h3 id="怎么才算是有效的数据过滤？"><a href="#怎么才算是有效的数据过滤？" class="headerlink" title="怎么才算是有效的数据过滤？"></a>怎么才算是有效的数据过滤？</h3><blockquote><p>原本的思路是过滤掉空行就行，但是后续也会有角标越界的风险存在，从而过滤的最终条件为当前行按照分隔符切割以后，必须是标准列数<br>ps: java和scala都存在这样的bug,如果多行数据的最后一列为空，直接使用spit,得到的列数会少1,当然你去便利该数组，也会少个元素，必须这样使用spilt(str,-1),<br>核心代码：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">_._2.toString.split(comma, -1).length == 47</div></pre></td></tr></table></figure><h3 id="如果匹配到的设备号为空怎么办？"><a href="#如果匹配到的设备号为空怎么办？" class="headerlink" title="如果匹配到的设备号为空怎么办？"></a>如果匹配到的设备号为空怎么办？</h3><blockquote><p>开发之初，没有考虑到该因素，后来有问到数据提供的同事，不排除会存在设备好为空或者空格占位，所以使用正则过滤掉这些无意义的输出<br>代码:filter(_.device.matches(“\S+”))</p></blockquote><h3 id="怎么多列的配置文件的前提下，过滤掉同个城市下会存在重复的mid"><a href="#怎么多列的配置文件的前提下，过滤掉同个城市下会存在重复的mid" class="headerlink" title="怎么多列的配置文件的前提下，过滤掉同个城市下会存在重复的mid"></a>怎么多列的配置文件的前提下，过滤掉同个城市下会存在重复的mid</h3><blockquote><p>不多说，直接贴代码</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 考虑到只有city和mid的前提下，就会产生重复数据，所以要过滤以后再建表。</span></div><div class="line"> <span class="keyword">import</span> sqlContext.implicits._</div><div class="line"> <span class="keyword">val</span> midFilePath = args(<span class="number">0</span>)</div><div class="line"> <span class="keyword">val</span> cardMids = sc.textFile(midFilePath)</div><div class="line">   .filter(_.trim.split(comma, <span class="number">-1</span>).length == <span class="number">6</span>)</div><div class="line">   .map(line =&gt; &#123;</div><div class="line">     <span class="keyword">val</span> details = line.split(comma, <span class="number">-1</span>)</div><div class="line">     details(<span class="number">0</span>) + comma + details(<span class="number">4</span>)</div><div class="line">   &#125;).distinct().map(line =&gt; &#123;</div><div class="line">   <span class="keyword">val</span> details = line.split(comma, <span class="number">-1</span>)</div><div class="line">   <span class="type">CityMid</span>(details(<span class="number">0</span>), details(<span class="number">1</span>))</div><div class="line"> &#125;).toDF()</div></pre></td></tr></table></figure><h3 id="如何在最终结果文件中按文件分发？（shell实现以及理论上的scala实现）"><a href="#如何在最终结果文件中按文件分发？（shell实现以及理论上的scala实现）" class="headerlink" title="如何在最终结果文件中按文件分发？（shell实现以及理论上的scala实现）"></a>如何在最终结果文件中按文件分发？（shell实现以及理论上的scala实现）</h3><h4 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">fileName=`date -d <span class="string">"1 hour ago"</span>  +<span class="string">"%Y%m%d%H"</span>`</div><div class="line">fileFullName=<span class="variable">$fileName</span><span class="string">".csv"</span></div><div class="line">hadoop fs -getmerge <span class="variable">$resPath</span> <span class="variable">$fileFullName</span></div><div class="line">awk -F <span class="string">','</span> <span class="string">'&#123;print $2  &gt;$1"_""'</span><span class="variable">$fileName</span><span class="string">'"".csv"&#125;'</span> <span class="variable">$fileFullName</span></div></pre></td></tr></table></figure><blockquote><p>难点1：按第一列去分发第二列内容，参考本博客的其他文章中的awk分发文件。<br>难点2：在awk中引用变量的值</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line">koulb@koulb-ubantu:~$ a=<span class="string">"test"</span></div><div class="line">koulb@koulb-ubantu:~$ awk <span class="string">'BEGIN&#123;print "'</span><span class="variable">$a</span><span class="string">'"&#125;'</span> </div><div class="line"><span class="built_in">test</span></div></pre></td></tr></table></figure><h4 id="scala"><a href="#scala" class="headerlink" title="scala"></a>scala</h4><blockquote><p>最终的文件为多个城市对应设备号的结果，需要做的是，把第一列group by 去重，然后遍历该城市列表拿拿到对应的设备号，生成对应的结果文件。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> hdfs </tag>
            
            <tag> shell </tag>
            
            <tag> file </tag>
            
            <tag> scala </tag>
            
            <tag> awk </tag>
            
            <tag> spark </tag>
            
            <tag> suffix </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hive trim() 去除空格遇到的问题</title>
      <link href="/ITWO/2018/02/28/hive-trim-%E5%8E%BB%E9%99%A4%E7%A9%BA%E6%A0%BC%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/ITWO/2018/02/28/hive-trim-%E5%8E%BB%E9%99%A4%E7%A9%BA%E6%A0%BC%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>在提取数据时，有用到使用商户号和终端号join匹配商户信息，但是返现怎么都匹配不到，以为是这两个号可能前后有空格，所以使用trim()函数处理，但还是没有匹配到结果，后来，vi文件 set list，发现 有一字段后面有^I紧跟其后，才警觉，这丫不是tab么，后来查看源码发现，hive的trim()只对空格感兴趣，所以想起可以使用replace,但是想到通用来讲，但是考虑到使用正则好点，所以又查到hive有正则替换。</p></blockquote><a id="more"></a><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">hive <span class="number">0.10</span>.0源码</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> Text <span class="title">evaluate</span><span class="params">(Text s)</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (s == <span class="keyword">null</span>) &#123;</div><div class="line"></div><div class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    result.set(StringUtils.strip(s.toString(), <span class="string">" "</span>));</div><div class="line"></div><div class="line">    <span class="keyword">return</span> result;</div><div class="line"></div><div class="line">  &#125;</div></pre></td></tr></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">用法如下：</div><div class="line"></div><div class="line">      regexp_replace(yourcolname,'\\s+','')</div><div class="line"></div><div class="line">最后问题得以解决。​</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> hive </tag>
            
            <tag> trim </tag>
            
            <tag> 空格 </tag>
            
            <tag> tab </tag>
            
            <tag> 制表符 </tag>
            
            <tag> regex_replace </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python 拾遗</title>
      <link href="/ITWO/2018/01/30/python-%E6%8B%BE%E9%81%97/"/>
      <url>/ITWO/2018/01/30/python-%E6%8B%BE%E9%81%97/</url>
      <content type="html"><![CDATA[<h2 id="又是背景"><a href="#又是背景" class="headerlink" title="又是背景"></a>又是背景</h2><blockquote><p>python 作为工作大数据mapreduce脚本支撑语言用过一段时间了,通过这篇文章查缺补漏.<a id="more"></a></p></blockquote><h2 id="展开补漏"><a href="#展开补漏" class="headerlink" title="展开补漏"></a>展开补漏</h2><ol><li>字符串与其它类型数据连接问题</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">"hello"</span> + <span class="number">666</span></div></pre></td></tr></table></figure><blockquote><p>如上代码会报错如下:</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">TypeError: cannot concatenate <span class="string">'str'</span> <span class="keyword">and</span> <span class="string">'int'</span> objects</div></pre></td></tr></table></figure><p>解决方案如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> <span class="string">"hello"</span>+`<span class="number">666</span>`</div><div class="line">hello666</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> <span class="string">"hello"</span>+repr(<span class="number">666</span>)</div><div class="line">hello666</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> <span class="string">"hello"</span>+str(<span class="number">666</span>)</div><div class="line">hello666</div></pre></td></tr></table></figure><blockquote><p>如上的解决方案,第三种比较直观,也是常用的,反引号和repr则把结果字符串转换为合法的python表达式,现在python3中已经不再使用反引号了.<br>ps:str int long 属于数据基本类型转换,而repr属于函数</p></blockquote><ol><li>字符串与其它类型数据连接问题</li></ol>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark ListBuffer遍历</title>
      <link href="/ITWO/2018/01/25/spark-ListBuffer%E9%81%8D%E5%8E%86/"/>
      <url>/ITWO/2018/01/25/spark-ListBuffer%E9%81%8D%E5%8E%86/</url>
      <content type="html"><![CDATA[<a id="more"></a>]]></content>
      
      
    </entry>
    
    <entry>
      <title>hadoop streaming 使用中遇到的问题总结</title>
      <link href="/ITWO/2018/01/11/hadoop-streaming-%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
      <url>/ITWO/2018/01/11/hadoop-streaming-%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>hadoop生态圈中hadoop streaming占了很大的比重,因为它很好的融合了其他脚本语言作为map,reduce来处理业务逻辑,本文重点说的是使用Python或者shell遇到的问题.<br><a id="more"></a></p><h2 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h2><h3 id="last-tool-output-null"><a href="#last-tool-output-null" class="headerlink" title="last tool output null"></a>last tool output null</h3><p>报错信息如下</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">USER=lming_08  </div><div class="line">HADOOP_USER=<span class="keyword">null</span>  </div><div class="line">last tool output: |<span class="keyword">null</span>|  </div><div class="line">  </div><div class="line">java.io.IOException: Broken pipe</div></pre></td></tr></table></figure><blockquote><p>刚开始以为是 map 程序中对空行未处理导致的，后来发现是 map 中有对一个上传的文件进行读取，而程序对该配置文件,读取而且读取以后还会用正则去遍历模糊匹配关键词，在处理该文件时会执行 10 多亿次循环，导致超时了。<br>解决方案:yield block 的使用,少用正则匹配,可以利用切词然后join来完成这样的匹配,本来mapreduce就是为了空间换时间,利用集群多个节点去并行处理逻辑.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> streaming </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>给hive mapreduce分配队列和优先级</title>
      <link href="/ITWO/2018/01/10/%E7%BB%99hive-mapreduce%E5%88%86%E9%85%8D%E9%98%9F%E5%88%97%E5%92%8C%E4%BC%98%E5%85%88%E7%BA%A7/"/>
      <url>/ITWO/2018/01/10/%E7%BB%99hive-mapreduce%E5%88%86%E9%85%8D%E9%98%9F%E5%88%97%E5%92%8C%E4%BC%98%E5%85%88%E7%BA%A7/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>集群资源有限,考虑到有多个部门要用到,所以使用不同部门使用不同队列的方式来使用集群资源,这里我们使用的是Capacity Schedule分配策略,顾名思义,是给各个队列分配相应占比的资源来独立使用,而队列内部则还是使用yarn默认的FIFO Schedule分配策略,这样可以保证每个队列可设定一定比例的资源最低保证和使用上限，同时，每个用户也可以设定一定的资源使用上限以防止资源滥用。而当一个队列的资源有剩余时，可暂时将剩余资源共享给其他队列。<a id="more"></a></p></blockquote><h2 id="使用详解"><a href="#使用详解" class="headerlink" title="使用详解"></a>使用详解</h2><blockquote><p>hive –hiveconf mapreduce.job.queuename=root.fast –hiveconf mapreduce.job.name=’job name’ -f  etl.hql<br>hive<br>set mapreduce.job.queuename=root.fast;<br>set mapreduce.job.name=’job name’</p><p>yarn application  -movetoqueue  application_1478676388082_963529  -queue  root.etl #迁移任务到另一个队列</p></blockquote><p>ps:</p><blockquote><p>作业提交到的队列：mapreduce.job.queuename</p><p>作业优先级：mapreduce.job.priority，优先级默认有5个:LOW VERY_LOW NORMAL（默认） HIGH VERY_HIGH</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> mapreduce </tag>
            
            <tag> hive </tag>
            
            <tag> queue </tag>
            
            <tag> priority </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>矩阵变形记</title>
      <link href="/ITWO/2018/01/09/%E7%9F%A9%E9%98%B5%E5%8F%98%E5%BD%A2%E8%AE%B0/"/>
      <url>/ITWO/2018/01/09/%E7%9F%A9%E9%98%B5%E5%8F%98%E5%BD%A2%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>描述如下图所示:<br><img src="/ITWO/assets/rangeImg.png" alt="矩阵变换图"><br>把左边的图形转换为右边的模样<a id="more"></a></p></blockquote><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><blockquote><p>使用的是快速上手的python脚本语言,逻辑理顺了,语言只是辅助.<br>逻辑分析:<br>既要控制纵向输出的列数,又要控制横向的输出格式,所以会用到两层的for循环,在控制纵向延伸的同时,往胖的控制膨胀,纵向的长度可以看出等于传入的c+k-1,横向的宽度是为k,因为使用的是二维角标遍历,所以要考虑到越界的问题,拿最极端的第c列来模拟通用的输出函数,好比这里传入的是3,print a[2][0],a[1][1],a[0][2],可以看出输出的一维二维的角标之和等于纵向遍历的i的值,而且可以看出一维的角标为降序,截止纵向角标越界之前,我们可以得到tempColl.append(str(a[i-j][j])),输出的结果可以这么堆积,这样的就可以把横向的输出控制在i的个数内,然后讨论偏移,我们可以看出偏移部分要补位,补位的个数又和纵向遍历的i-j&gt;c-1遍历的次数相等,利用该特性,我们不用刻意去补几个空位,利用纵向遍历超出c-1时,一维角标就要越界的特性,在横向遍历的时候,i-j&gt;c-1(角标等于长度减一)几次就补几个空格,当遍历到正常输出的二维角标时,也同时套用上边的通用公式输出tempColl.append(str(a[i-j][j])).<br><strong>核心</strong>:无论二维角标怎么变换,最终肯定会控制在i-j的范围内(越界的补位(空格)).</p></blockquote><h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="comment">#!/usr/bin/env python </span></div><div class="line"></div><div class="line"><span class="comment"># final version</span></div><div class="line"><span class="comment"># print a[0][0]</span></div><div class="line"><span class="comment"># print a[1][0],a[0][1]</span></div><div class="line"><span class="comment"># print a[2][0],a[1][1],a[0][2]</span></div><div class="line"><span class="comment"># print ' ',a[2][1],a[1][2]</span></div><div class="line"><span class="comment"># print ' ',' ',a[2][2]</span></div><div class="line"></div><div class="line"><span class="comment"># 0</span></div><div class="line"><span class="comment"># 3 1</span></div><div class="line"><span class="comment"># 6 4 2</span></div><div class="line"><span class="comment">#   7 5</span></div><div class="line"><span class="comment">#     8</span></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line">c = int(raw_input(<span class="string">'输入矩形长度：'</span>))</div><div class="line">k = int(raw_input(<span class="string">'输入矩形宽度: '</span>))</div><div class="line"></div><div class="line">a = arange(c*k).reshape(c,k)</div><div class="line"><span class="keyword">print</span> a</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># lines = a.shape[0]</span></div><div class="line"><span class="comment"># lines = lines + lines-1</span></div><div class="line"></div><div class="line"><span class="comment"># rows = a.shape[0]</span></div><div class="line"></div><div class="line"></div><div class="line">lines =c+k<span class="number">-1</span></div><div class="line"></div><div class="line">rows = k</div><div class="line"></div><div class="line">sep = <span class="string">' '</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(lines):</div><div class="line">tempColl = []</div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(rows):</div><div class="line"><span class="keyword">if</span>(i-j&gt;c<span class="number">-1</span>):</div><div class="line">tempColl.append(sep)</div><div class="line"><span class="keyword">elif</span>(i-j&gt;=<span class="number">0</span>):</div><div class="line">tempColl.append(str(a[i-j][j]))</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">","</span>.join(tempColl)</div></pre></td></tr></table></figure><blockquote><p>接收输入参数来设定需要生成几行几列的数据矩阵<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">c = int(raw_input(<span class="string">'输入矩形长度：'</span>))</div><div class="line">k = int(raw_input(<span class="string">'输入矩形宽度: '</span>))</div><div class="line"></div><div class="line">a = arange(c*k).reshape(c,k)</div><div class="line"><span class="keyword">print</span> a</div></pre></td></tr></table></figure></p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> numpy </tag>
            
            <tag> 矩阵 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>crontab 使用规范</title>
      <link href="/ITWO/2018/01/02/crontab-%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/"/>
      <url>/ITWO/2018/01/02/crontab-%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/</url>
      <content type="html"><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><blockquote><p>在使用crontab定制定时任务时,没有结果输出,想去查看下log.但是没有找到,通过一下途径来定位问题.<br><a id="more"></a></p><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析:"></a>问题分析:</h2><p>①该服务有没有开启?</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">查看该服务是否开启?</div><div class="line">sudo /etc/init.d/crond status </div><div class="line">如果没有开启,启动该服务.</div><div class="line">sudo /etc/init.d/crond start</div></pre></td></tr></table></figure><blockquote><p>②确认该任务开启以后,查看log定位问题,然后并没有看到log.</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">修改rsyslog</div><div class="line">sudo vim /etc/rsyslog.d/50-default.conf</div><div class="line">cron.*              /var/log/cron.log #将cron前面的注释符去掉 </div><div class="line">重启rsyslog</div><div class="line">sudo  service rsyslog  restart</div><div class="line">查看crontab日志</div><div class="line">less  /var/log/cron.log</div></pre></td></tr></table></figure><h2 id="用法核心"><a href="#用法核心" class="headerlink" title="用法核心"></a>用法核心</h2><blockquote><p>语法规范:</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">m h  dom mon dow   command</div><div class="line">分 时 每月的第几日 每年的第几个月 每周的第几天 可执行任务</div></pre></td></tr></table></figure><blockquote><p>使用demo</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 每天的10:05输出<span class="string">"1232"</span>到<span class="built_in">log</span>中</span></div><div class="line">05 10 * * * echo '1232' &gt;&gt; /home/testuser/test.log 2&gt;&amp;1</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> crontab </tag>
            
            <tag> log </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spring boot 和layui 集合实现简单的提供页面加解密工具</title>
      <link href="/ITWO/2017/12/28/spring-boot-%E5%92%8Clayui-%E9%9B%86%E5%90%88%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E6%8F%90%E4%BE%9B%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%A7%A3%E5%AF%86%E5%B7%A5%E5%85%B7/"/>
      <url>/ITWO/2017/12/28/spring-boot-%E5%92%8Clayui-%E9%9B%86%E5%90%88%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E6%8F%90%E4%BE%9B%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%A7%A3%E5%AF%86%E5%B7%A5%E5%85%B7/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>公司现阶段有很多的加密方式,过段时间会最终只有一个SM3,所以过渡阶段会有很多的解密加密的查询解析诉求,所以借用一个下午的时间想实现下提供一个页面供同事使用,来完成以下功能:</p></blockquote><ol><li>明文到现公司的各种加密(自定义脱敏,aes,sm3).</li><li>脱敏或者aes的数据的解密操作.</li><li>脱敏和aes数据到sm3的操作.<a id="more"></a><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析:"></a>技术分析:</h2><blockquote><p>ui 选择的时候选择了快速上手的layui,可以快速封装各种DOM,java框架选择了快速搭建的spring boot,然后一步到位实现功能.</p></blockquote></li></ol><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><h3 id="整合核心点"><a href="#整合核心点" class="headerlink" title="整合核心点"></a>整合核心点</h3><blockquote><p>springboot静态资源相对路径问题,我们都知道我们在与前端绑定数据交互的时候会在resource目录下，<br>建立一个static目录用来存放用到的css和js,并建立一个template目录用来存放h5页面，此时我们需要注意的是<br><strong>这两个目录对于springboot项目来讲是透明和屏蔽掉的</strong>，所以我们在h5页面设计js路径和css路径的时候要考虑到该影响因素.</p></blockquote><h3 id="h5和layui"><a href="#h5和layui" class="headerlink" title="h5和layui"></a>h5和layui</h3><blockquote><p>具体实例如下:</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">├── java</div><div class="line">├── resources</div><div class="line">│   ├── banner.txt</div><div class="line">│   ├── faviconbak.ico</div><div class="line">│   ├── favicon.ico</div><div class="line">│   ├── static</div><div class="line">│   │   ├── js</div><div class="line">│   │   └── layui</div><div class="line">│   │       ├── css</div><div class="line">│   │       │   ├── layui.css</div><div class="line">│   │       ├── layui.all.js</div><div class="line">│   │       └── layui.js</div><div class="line">│   └── templates</div><div class="line">│       └── index.html</div></pre></td></tr></table></figure><blockquote><p>以下为在index.html中的正确写法:</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"layui/css/layui.css"</span> <span class="attr">media</span>=<span class="string">"all"</span>/&gt;</span></div></pre></td></tr></table></figure><blockquote><p>错误写法(自以为的写法):</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"../static/layui/css/layui.css"</span> <span class="attr">media</span>=<span class="string">"all"</span>/&gt;</span></div></pre></td></tr></table></figure><blockquote><p>layui和后台ajax交互部分</p></blockquote><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">&lt;script&gt;</div><div class="line"></div><div class="line">    layui.use([<span class="string">'form'</span>],<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</div><div class="line">        <span class="keyword">var</span> form = layui.form</div><div class="line">        ,$ = layui.$</div><div class="line">        ,layer = layui.layer;</div><div class="line"></div><div class="line"></div><div class="line">          <span class="comment">//监听提交</span></div><div class="line">        form.on(<span class="string">'submit(demo1)'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</div><div class="line">            $.ajax(&#123;</div><div class="line">                url: <span class="string">"/data/handle"</span>,</div><div class="line">                contentType: <span class="string">"application/json"</span>,</div><div class="line">                data: data.field, <span class="comment">//请求的附加参数，用json对象</span></div><div class="line">                method: <span class="string">'GET'</span>,</div><div class="line">                success: <span class="function"><span class="keyword">function</span> (<span class="params">res</span>) </span>&#123;</div><div class="line">                    layer.msg(res, &#123;</div><div class="line">                        time: <span class="number">20000</span>, <span class="comment">//20s后自动关闭</span></div><div class="line">                        btn: [<span class="string">'明白了'</span>, <span class="string">'知道了'</span>, <span class="string">'哦'</span>]</div><div class="line">                    &#125;);</div><div class="line">                &#125;</div><div class="line">            &#125;)</div><div class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        &#125;);</div><div class="line"></div><div class="line"></div><div class="line">    &#125;);</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">&lt;<span class="regexp">/script&gt;</span></div></pre></td></tr></table></figure><h3 id="java部分"><a href="#java部分" class="headerlink" title="java部分:"></a>java部分:</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.upsmart.controller;</div><div class="line"></div><div class="line"><span class="keyword">import</span> cn.upsmart.constant.GlobalContant;</div><div class="line"><span class="keyword">import</span> cn.upsmart.utils.HandleUtils;</div><div class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</div><div class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestParam;</div><div class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Copyright (C), 2017, 公司</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * <span class="doctag">@author</span> koulb</span></div><div class="line"><span class="comment"> * <span class="doctag">@version</span> 0.0.1</span></div><div class="line"><span class="comment"> * <span class="doctag">@desc</span> 处理数据核心类</span></div><div class="line"><span class="comment"> * <span class="doctag">@date</span> 17-12-26</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="meta">@RestController</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataHandleController</span> </span>&#123;</div><div class="line">    </div><div class="line">    </div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String aesKey = <span class="string">"fdadssfafdadssfa"</span>;</div><div class="line">    </div><div class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/data/handle"</span>)</div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">dataHandle</span><span class="params">(@RequestParam String inputdata,</span></span></div><div class="line"><span class="function"><span class="params">                             @RequestParam String dataSource,</span></span></div><div class="line"><span class="function"><span class="params">                             @RequestParam String dataType,</span></span></div><div class="line"><span class="function"><span class="params">                             @RequestParam String handleType)</span> </span>&#123;</div><div class="line">        </div><div class="line">        <span class="keyword">switch</span> (dataType) &#123;</div><div class="line">            <span class="keyword">case</span> GlobalContant.REAL:</div><div class="line">                <span class="keyword">switch</span> (handleType) &#123;</div><div class="line">                    <span class="keyword">case</span> GlobalContant.SMARTENCODE:</div><div class="line">                        <span class="keyword">return</span> HandleUtils.realToTm(inputdata, dataSource);</div><div class="line">                    <span class="keyword">case</span> GlobalContant.SM3:</div><div class="line">                        <span class="keyword">return</span> HandleUtils.realToSM3(inputdata, dataSource);</div><div class="line">                    <span class="keyword">case</span> GlobalContant.AES:</div><div class="line">                        <span class="keyword">return</span> HandleUtils.realToAes(inputdata, dataSource, aesKey);</div><div class="line">                    <span class="keyword">default</span>:</div><div class="line">                        <span class="keyword">return</span> <span class="string">"加密真实卡号时,发现错误的加密类型"</span>;</div><div class="line">                &#125;</div><div class="line">            <span class="keyword">case</span> GlobalContant.SMARTENCODE:</div><div class="line">                <span class="keyword">switch</span> (handleType) &#123;</div><div class="line">                    <span class="keyword">case</span> GlobalContant.AES:</div><div class="line">                        <span class="keyword">return</span> HandleUtils.tmToAES(inputdata, dataSource);</div><div class="line">                    <span class="keyword">case</span> GlobalContant.SM3:</div><div class="line">                        <span class="keyword">return</span> HandleUtils.tmToSM3(inputdata, dataSource);</div><div class="line">                    <span class="keyword">case</span> GlobalContant.SMARTDECODE:</div><div class="line">                        <span class="keyword">return</span> HandleUtils.tmToReal(inputdata, dataSource);</div><div class="line">                    <span class="keyword">default</span>:</div><div class="line">                        <span class="keyword">return</span> <span class="string">"处理反脱敏数据时,发现错误的处理方式"</span>;</div><div class="line">                &#125;</div><div class="line">            <span class="keyword">case</span> GlobalContant.AES:</div><div class="line">                String tmdata;</div><div class="line">                <span class="keyword">switch</span> (handleType) &#123;</div><div class="line">                    <span class="keyword">case</span> GlobalContant.DAES:</div><div class="line">                        tmdata = HandleUtils.daes(inputdata, aesKey);</div><div class="line">                        <span class="keyword">return</span> HandleUtils.tmToReal(tmdata, dataSource);</div><div class="line">                    <span class="keyword">case</span> GlobalContant.SM3:</div><div class="line">                        tmdata = HandleUtils.daes(inputdata, aesKey);</div><div class="line">                        String realdata = HandleUtils.tmToReal(tmdata, dataSource);</div><div class="line">                        <span class="keyword">return</span> HandleUtils.realToSM3(realdata, dataSource);</div><div class="line">                    <span class="keyword">case</span> GlobalContant.SMARTENCODE:</div><div class="line">                        <span class="keyword">return</span> HandleUtils.daes(inputdata, aesKey);</div><div class="line">                    <span class="keyword">default</span>:</div><div class="line">                        <span class="keyword">return</span> <span class="string">"处理AES加密的数据时,发现错误的处理方式"</span>;</div><div class="line">                &#125;</div><div class="line">        &#125;</div><div class="line">        </div><div class="line">        </div><div class="line">        <span class="keyword">return</span> <span class="string">"未知错误请联系管理员"</span>;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    </div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> boot </tag>
            
            <tag> layui </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hbase 数据导入问题总结</title>
      <link href="/ITWO/2017/12/26/hbase-%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
      <url>/ITWO/2017/12/26/hbase-%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>公司现提供一批画像需要导入到hbase中，因为该画像还需要进一步处理才能作为最终的展示指标输出，所以需要自己实现业务逻辑mapreduce处理完了转换为tsv，接着转换为hfile，或者直接导入到hbase中（跳过生成hfile过程，不建议这样，比较慢）。<br>本文总结的是在数据导入的过程中遇到的各种问题。<br><a id="more"></a></p><h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2></blockquote><p>①: 数据量大导致的Trying to load more than 32 hfiles to one family of one region</p><blockquote><p>从字面可以看出该错误是因为在每个region的每个family中只能导入32个hfiles，超过该限制就会报错。<br>该配置如下：<br>/conf/hbase-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.mapreduce.bulkload.max.hfiles.perRegion.perFamily<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>32<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure></p><p>第一思路肯定是修改该配置为9999然后重启hbase搞定，但是明显在生成环境该解决方案扑街，后来查文档得知可以通过导入的时候设置参数搞定，所以准备通过该方法实现，具体做法为：当生成hfile以后我们统计下hfile的个数，当我们设计表的时候如果只用了一个列族，实际情况的确也是一个，我们的做法就是把该参数的值定位hfile的个数加一，加载该配置然后再buldload就可以解决异常。<br>ps:该bug在高版本已经修复。</p></blockquote><p>②: 在导入数据到hbase的过程中报错如下，然后找了很久的解决方案，终于得到解决，</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">LoadIncrementalHFiles loader = <span class="keyword">new</span> LoadIncrementalHFiles(HBaseConfiguration.create(conf2));</div><div class="line">String[] args = &#123;dataNodesFsName+ bulkOutput, tableName&#125;;</div><div class="line"><span class="keyword">int</span> run = loader.run(args);</div><div class="line">ERROR mapreduce.LoadIncrementalHFiles: Encountered unrecoverable error from region server, additional details: row <span class="string">''</span> on table <span class="string">'test'</span> at region=test,,<span class="number">1513078392894</span>.d1f8ece46dc8706c9594094d6d5c15c0., hostname=hostxxx,<span class="number">60020</span>,<span class="number">1512527608669</span>, seqNum=<span class="number">2</span></div></pre></td></tr></table></figure><blockquote><p>原本从字面意思可以看出是存在空的rowkey找不到对应的region（mapping不到startkey_endkey）导致的，但是过滤了多次hdfs的key,发现并没有此问题存在，最终看了很多google的解决方案试了如下的解决办法，顺利导入数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">出现上面异常的原因是执行命令的用户权限不够： </div><div class="line">两种方案： </div><div class="line">1.给output目录（hfile的存在目录）赋予权限</div><div class="line"></div><div class="line">hadoop fs -chmod -R 777 $output</div><div class="line"></div><div class="line">2.切换成有权限操做的用户执行。eg:sudo -u hbase</div></pre></td></tr></table></figure><blockquote><p>java解决方案</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">chmod</span><span class="params">(Configuration conf, Path path, <span class="keyword">boolean</span> recursive)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">FileSystem fs = FileSystem.get(conf);</div><div class="line">FsPermission permission = <span class="keyword">new</span> FsPermission((<span class="keyword">short</span>) <span class="number">00777</span>);</div><div class="line">fs.setPermission(path, permission);</div><div class="line"></div><div class="line"><span class="keyword">if</span> (recursive) &#123;</div><div class="line">FileStatus[] fStatusArray = fs.listStatus(path);</div><div class="line"><span class="keyword">if</span> (fStatusArray != <span class="keyword">null</span> &amp;&amp; fStatusArray.length != <span class="number">0</span>) &#123;</div><div class="line"><span class="keyword">for</span> (FileStatus fStatus : fStatusArray) &#123;</div><div class="line">Path subPath = fStatus.getPath();</div><div class="line"><span class="keyword">if</span> (fs.isDirectory(subPath)) &#123;</div><div class="line">chmod(conf, subPath, recursive);</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">fs.setPermission(subPath, permission);</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>③: 没有预分区的前提下，导入数据特别慢，只分配了两个虚拟内核和两个容器，跑的很慢，只有一个reduce在跑（HBase默认建表时有一个region)，跑的很慢，设置了reduce个数也还是没有奏效，后来查询api跟踪源码发现有如下两种解决方案:</p><blockquote><p>1.需要生成hfile的情况，该方法调用如下:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">HTable table = <span class="keyword">new</span> HTable(conf, tableName);</div><div class="line">job.setReducerClass(PutSortReducer.class);</div><div class="line">Path outputDir = <span class="keyword">new</span> Path(hfileOutPath);</div><div class="line">FileOutputFormat.setOutputPath(job, outputDir);</div><div class="line">job.setMapOutputKeyClass(ImmutableBytesWritable.class);</div><div class="line">job.setMapOutputValueClass(Put.class);</div><div class="line">job.setOutputFormatClass(HFileOutputFormat.class);</div><div class="line">HFileOutputFormat.configureIncrementalLoad(job, table);</div><div class="line"></div><div class="line"><span class="comment">// Use table's region boundaries for TOP split points.</span></div><div class="line">LOG.info(<span class="string">"Looking up current regions for table "</span> + table.getName());</div><div class="line">List&lt;ImmutableBytesWritable&gt; startKeys = getRegionStartKeys(regionLocator);</div><div class="line">LOG.info(<span class="string">"Configuring "</span> + startKeys.size() + <span class="string">" reduce partitions "</span> +</div><div class="line"><span class="string">"to match current region count"</span>);</div><div class="line">job.setNumReduceTasks(startKeys.size());</div></pre></td></tr></table></figure><blockquote><p>核心代码如上，可以看出该种途径reduce的的个数和regions的个数有关系，也就是你要预分区！！！<br>默认地，当我们只是通过HBaseAdmin指定TableDescriptor来创建一张表时，start-end key无边界，region的size越来越大时，大到 一定的阀值，就会找到一个midKey将region一分为二，成为2个region,这个过 程称为分裂(region-split).而midKey则为这二个region的临界,但是你只是用来生成hfile的话，用的一直是一个reduce，没有裂变过程。</p><p>2.不需要生成Hfile，直接导入情况:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 直接写入HBase表</span></div><div class="line">TableMapReduceUtil.initTableReducerJob(tableName, <span class="keyword">null</span>, job);</div><div class="line">job.setNumReduceTasks(<span class="number">0</span>);</div><div class="line"></div><div class="line"><span class="keyword">int</span> regions = MetaTableAccessor.getRegionCount(conf, TableName.valueOf(table));</div><div class="line"><span class="keyword">if</span> (job.getNumReduceTasks() &gt; regions) &#123;</div><div class="line">job.setNumReduceTasks(regions);</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>如上可以看出来，就算你设置了，毛用没有，还是会根据regions个数去设定reduce个数，其实也可以看出来这种方法其实也用不到reduce，但是一旦你用到的（有业务要求），你还是需要预分区！！！，这种也属于start-end key无边界，region的size越来越大时，大到 一定的阀值，就会找到一个midKey将region一分为二，成为2个region,还是需要分裂。</p></blockquote><h2 id="预分区方法"><a href="#预分区方法" class="headerlink" title="预分区方法"></a>预分区方法</h2><blockquote><p>合理设计rowkey 能让各个region 的并发请求 平均分配(趋于均匀) 使IO 效率达到最高.<br><strong>不预分区导致的问题</strong>:<br>1.总是往最大start-key的region写记录，之前分裂出来的region不会再被写数据，它们都处于半满状态<br>2.split是比较耗时耗资源<br>执行参考语句如下:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">create</span> <span class="string">'split_table_test'</span>,&#123;<span class="keyword">NAME</span> =&gt;<span class="string">'cf'</span>, COMPRESSION =&gt; <span class="string">'SNAPPY'</span>&#125;, &#123;SPLITS_FILE =&gt; <span class="string">'region_split_info.txt'</span>&#125;</div></pre></td></tr></table></figure></p><p>首先就是要想明白数据的key是如何分布的，然后规划一下要分成多少region，每个region的startkey和endkey是多少，然后将规划的key写到一个文件中。<br>预分区需要将hbase.hregion.max.filesize设置一个较大的值，默认是10G（0.94.3 ） 也就是说单个region 默认大小是10G,如果你的其他数据源中的key设计的十分合理,可以直接用来做rowkey,可以利用该值设置大点,然后预估下总共需要预分区多少个,同时也就可以定位好endkey. 总行数(数据不重复)/(数据源文件大小/filesize)可以拿到分割数据的依据,然后利用split shell切割文件,同时tail -1 就可以拿到endkey,把endkey放到同一个splitfile中作为分区依据.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hbase </tag>
            
            <tag> bulkload </tag>
            
            <tag> error </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>yarn 详解</title>
      <link href="/ITWO/2017/12/22/yarn-%E8%AF%A6%E8%A7%A3/"/>
      <url>/ITWO/2017/12/22/yarn-%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>yarn 作为hadoop2.0的新特性，使用了这么久的时间，把概念重新过一遍。<br>温故知新，查缺补漏。<a id="more"></a></p></blockquote><h2 id="出现背景"><a href="#出现背景" class="headerlink" title="出现背景"></a>出现背景</h2><blockquote><p>在hadoop1.0体系中，我们经常使用client提交任务会提交给JobTracker，然后jobTracker会根据集群现有的资源分配资源给该请求,负责任务的监控和任务的重试机制（失败→重启），TaskTracker通过心跳机制把当前任务的状态以及自己的状态报告给jobTracker。<br>jobTracker的职责:</p></blockquote><ol><li>接受处理客户单提交上来的任务请求。</li><li>监控和保持TaskTracker的存活，控制map和reduce slot的数量。</li><li>监控集群上的job以及任务的执行。</li><li><p>指导 TaskTracker 启动 map 和 reduce 任务</p><blockquote><p>TaskTracker的职责</p></blockquote></li></ol><ol><li>运行map和reduce任务。</li><li>报告详情给 jobTracker。</li></ol><blockquote><p>弊端:</p></blockquote><ol><li>只有一个jobTrakcer，缺乏高可用，一旦宕机，整个集群瘫痪。</li><li>slot机制约束了map节点只能运行的节点类型，而且不能超过分配的slot上限，reduce亦然。</li></ol><h2 id="yarn的出现"><a href="#yarn的出现" class="headerlink" title="yarn的出现"></a>yarn的出现</h2><ul><li><p>ResourceManager 代替集群管理器 </p><blockquote><p>资源调度器，分配资源，监控NM，协调用户提交的应用程序，数据位置、队列、容量，ACLS(访问控制列表)。</p></blockquote></li><li><p>ApplicationMaster 代替一个专用且短暂的 JobTracker</p><blockquote><p>由NM启动，协调所有任务的执行，监控任务，实现任务的重试机制;AM和tasks都运行在NM控制的container容器中运行。<br>一个节点上的容器数量：由配置的参数和除去后台进程和操作系统之外的节点资源总量（比如总 CPU 数和总内存）共同决定。<br>得益于应用程序的代码都转移到了AM中，所以各种分布式框架只要实现了AM,定制个性化的服务，都会受YARN的支持。（MapReduce、Giraph、Storm、Spark、Tez/Impala、MPI ）</p></blockquote></li><li><p>NodeManager 代替 TaskTracker </p></li></ul><ul><li>一个分布式应用程序代替一个 MapReduce 作业</li></ul>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> mapreduce </tag>
            
            <tag> yarn </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>selenium 爬取淘宝商品明细数据</title>
      <link href="/ITWO/2017/12/21/selenium-%E7%88%AC%E5%8F%96%E6%B7%98%E5%AE%9D%E5%95%86%E5%93%81%E6%98%8E%E7%BB%86%E6%95%B0%E6%8D%AE/"/>
      <url>/ITWO/2017/12/21/selenium-%E7%88%AC%E5%8F%96%E6%B7%98%E5%AE%9D%E5%95%86%E5%93%81%E6%98%8E%E7%BB%86%E6%95%B0%E6%8D%AE/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>selenium 爬取淘宝商品明细数据<a id="more"></a></p></blockquote><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><blockquote><p>确定元素的有针对性检索:<br>①：区分输入框和带有点击相应事件的点击按钮(<strong>div&gt;p</strong>    选择父元素为 <strong>div</strong> 元素的所有 <strong>p</strong>元素。)<br>②：如果是搜索的是多级样式选择器（<strong>div p</strong> 选择 <strong>div</strong> 元素内部的所有<strong>p</strong> 元素。），这种一般会拿到多个元素返回，的确也是我们需要的多个商品item, 确保这些元素存在以后，然后进一步将这些dom树使用pyquery(python+jquery)解析<br>ps : presence_of_element_located : returns the WebElement once it is located</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>config.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">MONGO_URL = <span class="string">'localhost'</span></div><div class="line">MONGO_DB = <span class="string">'taobao'</span></div><div class="line">MONGO_TABLE = <span class="string">'productions'</span></div><div class="line"></div><div class="line">SERVER_ARGS = [<span class="string">'--disk-cache=true'</span>, <span class="string">'--load-images=false'</span>]</div></pre></td></tr></table></figure><blockquote><p>tbPage.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</div><div class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</div><div class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</div><div class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</div><div class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> mongConfig <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> pymongo</div><div class="line"></div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 启动浏览器模拟操作</span></div><div class="line"><span class="comment"># browser = webdriver.Chrome()</span></div><div class="line"><span class="comment"># 模拟浏览器环境</span></div><div class="line">browser = webdriver.PhantomJS(service_args=SERVER_ARGS)</div><div class="line"><span class="comment"># 模拟浏览器窗口大小</span></div><div class="line">browser.set_window_size(<span class="string">"1400"</span>, <span class="string">'900'</span>)</div><div class="line">wait = WebDriverWait(browser, <span class="number">10</span>)</div><div class="line">browser.get(<span class="string">"https://www.taobao.com"</span>)</div><div class="line"></div><div class="line"><span class="comment"># 初始化mongo链接</span></div><div class="line"></div><div class="line">mongoClient = pymongo.MongoClient(MONGO_URL)</div><div class="line">mongoDB = mongoClient[MONGO_DB]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 确定元素的有针对性检索:</span></div><div class="line"><span class="comment"># ①：区分输入框和带有点击相应事件的点击按钮(div&gt;p选择父元素为 &lt;div&gt; 元素的所有 &lt;p&gt; 元素。)</span></div><div class="line"><span class="comment"># ②：如果是搜索的是多级样式选择器（div p 选择 &lt;div&gt; 元素内部的所有 &lt;p&gt; 元素。），这种一般会拿到多个元素返回，的确也是我们需要的多个商品item</span></div><div class="line"><span class="comment"># 这种需要进一步将这些dom树使用pyquery(python+jquery)解析，</span></div><div class="line"><span class="comment"># presence_of_element_located : returns the WebElement once it is located</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(keyword)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        input = wait.until(</div><div class="line">            EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">"#q"</span>))</div><div class="line">        )</div><div class="line"></div><div class="line">        commit = wait.until(</div><div class="line">            EC.element_to_be_clickable((By.CSS_SELECTOR, <span class="string">"#J_TSearchForm &gt; div.search-button &gt; button"</span>))</div><div class="line">        )</div><div class="line"></div><div class="line">        <span class="comment"># 输入框填充搜素关键词</span></div><div class="line">        input.send_keys(keyword.decode(<span class="string">'utf-8'</span>))</div><div class="line"></div><div class="line">        <span class="comment"># 模拟点击搜素按钮→触发搜素</span></div><div class="line">        commit.click()</div><div class="line"></div><div class="line">        page_total = wait.until(</div><div class="line">            EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">"#mainsrp-pager &gt; div &gt; div &gt; div &gt; div.total"</span>))</div><div class="line">        )</div><div class="line">        <span class="comment"># 首页不参与分页翻页的逻辑</span></div><div class="line">        parse_content()</div><div class="line">        <span class="keyword">return</span> page_total.text</div><div class="line">    <span class="keyword">except</span> TimeoutException:</div><div class="line">        <span class="keyword">return</span> search(keyword)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">next_page</span><span class="params">(pagenum)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"正在采集第%d页数据"</span> % pagenum</div><div class="line">    now_page = wait.until(</div><div class="line">        EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">"#mainsrp-pager &gt; div &gt; div &gt; div &gt; div.form &gt; input"</span>))</div><div class="line">    )</div><div class="line"></div><div class="line">    next = wait.until(</div><div class="line">        EC.element_to_be_clickable((By.CSS_SELECTOR, <span class="string">"#mainsrp-pager &gt; div &gt; div &gt; div &gt; div.form &gt; span.btn.J_Submit"</span>))</div><div class="line">    )</div><div class="line"></div><div class="line">    now_page.clear()</div><div class="line">    now_page.send_keys(pagenum)</div><div class="line">    next.click()</div><div class="line"></div><div class="line">    <span class="comment"># 判断成功的前提是高亮的分页数字为传入的分页页码</span></div><div class="line">    WebDriverWait(browser, <span class="number">100</span>).until(</div><div class="line">        EC.text_to_be_present_in_element(</div><div class="line">            (By.CSS_SELECTOR, <span class="string">"#mainsrp-pager &gt; div &gt; div &gt; div &gt; ul &gt; li.item.active &gt; span"</span>), str(pagenum))</div><div class="line">    )</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_content</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">"#mainsrp-itemlist .items .item"</span>)))</div><div class="line"></div><div class="line">        content_html = browser.page_source</div><div class="line">        context = pq(content_html)</div><div class="line">        items = context(<span class="string">'#mainsrp-itemlist .items .item'</span>).items()</div><div class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">            product = &#123;</div><div class="line">                <span class="string">'image'</span>: item.find(<span class="string">'.pic .img'</span>).attr(<span class="string">'src'</span>),</div><div class="line">                <span class="string">'price'</span>: item.find(<span class="string">'.price'</span>).text(),</div><div class="line">                <span class="string">'deal-cnt'</span>: item.find(<span class="string">'.deal-cnt'</span>).text()[:<span class="number">-3</span>],</div><div class="line">                <span class="string">'title'</span>: item.find(<span class="string">'.title'</span>).text(),</div><div class="line">                <span class="string">'shop'</span>: item.find(<span class="string">'.shop'</span>).text(),</div><div class="line">                <span class="string">'location'</span>: item.find(<span class="string">'.location'</span>).text()</div><div class="line">            &#125;</div><div class="line">            utf_product = json.dumps(product, ensure_ascii=<span class="keyword">False</span>)</div><div class="line">            <span class="keyword">print</span> utf_product</div><div class="line">            <span class="comment"># save_to_mongo(product)</span></div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">except</span> TimeoutException:</div><div class="line">        parse_content()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mongo</span><span class="params">(product)</span>:</span></div><div class="line">    utf_title = json.dumps(product[<span class="string">'title'</span>], ensure_ascii=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">if</span> mongoDB[MONGO_TABLE].insert(product):</div><div class="line">        <span class="keyword">print</span>  <span class="string">"%s\t插入mongo成功"</span> % utf_title</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">"%s存储到mongo失败"</span> % utf_title</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">page_query</span><span class="params">(keyword)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        total = search(keyword)</div><div class="line">        total = int(re.compile(<span class="string">"(\\d+)"</span>).search(total).group(<span class="number">1</span>))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, total + <span class="number">1</span>):</div><div class="line">            next_page(i)</div><div class="line">            parse_content()</div><div class="line"></div><div class="line">    <span class="keyword">finally</span>:</div><div class="line">        browser.close()</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    keyword = <span class="string">"零食"</span></div><div class="line">    page_query(keyword)</div></pre></td></tr></table></figure></p></blockquote><h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h2><p>① 发起请求要求的必须是unicode码,否则会报错(‘utf8’ codec can’t decode byte 0xe9 in position 0: unexpected end of data), input.send_keys(keyword.decode(‘utf-8’))</p><blockquote><p>  详情参考selenium utils.py 中的如下代码:</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">keys_to_typing</span><span class="params">(value)</span>:</span></div><div class="line">    <span class="string">"""Processes the values that will be typed in the element."""</span></div><div class="line">    typing = []</div><div class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> value:</div><div class="line">        <span class="keyword">if</span> isinstance(val, Keys):</div><div class="line">            typing.append(val)</div><div class="line">        <span class="keyword">elif</span> isinstance(val, int):</div><div class="line">            val = str(val)</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(val)):</div><div class="line">                typing.append(val[i])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(val)):</div><div class="line">                typing.append(val[i])</div><div class="line">    <span class="keyword">return</span> typing</div></pre></td></tr></table></figure><blockquote><p>上面代码中提到的Keys的部分代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Keys</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Set of special keys codes.</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    NULL = <span class="string">'\ue000'</span></div><div class="line">    CANCEL = <span class="string">'\ue001'</span>  <span class="comment"># ^break</span></div><div class="line">    HELP = <span class="string">'\ue002'</span></div><div class="line">    BACKSPACE = <span class="string">'\ue003'</span></div><div class="line">    BACK_SPACE = BACKSPACE</div><div class="line">    TAB = <span class="string">'\ue004'</span></div><div class="line">    CLEAR = <span class="string">'\ue005'</span></div></pre></td></tr></table></figure></p></blockquote><p> ②   判断成功的前提是高亮的分页数字为传入的分页页码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">WebDriverWait(browser, <span class="number">100</span>).until(</div><div class="line">    EC.text_to_be_present_in_element(</div><div class="line">        (By.CSS_SELECTOR, <span class="string">"#mainsrp-pager &gt; div &gt; div &gt; div &gt; ul &gt; li.item.active &gt; span"</span>), str(pagenum))</div><div class="line">)</div></pre></td></tr></table></figure><blockquote><p>这里拿到传入的页数以后要转换为str，否则会报错如下：TypeError: coercing to Unicode: need string or buffer, int found<br>究其原因如下：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">     <span class="class"><span class="keyword">class</span> <span class="title">text_to_be_present_in_element</span><span class="params">(object)</span>:</span></div><div class="line"> <span class="string">""" An expectation for checking if the given text is present in the</span></div><div class="line"><span class="string"> specified element.</span></div><div class="line"><span class="string"> locator, text</span></div><div class="line"><span class="string"> """</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, locator, text_)</span>:</span></div><div class="line">     self.locator = locator</div><div class="line">     self.text = text_</div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, driver)</span>:</span></div><div class="line">     <span class="keyword">try</span>:</div><div class="line">         element_text = _find_element(driver, self.locator).text</div><div class="line">&amp;nbsp; &amp;nbsp; <span class="comment">#重点看这里，传入的值非String类型就会导致报错。</span></div><div class="line">         <span class="keyword">return</span> self.text <span class="keyword">in</span> element_text</div><div class="line">     <span class="keyword">except</span> StaleElementReferenceException:</div><div class="line">         <span class="keyword">return</span> <span class="keyword">False</span></div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> selenium </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hive NullPointerExcption解决</title>
      <link href="/ITWO/2017/12/19/hive-NullPointerExcption%E8%A7%A3%E5%86%B3/"/>
      <url>/ITWO/2017/12/19/hive-NullPointerExcption%E8%A7%A3%E5%86%B3/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>同事在跑去hive任务的时候，把大表放在左边，小表放在右边，出现如下错误:<br>org.apache.hadoop.hive.ql.exec.mr.ExecMapper: java.lang.NullPointerException<br><a id="more"></a></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>hive.auto.convert.join = false 关闭mapjoin的自动大小表切换，原因不详。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hive </tag>
            
            <tag> NullPointerException </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark中RDD、DataFrame和DataSet</title>
      <link href="/ITWO/2017/12/07/spark%E4%B8%ADRDD%E3%80%81DataFrame%E5%92%8CDataSet/"/>
      <url>/ITWO/2017/12/07/spark%E4%B8%ADRDD%E3%80%81DataFrame%E5%92%8CDataSet/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>分析下虽然提供了这么多的数据格式，那种适用，那种才是适合自己的。</p></blockquote><a id="more"></a><h2 id="分析细节"><a href="#分析细节" class="headerlink" title="分析细节"></a>分析细节</h2><h3 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h3><blockquote><p>我们在spark入门的时候接触到的是熟悉的RDD，</p></blockquote><h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><h3 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h3><blockquote><p>Dataset 与 RDD 相似, 然而, 并不是使用 Java 序列化或者 Kryo来序列化用于处理或者通过网络进行传输的对象. 虽然编码器和标准的序列化都负责将一个对象序列化成字节, 但编码器是动态生成的代码, 并且使用了一种允许 Spark 去执行许多像 filtering, sorting 以及 hashing 这样的操作, 而不需要将字节反序列化成对象的格式.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> RDD </tag>
            
            <tag> DataFrame </tag>
            
            <tag> DataSet </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>另类的数据结构HashMap</title>
      <link href="/ITWO/2017/12/06/%E5%8F%A6%E7%B1%BB%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84HashMap/"/>
      <url>/ITWO/2017/12/06/%E5%8F%A6%E7%B1%BB%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84HashMap/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>分析HashMap的数据结构，put，get的过程。可以简单的理解为：链表的数组。<a id="more"></a></p></blockquote><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><blockquote><p>核心代码:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))</div></pre></td></tr></table></figure><h3 id="检索过程"><a href="#检索过程" class="headerlink" title="检索过程"></a>检索过程</h3><blockquote><p>&ensp;&ensp;拿到key以后利用二次哈希函数生成hash，然后和HashTable的长度-1做与运算获得HashTable的下标，从而定位到存在于HashTable中的那个散列链表中，然后便利与key比较拿到value返回。<br>ps:HashTable的定义，Entry<k,v>[] table，数组类型的Entry<k,v></k,v></k,v></p></blockquote><h3 id="插入过程"><a href="#插入过程" class="headerlink" title="插入过程"></a>插入过程</h3><blockquote><p>&ensp;&ensp;根据key拿到hash值(二次哈希），找到hashtable中对应的下标位置，然后判断对应的链表是否为空，如果为空，则放进去然后指针指向next，如果不为空，则根据key遍历链表判断链表中的是否存在相同key，如果存在相同的key，则返回原来的值，如果不存在相同的key，则插入到链表尾部。</p></blockquote><h3 id="删除过程"><a href="#删除过程" class="headerlink" title="删除过程"></a>删除过程</h3><blockquote><p>&ensp;&ensp;根据Key拿到hash值（二次哈希）,然后根据拿到的hash值定位到Entry数组中的位置，然后比较散列链表中key找到对应的位置然后，改变指针的指向。</p></blockquote><h2 id="小知识点"><a href="#小知识点" class="headerlink" title="小知识点"></a>小知识点</h2><blockquote><p>在以前大学的时候接触到的与运算拾遗。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="number">51</span>&amp;<span class="number">9</span></div><div class="line"><span class="number">111001</span></div><div class="line"><span class="number">001000</span></div><div class="line">=<span class="number">1000</span></div></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote><p>&ensp;&ensp;HashMap其实也是一个线性的数组实现的,所以可以理解为其存储数据的容器就是一个线性数组。这可能让我们很不解，一个线性的数组怎么实现按键值对来存取数据呢？这里HashMap有做一些处理。<br>&ensp;&ensp;首先HashMap里面实现一个静态内部类Entry，其重要的属性有 key , value, next，从属性key,value我们就能很明显的看出来Entry就是HashMap键值对实现的一个基础bean，我们上面说到HashMap的基础就是一个线性数组，这个数组就是Entry[]，Map里面的内容都保存在Entry[]里面。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * The table, resized as necessary. Length MUST Always be a power of two.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">transient</span> Entry[] table;</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 数据结构 </tag>
            
            <tag> HashMap </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop mapredcue和streaming hive 三种思路实现not in join</title>
      <link href="/ITWO/2017/11/22/hadoop-mapredcue%E5%92%8Cstreaming-hive-%E4%B8%89%E7%A7%8D%E6%80%9D%E8%B7%AF%E5%AE%9E%E7%8E%B0not-in-join/"/>
      <url>/ITWO/2017/11/22/hadoop-mapredcue%E5%92%8Cstreaming-hive-%E4%B8%89%E7%A7%8D%E6%80%9D%E8%B7%AF%E5%AE%9E%E7%8E%B0not-in-join/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>公司接入市场流水，有两个路径去存储，有一天突然发现，有个路径下面流水重复，有个路径下面的流水缺失，缺失的路径下面的是生产环境用到的，所以现需要找到这部分缺失的流水，然后打补丁到该hdfs文件路径下。<br><a id="more"></a></p><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><p>首先想到的技术是hive,利用传统的类sql去解决，因为以前有做过类似的需求，left outer join 去解决。<br>第二想到的是hadoop streaming ，其实是领导要求的，用python脚本语言去实现缺失数据打补丁的需求。<br>第三个是原汁原味的hadoop mapreduce经典案例wordcount的改良，其实也是受以前有做过wordcount和使用hadoop mapreduce实现去重联想到的，其实个人觉着这种方法是最简单的。</p></blockquote><h2 id="细节实现"><a href="#细节实现" class="headerlink" title="细节实现"></a>细节实现</h2><blockquote><p>hive<br>思路解析:在hive中一张大表和一张小表去做left ouer join ，<strong>当小表mapping到大表中不存在的关联键时，补值null</strong>,这样我们就可以利用小表id is  null,然后输出a.*,来实现输出大表中有而小表中没有的数据。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> b.* <span class="keyword">from</span> bigtable b</div><div class="line"><span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> littletable l <span class="keyword">on</span> b.id=l.id</div><div class="line"><span class="keyword">where</span> l.id <span class="keyword">is</span> <span class="literal">null</span>;</div></pre></td></tr></table></figure><blockquote><p>hadoop streaming python<br>思路解析:<strong>streaming 中map输出并且经过shuffle以后得到的reduce输入文件是根据tab（默认的分割符，我们可以使用指定(KeyFieldBasedPartitioner)去达到将其他符号作为分隔符）分割后，同时配合加上-jobconf stream.num.map.output.key.fields=2 参数，使得前两个值作为key做排序后的数据</strong>，所以我们可以利用该特性，初始化一个全局的变量去存储上一条数据的关联键，然后当下一条数据进来的时候去和该值比较如果一样的话，我们将该变量的值重置为空，如果不一样的话，我们输出该条数据（从这里我们可以看出，我们需要保证，两个数据源中的数据我们必须提前确保各自是已经经过去重的。）,还有一个重点是，我们需要保证给小文件中数据打上的标签必须要比大文件中的数据打上的标签值要小，才能保证优先小表中的数据作为参考key去过滤已经存在的数据。<br>ps: Partitioner，默认为HashPartitioner，其根据key的hash值来决定进入哪个partition，每个partition被一个reduce task处理，所以partition的个数等于reduce task的个数</p></blockquote><p>到reduce端的数据demo<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">1,2,3   0</div><div class="line">1,2,3   1</div><div class="line">312312312       1</div><div class="line">a,b,c   0</div><div class="line">a,b,c   1</div><div class="line">d,e,f   0</div><div class="line">d,e,f   1</div><div class="line">,.,j..  1</div><div class="line">kljl    1</div><div class="line">lkjl    1</div><div class="line">ouroiu  1</div><div class="line">zjljlj  0</div></pre></td></tr></table></figure></p><p>start.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"></div><div class="line">hadoop fs -<span class="built_in">test</span> -e <span class="variable">$&#123;3&#125;</span></div><div class="line"><span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></div><div class="line">hadoop fs -rmr <span class="variable">$&#123;3&#125;</span></div><div class="line"><span class="keyword">fi</span></div><div class="line">hadoop jar /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/hadoop-streaming-2.6.0-cdh5.4.0.jar \</div><div class="line">        -D stream.num.map.output.key.fields=2 \</div><div class="line">        -D num.key.fields.for.partition=1 \</div><div class="line">        -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</div><div class="line">        -input <span class="variable">$&#123;1&#125;</span> <span class="variable">$&#123;2&#125;</span>\</div><div class="line">        -output <span class="variable">$&#123;3&#125;</span> \</div><div class="line">        -file map.py \</div><div class="line">        -file red.py \</div><div class="line">        -mapper <span class="string">"python map.py"</span> \</div><div class="line">        -reducer <span class="string">"python red.py"</span> \</div><div class="line">        -jobconf mapred.reduce.tasks=5 \</div><div class="line">        -jobconf mapred.job.name=<span class="string">"not_in_match"</span></div></pre></td></tr></table></figure><p>map.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> md5</div><div class="line"><span class="keyword">import</span> os</div><div class="line"></div><div class="line">filepath = os.environ[<span class="string">"map_input_file"</span>]</div><div class="line">filename = os.path.split(filepath)[<span class="number">-1</span>]</div><div class="line"></div><div class="line">sep = <span class="string">'\t'</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">detail = line.strip()</div><div class="line"><span class="keyword">if</span> filename==<span class="string">"littletable"</span>:</div><div class="line"><span class="keyword">print</span> detail+sep+<span class="string">'0'</span></div><div class="line"><span class="comment"># big table</span></div><div class="line"><span class="keyword">else</span>:</div><div class="line"><span class="keyword">print</span> detail+sep+<span class="string">'1'</span></div></pre></td></tr></table></figure></p><p>reduce.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"></div><div class="line">key_exist = <span class="keyword">None</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">detail = line.strip().split(<span class="string">"\t"</span>)[<span class="number">0</span>]</div><div class="line"><span class="keyword">if</span>(line.strip().endswith(<span class="string">'\t0'</span>)):</div><div class="line">key_exist = detail</div><div class="line"><span class="keyword">else</span>:</div><div class="line"><span class="keyword">if</span> key_exist = detail:</div><div class="line">key_exist = <span class="keyword">None</span></div><div class="line"><span class="keyword">else</span>:</div><div class="line"><span class="keyword">print</span> detail</div></pre></td></tr></table></figure><blockquote><p>hadoop mapreduce 原汤化原食<br>思路解析:<strong>在入门hadoop的时候我们都有接触过java版本的wc,其中我们可以看到redcue的输入是（k,vs）</strong>，利用该思路，我们可以改良的下wc，来实现该功能，reduce的输出是（k,sum(vs)）,我们只要保证sum(vs)==1，然后输出该key,就可以实现输出仅在大表中才有的数据。<br>彩蛋:其实利用这种特性，我们就已经可以实现去重了，因为reduce的输入已经是去重后的key然后把对应的map端输出value，拼接为集合放在后面，所以我们只要不输出reduce的value(使用NullWritable来占位)，从而实现数据去重。</p></blockquote><p>map.class<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">MapReduceBase</span> <span class="keyword">implements</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</div><div class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">        String line = value.toString();</div><div class="line">        StringTokenizer tokenizer = <span class="keyword">new</span> StringTokenizer(line);</div><div class="line">        <span class="keyword">while</span> (tokenizer.hasMoreTokens()) &#123;</div><div class="line">            word.set(tokenizer.nextToken());</div><div class="line">            output.collect(word, one);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>reduce.class</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">MapReduceBase</span> <span class="keyword">implements</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterator&lt;IntWritable&gt; values, OutputCollector&lt;Text, NullWritable&gt; output, Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">        <span class="keyword">while</span> (values.hasNext()) &#123;</div><div class="line">            sum += values.next().get();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (sum == one.get()) &#123;</div><div class="line">            output.collect(key, NullWritable.get());</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><blockquote><p>提示:在原来版本wc中我们有看到还有使用到combiner（map端的reduce）,但是使用combiner的前提是必须要保证和map的输出指定的数据类型必须是一样的，但是明显我们这里不满足，因为combinner使用的是reduce中的逻辑已经改变了输出数据的数据类型，所以要去掉或者注释掉这部分的代码。</p></blockquote><h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><blockquote><p>我们处理大数据的大前提一定是要保证门清儿<strong>各种框架的优势</strong>，然后再在此基础上使用逻辑规约数据输出我们所需要的数据．</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> streaming </tag>
            
            <tag> mapreduce </tag>
            
            <tag> hive </tag>
            
            <tag> not in </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark 本地模式处理文件时报错</title>
      <link href="/ITWO/2017/11/17/spark-%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%B6%E6%8A%A5%E9%94%99/"/>
      <url>/ITWO/2017/11/17/spark-%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%97%B6%E6%8A%A5%E9%94%99/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>公司平台需要一个工具包处理，aes→sm3的工具包。写好发布到线上以后跑yarn-client模式没有错误，但是在跑取本地模式的时候会报错如下:<a id="more"></a></p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="number">17</span>/<span class="number">11</span>/<span class="number">17</span> <span class="number">14</span>:<span class="number">48</span>:<span class="number">28</span> ERROR LiveListenerBus: Listener EventLoggingListener threw an exception</div><div class="line">java.lang.reflect.InvocationTargetException</div><div class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</div><div class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</div><div class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</div><div class="line">        at java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</div><div class="line">        at org.apache.spark.scheduler.EventLoggingListener$$anonfun$logEvent$<span class="number">3</span>.apply(EventLoggingListener.scala:<span class="number">144</span>)</div><div class="line">        at org.apache.spark.scheduler.EventLoggingListener$$anonfun$logEvent$<span class="number">3</span>.apply(EventLoggingListener.scala:<span class="number">144</span>)</div><div class="line">        at scala.Option.foreach(Option.scala:<span class="number">236</span>)</div><div class="line">        at org.apache.spark.scheduler.EventLoggingListener.logEvent(EventLoggingListener.scala:<span class="number">144</span>)</div><div class="line">        at org.apache.spark.scheduler.EventLoggingListener.onJobEnd(EventLoggingListener.scala:<span class="number">169</span>)</div><div class="line">        at org.apache.spark.scheduler.SparkListenerBus$class.onPostEvent(SparkListenerBus.scala:36)</div><div class="line">        at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:<span class="number">31</span>)</div><div class="line">        at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:<span class="number">31</span>)</div><div class="line">        at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:53)</div><div class="line">        at org.apache.spark.util.AsynchronousListenerBus.postToAll(AsynchronousListenerBus.scala:<span class="number">36</span>)</div><div class="line">        at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>$$anonfun$run$<span class="number">1</span>.apply$mcV$sp(AsynchronousListenerBus.scala:<span class="number">76</span>)</div><div class="line">        at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>$$anonfun$run$<span class="number">1</span>.apply(AsynchronousListenerBus.scala:<span class="number">61</span>)</div><div class="line">        at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>$$anonfun$run$<span class="number">1</span>.apply(AsynchronousListenerBus.scala:<span class="number">61</span>)</div><div class="line">        at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:<span class="number">1617</span>)</div><div class="line">        at org.apache.spark.util.AsynchronousListenerBus$$anon$<span class="number">1</span>.run(AsynchronousListenerBus.scala:<span class="number">60</span>)</div><div class="line">Caused by: java.io.IOException: Filesystem closed</div><div class="line">        at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:<span class="number">792</span>)</div><div class="line">        at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:<span class="number">1998</span>)</div><div class="line">        at org.apache.hadoop.hdfs.DFSOutputStream.hflush(DFSOutputStream.java:<span class="number">1959</span>)</div><div class="line">        at org.apache.hadoop.fs.FSDataOutputStream.hflush(FSDataOutputStream.java:<span class="number">130</span>)</div><div class="line">        ... <span class="number">19</span> more</div></pre></td></tr></table></figure><h2 id="问题定位"><a href="#问题定位" class="headerlink" title="问题定位"></a>问题定位</h2><blockquote><p>后来在网上有找到是因为sparkcontext使用完了没有关闭导致的，修改代码在主函数最后加了sc.stop()，问题解决。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> error </tag>
            
            <tag> spark </tag>
            
            <tag> local </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop  streaming 二次排序join的实现</title>
      <link href="/ITWO/2017/11/02/hadoop-%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8Fjoin%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
      <url>/ITWO/2017/11/02/hadoop-%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8Fjoin%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>提供一批卡号，去提取这批卡号的流水(lzo格式的交易流水)<br>一个典型的Map-Reduce过程包 括：Input-&gt;Map-&gt;Partition-&gt;Reduce-&gt;Output。<br><a id="more"></a></p><h2 id="模拟实现逻辑"><a href="#模拟实现逻辑" class="headerlink" title="模拟实现逻辑"></a>模拟实现逻辑</h2></blockquote><p><img src="/ITWO/assets/mapreduce03.jpg" alt="scrapy 流程图"></p><h2 id="配置文件如下"><a href="#配置文件如下" class="headerlink" title="配置文件如下"></a>配置文件如下</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line">hadoop fs -<span class="built_in">test</span> -d  <span class="variable">$&#123;2&#125;</span></div><div class="line"><span class="keyword">if</span> [$? -eq 0]</div><div class="line"><span class="keyword">then</span></div><div class="line">hadoop fs -rmr card_match_2/output</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line">hadoop jar ~/koulb/softjar/hadoop-streaming-2.0.0-mr1-cdh4.7.0.jar \</div><div class="line"></div><div class="line">-D map.output.key.field.separator=_ \</div><div class="line"></div><div class="line">-D num.key.fields.for.partition=1 \</div><div class="line"></div><div class="line">-D stream.map.input.ignoreKey=<span class="literal">true</span> \</div><div class="line"></div><div class="line">-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</div><div class="line"></div><div class="line">-inputformat com.hadoop.mapred.DeprecatedLzoTextInputFormat \</div><div class="line"></div><div class="line">-input <span class="variable">$&#123;1&#125;</span>\</div><div class="line"></div><div class="line">-output <span class="variable">$&#123;2&#125;</span> \</div><div class="line"></div><div class="line">-file map.py \</div><div class="line"></div><div class="line">-file red.py \</div><div class="line"></div><div class="line">-mapper <span class="string">"python map.py"</span> \</div><div class="line"></div><div class="line">-reducer <span class="string">"python red.py"</span> \</div><div class="line"></div><div class="line">-jobconf mapred.job.priority=VERY_HIGH \</div><div class="line"></div><div class="line">-jobconf mapred.reduce.tasks=40 \</div><div class="line"></div><div class="line">-jobconf mapred.job.name=<span class="string">"card_match"</span></div></pre></td></tr></table></figure><h2 id="参数普及"><a href="#参数普及" class="headerlink" title="参数普及"></a>参数普及</h2><blockquote><p>一个典型的Map-Reduce过程包 括：Input-&gt;Map-&gt;Partition-&gt;Reduce-&gt;Output。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">hadoop streaming /    </div><div class="line">-D stream.map.output.field.separator=, /    </div><div class="line">-D stream.num.map.output.key.fields=4 /    </div><div class="line">-D map.output.key.field.separator=, /    </div><div class="line">-D num.key.fields.for.partition=2 /    </div><div class="line">-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner /</div></pre></td></tr></table></figure></p><p>stream.map.output.field.separator 指定map输出时使用的分隔符<br>stream.num.map.output.key.fields 指定用上面的分隔符分割的前四部分作为map输出的key<br>map.output.key.field.separator 指定二次排序的key内部使用的分隔符<br>num.key.fields.for.partition 指定使用上面设置的分隔符,切割key出的前两部分作为二次排序的依据<br>org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner 指定分区用的分割器<br>如果不指定默认的分割器为HashedPartitioner<br>以上实现的效果为:map输出时指定以”,”为分割符的字段的前四个key,其余部分作为value,这时,map输出的key被3个”,”分割成4部分,前2部分用于Partition,前2部分相同的key切分到同一个reducer,因此reduce内部的key排序时前2部分相同的key实际上是对后面2部分排序,这样就相当于前2部分作为排序主键,后2部分作为排序的辅键.</p><h2 id="疑惑"><a href="#疑惑" class="headerlink" title="疑惑"></a>疑惑</h2><p>在使用默认的分隔符”\t”去实现二次排序,一定不要指定stream分割符和partitioner分隔符,否则会导致二次排序失效. 类似 cut -d “\t”  ??,使用java mapredue时如果直接用”\t”,就会出现结果文件里面分隔符为\t字符,是否也是同样道理?</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">-jobconf stream.num.map.output.key.fields=4 \</div><div class="line">-jobconf num.key.fields.for.partition=3 \</div><div class="line">-jobconf mapred.reduce.tasks=2 \</div><div class="line">-input koulb/aa \</div><div class="line">-output $1 \</div><div class="line">-mapper "cat" \</div><div class="line">-reducer "cat" \</div><div class="line">-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> streaming </tag>
            
            <tag> join </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spring jpa no property column found for type 解决办法</title>
      <link href="/ITWO/2017/11/02/spring-jpa-no-property-column-found-for-type-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
      <url>/ITWO/2017/11/02/spring-jpa-no-property-column-found-for-type-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>一般爆出这种错误，会明显提示那个持久化类和那个实体类，也会告诉你那个实体类中的字段未找到，触发错误的关键在于，你已经从实体类中删除了某个字段映射，但是在持久化类中还有用到包含该字段的方法，从而导致方法解析到sql语句时，找不到对应的数据库表字段（实际情况可能到不了这一步）。<a id="more"></a></p></blockquote><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><blockquote><p>检查是否存在以上描述的问题，并删除或者注释掉引发该问题的方法块，重启项目，正常运行，不报错。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> jpa </tag>
            
            <tag> column </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>scrapy 入门</title>
      <link href="/ITWO/2017/11/02/scrapy-%E5%85%A5%E9%97%A8/"/>
      <url>/ITWO/2017/11/02/scrapy-%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<p>最近在自学python中的scrapy爬虫模块，以下是一些我的理解：<a id="more"></a></p><h2 id="模块组成"><a href="#模块组成" class="headerlink" title="模块组成"></a>模块组成</h2><p><img src="/ITWO/assets/scrapylct.png" alt="scrapy 流程图"></p><h2 id="流程建立"><a href="#流程建立" class="headerlink" title="流程建立"></a>流程建立</h2><blockquote><p>自定义的spider通过请求链接访问，scheduler模块负责封装url请求的一些参数然后带着封装好的request对象去请求下载保存链接返回的资源(middlewares控制下载时候的参数:eg:设置代理),然后将Response交给spider模块中的回调函数spider处理，最终将需要的数据封装成items给item　pipelines模块去清洗。</p></blockquote><h2 id="编写顺序"><a href="#编写顺序" class="headerlink" title="编写顺序"></a>编写顺序</h2><ol><li>创建一个Scrapy项目 </li><li>定义提取的Item </li><li>编写爬取网站的 spider 并提取 Item </li><li>编写 Item Pipeline   来存储提取到的Item(即数据)</li></ol>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> scrapy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop 建立多级目录　报错误　　No such file or directory</title>
      <link href="/ITWO/2017/11/02/hadoop-%E5%BB%BA%E7%AB%8B%E5%A4%9A%E7%BA%A7%E7%9B%AE%E5%BD%95-%E6%8A%A5%E9%94%99%E8%AF%AF-No-such-file-or-directory/"/>
      <url>/ITWO/2017/11/02/hadoop-%E5%BB%BA%E7%AB%8B%E5%A4%9A%E7%BA%A7%E7%9B%AE%E5%BD%95-%E6%8A%A5%E9%94%99%E8%AF%AF-No-such-file-or-directory/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>在shell脚本想建立多层ｈｄｆｓ目录时，报错。<br>在HDFS中创建多级目录，然而总是报错：<br><a id="more"></a><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir: `/user/a/bb': No such file or directory。</div></pre></td></tr></table></figure></p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><blockquote><p>在StackOverflow上面某牛说是命令本身有问题，应该是 $HADOOP_HOME/bin/hadoop fs -mkdir -p /user/hive/warehouse，使用该命令，不再报错，问题完美解决！</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> no </tag>
            
            <tag> such </tag>
            
            <tag> file </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ubantu 下chrome 崩溃的解决办法</title>
      <link href="/ITWO/2017/11/02/ubantu-%E4%B8%8Bchrome-%E5%B4%A9%E6%BA%83%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
      <url>/ITWO/2017/11/02/ubantu-%E4%B8%8Bchrome-%E5%B4%A9%E6%BA%83%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>公司昨天晚上断电，电脑没有关掉，早上过来，重启电脑，chrome插件各种崩溃，提示重启应用可以点击了没有任何反应和启动的迹象。<a id="more"></a></p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>处理方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rm -rf</div><div class="line">~/.config/google-chrome/</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> chrome </tag>
            
            <tag> ubantu </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python 怎么随机生成15位随机数字</title>
      <link href="/ITWO/2017/11/02/python-%E6%80%8E%E4%B9%88%E9%9A%8F%E6%9C%BA%E7%94%9F%E6%88%9015%E4%BD%8D%E9%9A%8F%E6%9C%BA%E6%95%B0%E5%AD%97/"/>
      <url>/ITWO/2017/11/02/python-%E6%80%8E%E4%B9%88%E9%9A%8F%E6%9C%BA%E7%94%9F%E6%88%9015%E4%BD%8D%E9%9A%8F%E6%9C%BA%E6%95%B0%E5%AD%97/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>测试系统的时候需要造一批手机号和idfa的设备号。<a id="more"></a></p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>首先想到的是容易上手的python</p></blockquote><p>设备号</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="string">""</span>.join(random.choice(<span class="string">"0123456789"</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">15</span>))</div></pre></td></tr></table></figure><p>手机号</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">random.choice([<span class="string">'139'</span>,<span class="string">'188'</span>,<span class="string">'185'</span>,<span class="string">'136'</span>,<span class="string">'158'</span>,<span class="string">'151'</span>])+<span class="string">""</span>.join(random.choice(<span class="string">"0123456789"</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>))</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> mobile </tag>
            
            <tag> idfa </tag>
            
            <tag> imei </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>aws s3 　递归上传和下载 </title>
      <link href="/ITWO/2017/11/02/aws-s3-%E9%80%92%E5%BD%92%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/"/>
      <url>/ITWO/2017/11/02/aws-s3-%E9%80%92%E5%BD%92%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><blockquote><p>如何在aws集群中递归下载需要的文件夹下面的内容<br><a id="more"></a></p><h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><p>上传</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">aws s3 cp MyFolder s3://bucket-name -- recursive [--region us-west-2]</div></pre></td></tr></table></figure><blockquote><p>下载</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">aws s3 cp  s3://bucket-name  [--region us-west-2]　localfilePath -- recursive</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> aws </tag>
            
            <tag> s3 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>cat 和　xargs cat的区别</title>
      <link href="/ITWO/2017/10/18/cat-%E5%92%8C-xargs-cat%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/ITWO/2017/10/18/cat-%E5%92%8C-xargs-cat%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      <content type="html"><![CDATA[<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><blockquote><p>在hadoop官方文档上有看到这样的使用<br><a id="more"></a><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/bin/hadoop  jar <span class="variable">$HADOOP_HOME</span>/hadoop-streaming.jar \</span></div><div class="line">                 -archives 'hdfs://hadoop-nn1.example.com/user/me/samples/cachefile/cachedir.jar' \  </div><div class="line">                 -D mapred.map.tasks=1 \</div><div class="line">                 -D mapred.reduce.tasks=1 \ </div><div class="line">                 -D mapred.job.name="Experiment" \</div><div class="line">                 -input "/user/me/samples/cachefile/input.txt"  \</div><div class="line">                 -output "/user/me/samples/cachefile/out" \  </div><div class="line">                 -mapper "xargs cat"  \</div><div class="line">                 -reducer "cat"</div></pre></td></tr></table></figure></p><p>其中 mapper中用的可执行命令是xargs cat而redcuer用的是cat,这样的区别在哪里？</p></blockquote><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><blockquote><p>管道是实现“将前面的标准输出作为后面的标准输入”<br>xargs是实现“将标准输入作为命令的参数”</p><p>你可以试试运行：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">echo</span> <span class="string">"--help"</span>|cat</div><div class="line"><span class="built_in">echo</span> <span class="string">"--help"</span>|xargs cat</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> cat </tag>
            
            <tag> xargs </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数据集join杂谈</title>
      <link href="/ITWO/2017/10/16/%E6%95%B0%E6%8D%AE%E9%9B%86join%E6%9D%82%E8%B0%88/"/>
      <url>/ITWO/2017/10/16/%E6%95%B0%E6%8D%AE%E9%9B%86join%E6%9D%82%E8%B0%88/</url>
      <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><blockquote><p>在操作数据的时候我们经常有以下操作；<a id="more"></a></p></blockquote><ol><li>数据库。</li><li>各种语言中集合类。</li></ol><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><blockquote><p>各种集合类或者数据库中，我们操作数据无外乎，分为以下操作：增删改查。<br>增：顾名思义，新的，不存在的，操作思路，新增一条记录（db），我们拿集合类中的map做类比，我们需要做的是新增一个key，并且新增一个集合类作为values,具体怎样的集合类和业务有关，所以需要做的是实例化一个集合类，然后往vaules中插入要增加的值，然后赋值。<br>删：删，欲使之灭亡，必先使其疯狂，所以先找到它，捧它，让它显露出来嘚瑟，然后pass掉，delete from db.table where id=? (db)，集合类则也一样，所以判断它是否存在，然后remove掉，（顺序存储和链式存储有不同的区别）。<br>改：同样的，它要首先存在，所以第一步，一样无论是where检索，或者是通过map的key去找到对应的需要修改的values值，改完了，然后重新赋值给map中的原来的key.<br>查：就不说了。</p></blockquote><h2 id="python-demo-结尾"><a href="#python-demo-结尾" class="headerlink" title="python demo 结尾:"></a>python demo 结尾:</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># coding=utf-8</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span><span class="params">()</span>:</span></div><div class="line">    mobile_id=&#123;&#125;</div><div class="line">    fileInput = open(<span class="string">'config'</span>)</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        lines = fileInput.readlines()</div><div class="line">        cards = []</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines:</div><div class="line">            mc = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">            key = mc[<span class="number">0</span>]</div><div class="line">            card = mc[<span class="number">1</span>]</div><div class="line">            <span class="keyword">if</span>(key <span class="keyword">in</span> mobile_id.keys()):</div><div class="line">                oldCards = mobile_id[key]</div><div class="line">                oldCards.append(card)                </div><div class="line">                mobile_id[key] = oldCards</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                cards = []</div><div class="line">                cards.append(card)</div><div class="line">                mobile_id[key] = cards</div><div class="line">        <span class="keyword">return</span> mobile_id</div><div class="line">    <span class="keyword">finally</span>:</div><div class="line">        fileInput.close()</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    mobile_id = read_file()</div><div class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> sys.stdin:</div><div class="line">        detail = data.strip().split(<span class="string">"\t"</span>)</div><div class="line">    <span class="keyword">if</span>(detail[<span class="number">2</span>] <span class="keyword">in</span> mobile_id.keys()):</div><div class="line">                cards = mobile_id[detail[<span class="number">2</span>]]</div><div class="line">                <span class="keyword">for</span> card <span class="keyword">in</span> cards:</div><div class="line">               <span class="keyword">print</span> card+<span class="string">"\t"</span>+<span class="string">"\t"</span>.join(detail[:<span class="number">2</span>])</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> join </tag>
            
            <tag> db </tag>
            
            <tag> dict </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mongo 中count的正确用法</title>
      <link href="/ITWO/2017/10/13/mongo-%E4%B8%ADcount%E7%9A%84%E6%AD%A3%E7%A1%AE%E7%94%A8%E6%B3%95/"/>
      <url>/ITWO/2017/10/13/mongo-%E4%B8%ADcount%E7%9A%84%E6%AD%A3%E7%A1%AE%E7%94%A8%E6%B3%95/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>统计大批量次的某个时间段内的记录数，第一次使用的是count(),但是慢的要死，最后回想起聚合里面可以另辟蹊径统计记录数，下面给出解决方案：<br><a id="more"></a></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="comment">#!/usr/bin/env python  </span></div><div class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> json</div><div class="line">db = MongoClient(<span class="string">'mongodb://localhost:27017/'</span>).tal</div><div class="line"></div><div class="line"></div><div class="line">start = datetime.datetime.strptime(<span class="string">'2017-09-01T'</span>,<span class="string">'%Y-%m-%dT'</span>)</div><div class="line">end = datetime.datetime.strptime(<span class="string">'2017-10-01T'</span>,<span class="string">'%Y-%m-%dT'</span>)</div><div class="line"></div><div class="line">pipeline = [</div><div class="line">     &#123;<span class="string">"$match"</span>:&#123;<span class="string">"requestTime"</span>:&#123;<span class="string">"$gte"</span>:start,<span class="string">"$lt"</span>:end&#125;&#125;&#125;,</div><div class="line">     &#123;<span class="string">"$group"</span>:&#123;<span class="string">"_id"</span>:&#123;<span class="string">"uri"</span>:<span class="string">"null"</span>&#125;,<span class="string">"count"</span>:&#123;<span class="string">"$sum"</span>:<span class="number">1</span>&#125;&#125;&#125;</div><div class="line"> ]</div><div class="line">ret_val = list(db.sysRequestWrapper.aggregate(pipeline))</div><div class="line">ret_ditc = eval(json.dumps(ret_val[<span class="number">0</span>], sort_keys=<span class="keyword">True</span>))</div><div class="line"><span class="keyword">print</span> ret_ditc[<span class="string">'count'</span>]</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> mongo </tag>
            
            <tag> count </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python 操作mongo实现查询和聚合</title>
      <link href="/ITWO/2017/10/12/python-%E6%93%8D%E4%BD%9Cmongo%E5%AE%9E%E7%8E%B0%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%81%9A%E5%90%88/"/>
      <url>/ITWO/2017/10/12/python-%E6%93%8D%E4%BD%9Cmongo%E5%AE%9E%E7%8E%B0%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%81%9A%E5%90%88/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>分月分接口统计下我部门所有接口服务每月总计收到的请求数量<a id="more"></a></p></blockquote><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><blockquote><p>从需求字面可以理解到分析的维度是<strong>月份</strong>和<strong>接口</strong>，然后再使用<strong>聚合</strong>就应该可以搞定。</p></blockquote><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><blockquote><p>&ensp;&ensp;&ensp;&ensp;本来觉着使用mongo自带的聚合就可以搞定，但是月份维度的使用则很让我为难，因为时间存储的是<strong>UTC</strong>格式的时间(eg:ISODate(“2016-10-18T17:22:04.563Z”)),但是分析维度用的只是具体到月份，所以直接使用不是很方便（其实是我没有找到解决方案，但个人理解是这样的两个维度去统计性能也会不理想），所以就考虑到使用容易实现的python来构建json格式的聚合实现，日期则使用遍历和角标结合的解决方案。具体代码如下:</p><p>测试代码test.py(测试服务器以及库和集合的连通性,实现查询数据的功能)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="comment">#!/usr/bin/env python  </span></div><div class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</div><div class="line"></div><div class="line"></div><div class="line">db = MongoClient(<span class="string">'mongodb://127.0.0.1:27017/'</span>).tal</div><div class="line"></div><div class="line">db_data = db.sysRequestWrapper.find().limit(<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> data <span class="keyword">in</span> db_data:</div><div class="line"><span class="keyword">print</span> data</div></pre></td></tr></table></figure></p><p>聚合代码 mongoAggr.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="comment">#!/usr/bin/env python  </span></div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line">db = MongoClient(<span class="string">'mongodb://127.0.0.1:27017/'</span>).tal</div><div class="line"></div><div class="line"></div><div class="line">starts=[<span class="string">'2017-01-01T'</span>,<span class="string">'2017-02-01T'</span>,<span class="string">'2017-03-01T'</span>,<span class="string">'2017-04-01T'</span>,<span class="string">'2017-05-01T'</span>,<span class="string">'2017-06-01T'</span>,<span class="string">'2017-07-01T'</span>,<span class="string">'2017-08-01T'</span>,<span class="string">'2017-09-01T'</span>,<span class="string">'2017-10-01T'</span>]</div><div class="line"><span class="keyword">for</span> index,day <span class="keyword">in</span> enumerate(starts):</div><div class="line"><span class="keyword">if</span>(index == len(starts)<span class="number">-1</span>):</div><div class="line"><span class="keyword">break</span></div><div class="line"><span class="keyword">else</span>:</div><div class="line">start = datetime.datetime.strptime(day,<span class="string">'%Y-%m-%dT'</span>)</div><div class="line">end = datetime.datetime.strptime(starts[index+<span class="number">1</span>],<span class="string">'%Y-%m-%dT'</span>)</div><div class="line">pipeline = [</div><div class="line">     &#123;<span class="string">"$match"</span>:&#123;<span class="string">"requestTime"</span>:&#123;<span class="string">"$gte"</span>:start,<span class="string">"$lt"</span>:end&#125;&#125;&#125;,</div><div class="line">     &#123;<span class="string">"$group"</span>:&#123;<span class="string">"_id"</span>:&#123;<span class="string">"uri"</span>:<span class="string">"$uri"</span>&#125;,<span class="string">"count"</span>:&#123;<span class="string">"$sum"</span>:<span class="number">1</span>&#125;&#125;&#125;</div><div class="line"> ]</div><div class="line">res =  list(db.sysRequestWrapper.aggregate(pipeline))</div><div class="line"><span class="keyword">for</span> item <span class="keyword">in</span> res:</div><div class="line">retVal = eval(json.dumps(item, sort_keys=<span class="keyword">True</span>))</div><div class="line">uri = retVal[<span class="string">'_id'</span>][<span class="string">'uri'</span>]</div><div class="line">count = retVal[<span class="string">'count'</span>]</div><div class="line"><span class="keyword">print</span> <span class="string">'%s\t%s\t%d'</span> % (day[:<span class="number">7</span>],uri,count)</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结:"></a>总结:</h2><h3 id="难点一"><a href="#难点一" class="headerlink" title="难点一:"></a>难点一:</h3><blockquote><p>&ensp;&ensp;&ensp;&ensp;纠结的时间问题，本来使用的是常规的时间，但是python不像java一样提供的是系统时间，这样导致和服务器的utc时间差八个小时，后来使用了UTC时间来规避这个问题，从而解决了查询不到的问题。</p></blockquote><h3 id="难点二"><a href="#难点二" class="headerlink" title="难点二"></a>难点二</h3><blockquote><p>多个时间区间的问题，本来考虑的是两个for循环搞定，但是灵机一动，考虑到的角标加一的解决方案。</p></blockquote><h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点:"></a>注意点:</h3><blockquote><p>结果的格式化、排序，以及str到ditc的转化。</p></blockquote><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><blockquote><p>&ensp;&ensp;&ensp;&ensp;mongo中的date类型以UTC（Coordinated Universal Time）存储，就等于GMT（格林尼治标准时）时间。所以,java读写mongo的Date时，会根据当前系统的时区与GMT进行相互转化。我猜上述转化应该是由java的mongo驱动实现的。比如，在java中，时间2017-09-27 17:57:46.055存入mongo会转化为ISODate(“2017-09-27T09:57:46.055Z”)，时间少了8小时，这个是由GMT+0800向GMT转化导致的。</p><p>&ensp;&ensp;&ensp;&ensp;而在python中，通常调用datetime.now()或datetime.today()返回当前时间，但是这两个方法只是返回系统时间，不返回时区。而且在python中查询mongo日期类型时，不会进行时区的转化，这就导致查询结果不准（时间大了8小时）。而解决这个问题的方法就是直接以utc格式的时间查询mongo，可以通过datetime.utcnow()返回utc时间，这个方法会根据系统当前时区把时间转化为utc格式，这样就可以查到正确的结果了。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> mongo </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python- 实现聚合（单机版和mapreduce版本）</title>
      <link href="/ITWO/2017/10/10/python-%E5%AE%9E%E7%8E%B0%E8%81%9A%E5%90%88%EF%BC%88%E5%8D%95%E6%9C%BA%E7%89%88%E5%92%8Cmapreduce%E7%89%88%E6%9C%AC%EF%BC%89/"/>
      <url>/ITWO/2017/10/10/python-%E5%AE%9E%E7%8E%B0%E8%81%9A%E5%90%88%EF%BC%88%E5%8D%95%E6%9C%BA%E7%89%88%E5%92%8Cmapreduce%E7%89%88%E6%9C%AC%EF%BC%89/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>公司接口国庆期间调用量比较大，领导想要统计下今年和去年国庆期间接口每天的调用量和当天接口的调用的平均耗时．</p></blockquote><a id="more"></a><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><blockquote><p>技术选型：选择了python<br>同时从需求中可以了解到涉及到时间差的运算，联想到以前用过python中的datetime模块中的timedelta（时间三角洲）．</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><h3 id="方法一-使用panda-series解决-此解决方案由同事提供"><a href="#方法一-使用panda-series解决-此解决方案由同事提供" class="headerlink" title="方法一: 使用panda series解决(此解决方案由同事提供)"></a>方法一: 使用panda series解决(此解决方案由同事提供)</h3><blockquote><p>代码如下：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="string">"""</span></div><div class="line"><span class="string"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="string">"""</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line">data=pd.read_csv(<span class="string">'1610.csv'</span>)</div><div class="line">data[<span class="string">'requestTime'</span>]=data[<span class="string">'requestTime'</span>].map(<span class="keyword">lambda</span> x:x.replace(<span class="string">'T'</span>,<span class="string">' '</span>))</div><div class="line">data[<span class="string">'responseTime'</span>]=data[<span class="string">'responseTime'</span>].map(<span class="keyword">lambda</span> x:x.replace(<span class="string">'T'</span>,<span class="string">' '</span>))</div><div class="line">data[<span class="string">'requestTime'</span>]=data[<span class="string">'requestTime'</span>].map(<span class="keyword">lambda</span> x:x.replace(<span class="string">'Z'</span>,<span class="string">''</span>))</div><div class="line">data[<span class="string">'responseTime'</span>]=data[<span class="string">'responseTime'</span>].map(<span class="keyword">lambda</span> x:x.replace(<span class="string">'Z'</span>,<span class="string">''</span>))</div><div class="line">data[<span class="string">'requestTime'</span>]=data[<span class="string">'requestTime'</span>].map(<span class="keyword">lambda</span> x:x.replace(<span class="string">'.'</span>,<span class="string">' '</span>))</div><div class="line">data[<span class="string">'responseTime'</span>]=data[<span class="string">'responseTime'</span>].map(<span class="keyword">lambda</span> x:x.replace(<span class="string">'.'</span>,<span class="string">' '</span>))</div><div class="line"></div><div class="line">data[<span class="string">'delta'</span>]=pd.Series(map(<span class="keyword">lambda</span> x,y:(datetime.datetime.strptime(x,<span class="string">'%Y-%m-%d %H:%M:%S %f'</span>)-datetime.datetime.strptime(y,<span class="string">'%Y-%m-%d %H:%M:%S %f'</span>)).total_seconds()*<span class="number">1000</span>,data[<span class="string">'responseTime'</span>],data[<span class="string">'requestTime'</span>]))</div><div class="line">data[<span class="string">'date_day'</span>]=pd.Series(map(<span class="keyword">lambda</span> x:x[:<span class="number">10</span>],data[<span class="string">'requestTime'</span>]))</div><div class="line">data_out=data.groupby([<span class="string">'uri'</span>,<span class="string">'date_day'</span>]).delta.agg([<span class="string">'mean'</span>,<span class="string">'count'</span>,<span class="string">'sum'</span>]).reset_index()</div><div class="line">data_out.to_csv(<span class="string">'16.csv'</span>,index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure><p>###方法二： 纯map解决</p><blockquote><p>这个是由两个时间的差值返回的,两个date或datetime对象相减时可以返回一个timedelta对象。<br>查看timedelta源码可以找到其中返回的有以下几个方法，如下图：</p></blockquote><p><img src="/ITWO/assets/timedela.png" alt="timedela中用到的方法"></p><blockquote><p>可以看出来，有很多有用的方法，可以求出两个时间的天数差，秒差，微秒差．<br>接口耗时我们需要的肯定是定位到毫秒即可，所以我们的解决方案是拿到微秒差然后除以1000转换为毫秒．</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compare_time</span><span class="params">(sourceTime,reqtime)</span>:</span></div><div class="line">sourceTime = datetime.strptime(sourceTime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line">reqtime = datetime.strptime(reqtime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line"><span class="comment">#retval = (reqtime-sourceTime).microseconds/1000</span></div><div class="line"><span class="keyword">return</span> retval</div></pre></td></tr></table></figure><blockquote><p>此处这么用只算到了微秒值，但是可能存在超过一秒的调用耗时，所以我们需要使用以下的方法来实现计算毫秒差值,此方法是python 2.7以后提供的，注意使用环境。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compare_time</span><span class="params">(sourceTime,reqtime)</span>:</span></div><div class="line">sourceTime = datetime.strptime(sourceTime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line">reqtime = datetime.strptime(reqtime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line"><span class="comment">#retval = (reqtime-sourceTime).microseconds/1000</span></div><div class="line">retval = (reqtime-sourceTime).total_seconds()*<span class="number">1000</span></div><div class="line"><span class="keyword">return</span> retval</div></pre></td></tr></table></figure><blockquote><p>数据demo:/quota/usernature,2017-09-24T00:00:12.504Z,2017-09-24T00:00:12.628Z<br>继续分析:既然需要分析某天某个接口唯独的指标，则我们可以将uri和日期作为key，从demo中我们可以做到使用T作为分割符分割数据一次，就可以拿到我们想要的key，然后我们使用逗号分割，计算第二项和第三项的差值（取毫秒值）做为value，同时我们考虑到同一天同一个uri的调用量很多，所以肯定是vs,我们需要定义一个list存放多个时间差值，所以中间输出值为key,vs,eg:/quota/usernature,2017-09-24,[100,200,300…..]<br>然后需要做的是，遍历所有的key，当然为了方便查看，我们需要先将key排序，然后顺序查看，然后统计vs的长度，即为我们需要的该接口当天的调用量，使用list的sum函数统计总的耗时然后除以调用量就是我们需要的平均耗时。<br>全部代码实现如下：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compare_time</span><span class="params">(sourceTime,reqtime)</span>:</span></div><div class="line">sourceTime = datetime.strptime(sourceTime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line">reqtime = datetime.strptime(reqtime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line">retval = (reqtime-sourceTime).microseconds/<span class="number">1000</span></div><div class="line"><span class="keyword">return</span> retval</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(sep=<span class="string">","</span>)</span>:</span></div><div class="line">kv = &#123;&#125;</div><div class="line">vs = []</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">detail = line.strip().split(sep)</div><div class="line">restime = detail[<span class="number">1</span>]</div><div class="line">reqtime = detail[<span class="number">2</span>]</div><div class="line">value = compare_time(restime,reqtime)</div><div class="line">key = line.strip().split(<span class="string">"T"</span>,<span class="number">1</span>)[<span class="number">0</span>].strip()</div><div class="line"><span class="keyword">if</span>(key <span class="keyword">not</span> <span class="keyword">in</span> kv.keys()):</div><div class="line">vs=[]</div><div class="line">vs.append(value)</div><div class="line">kv[key] = vs</div><div class="line"><span class="keyword">else</span>:</div><div class="line">vs.append(value)</div><div class="line">kv[key] = vs</div><div class="line">keys = sorted(kv.keys())</div><div class="line"><span class="keyword">for</span> key <span class="keyword">in</span> keys:</div><div class="line">cnt = len(kv[key])</div><div class="line">avgCnt = sum(kv[key])/cnt</div><div class="line"><span class="keyword">print</span> <span class="string">"%s\t%d\t%f"</span> % (key,cnt,avgCnt)</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">main()</div></pre></td></tr></table></figure><p>此方法数据量大了有点问题，统计的有问题，还在磨合中，下面给出参考如下链接写出的mapreduce两个版本的脚本。<br><a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/" target="_blank" rel="external">http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/</a></p><h3 id="mapreduce版"><a href="#mapreduce版" class="headerlink" title="mapreduce版"></a>mapreduce版</h3><h4 id="方法一-使用mapreduce的特性"><a href="#方法一-使用mapreduce的特性" class="headerlink" title="方法一:使用mapreduce的特性"></a>方法一:使用mapreduce的特性</h4><blockquote><p>排序完使用，比较下一条和上一条的数据的key，累计调用耗时，以及次数最终的到结果。<br>map.py:</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compare_time</span><span class="params">(sourceTime,reqtime)</span>:</span></div><div class="line">sourceTime = datetime.strptime(sourceTime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line">reqtime = datetime.strptime(reqtime.replace(<span class="string">'T'</span>,<span class="string">' '</span>).replace(<span class="string">"Z"</span>,<span class="string">''</span>),<span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</div><div class="line">retval = (reqtime-sourceTime).total_seconds()*<span class="number">1000</span></div><div class="line"><span class="keyword">return</span> retval</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(sep=<span class="string">","</span>)</span>:</span></div><div class="line">kv = &#123;&#125;</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">detail = line.strip().split(sep)</div><div class="line">restime = detail[<span class="number">1</span>]</div><div class="line">reqtime = detail[<span class="number">2</span>]</div><div class="line">value = compare_time(restime,reqtime)</div><div class="line">key = line.strip().split(<span class="string">"T"</span>,<span class="number">1</span>)[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> key+<span class="string">'\t'</span>+str(value)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">main()</div></pre></td></tr></table></figure><blockquote><p>red.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python  </span></div><div class="line"><span class="comment"># -*-coding:utf-8-*-   </span></div><div class="line"><span class="keyword">import</span> sys  </div><div class="line">  </div><div class="line">current_key = <span class="keyword">None</span>  </div><div class="line">total_take = <span class="number">0</span>  </div><div class="line">key = <span class="keyword">None</span></div><div class="line">times = <span class="number">0</span>  </div><div class="line">one = <span class="number">1</span></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:  </div><div class="line">    line = line.strip()  </div><div class="line">  </div><div class="line">    key, time_take = line.split(<span class="string">'\t'</span>, one)  </div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        time_take = float(time_take)  </div><div class="line">    <span class="keyword">except</span> ValueError:  </div><div class="line">        <span class="comment">#bad line pass </span></div><div class="line">        <span class="keyword">continue</span>  </div><div class="line">    <span class="keyword">if</span> current_key == key:  </div><div class="line">        total_take += time_take</div><div class="line">        times += one</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># if current_key ne next_key handle this logic and  print result,then init new key line data and init times</span></div><div class="line">        <span class="keyword">if</span> current_key:  </div><div class="line">            <span class="keyword">print</span> <span class="string">'%s\t%s\t%s'</span> % (current_key,times,total_take/times)  </div><div class="line">        total_take = time_take  </div><div class="line">        current_key = key</div><div class="line">        times = one  </div><div class="line"></div><div class="line"><span class="comment"># if stdin input over ,then handle this logic(there is no comparation after the last key compute ,so print here is necessary)</span></div><div class="line"><span class="keyword">if</span> current_key == key:</div><div class="line">    <span class="keyword">print</span> <span class="string">'%s\t%s\t%f'</span> % (current_key,times,total_take/times)</div></pre></td></tr></table></figure><h4 id="方法二-使用迭代器"><a href="#方法二-使用迭代器" class="headerlink" title="方法二　使用迭代器"></a>方法二　使用迭代器</h4><blockquote><p>同样也可以利用mapreduce中间的shuffle过程，map代码同上，reduce代码则使用yield生成迭代器同时配合groupby 工具函数来完成聚合。<br>reduce.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*-coding:utf-8-*-  </span></div><div class="line"><span class="comment">#!/usr/bin/env python  </span></div><div class="line"></div><div class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> groupby  </div><div class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter  </div><div class="line"><span class="keyword">import</span> sys  </div><div class="line">  </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_mapper_output</span><span class="params">(file, separator=<span class="string">'\t'</span>)</span>:</span>  </div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:  </div><div class="line">        <span class="keyword">yield</span> line.rstrip().split(separator, <span class="number">1</span>)  </div><div class="line">  </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator=<span class="string">'\t'</span>)</span>:</span>  </div><div class="line">    data = read_mapper_output(sys.stdin, separator=separator)  </div><div class="line">    <span class="keyword">for</span> current_word, group <span class="keyword">in</span> groupby(data, itemgetter(<span class="number">0</span>)):  </div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="comment"># (float(count) for current_word,count in group)'s return is generator,if you want handle this twice,</span></div><div class="line">            <span class="comment"># you should store　generator into one collection(here:list) ,if not the generator just can be used once,</span></div><div class="line">            <span class="comment"># because the generator.next()(once used) had pointed to the end,can’t　be used more.</span></div><div class="line">            res_temp = list(float(count) <span class="keyword">for</span> current_word,count <span class="keyword">in</span> group)</div><div class="line">            size_count = sum(<span class="number">1</span> <span class="keyword">for</span> _ <span class="keyword">in</span> res_temp)</div><div class="line">            total_count = sum(res_temp)</div><div class="line">            <span class="keyword">print</span> <span class="string">"%s%s%d%s%f"</span> % (current_word, separator, size_count ,separator ,total_count/size_count)</div><div class="line">        <span class="keyword">except</span> ValueError:  </div><div class="line">            <span class="keyword">pass</span>  </div><div class="line">  </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:  </div><div class="line">    main()</div></pre></td></tr></table></figure><blockquote><p>以上两种mapreduce实现逻辑，我以用蹩脚的英文解释，看不懂，就使劲儿看。</p></blockquote><ul><li>知识点</li></ul><blockquote><p>yield 的好处<br>Python 的老用户应该会熟悉 Python 2 中的一个特性：内建函数 range 和 xrange。其中，range 函数返回的是一个列表，而 xrange 返回的是一个迭代器。</p><p>在 Python 3 中，range 相当于 Python 2 中的 xrange；而 Python 2 中的 range 可以用 list(range()) 来实现。</p><p>Python 之所以要提供这样的解决方案，是因为在很多时候，我们只是需要逐个顺序访问容器内的元素。大多数时候，我们不需要「一口气获取容器内所有的元素」。比方说，顺序访问容器内的前 5 个元素，可以有两种做法：</p></blockquote><ol><li>获取容器内的所有元素，然后取出前 5 个；</li><li>从头开始，逐个迭代容器内的元素，迭代 5 个元素之后停止。</li></ol><blockquote><p>显而易见，如果容器内的元素数量非常多（比如有 10 ** 8 个），或者容器内的元素体积非常大，那么后一种方案能节省巨大的时间、空间开销。<br>现在假设，我们有一个函数，其产出（返回值）是一个列表。而若我们知道，调用者对该函数的返回值，只有逐个迭代这一种方式。那么，如果函数生产列表中的每一个元素都需要耗费非常多的时间，或者生成所有元素需要等待很长时间，则使用 yield 把函数变成一个生成器函数，每次只产生一个元素，就能节省很多开销了。特别是你在使用大的字典配置文件的时候这么用就有很大优势了,当然如果配置文件大小尚可,放到内存中去解析配置当然是最快的匹配途径.</p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote><p>mapreduce思想可以很自然的解决此类问题，但是也考虑到仅有map的情况下，怎么解决？但是这次写的代码还是存在问题，后续会解决更新。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> date </tag>
            
            <tag> count </tag>
            
            <tag> sum </tag>
            
            <tag> aggr </tag>
            
            <tag> mean </tag>
            
            <tag> panda </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mongo中实现带where的group by</title>
      <link href="/ITWO/2017/10/09/mongo-%E4%B8%AD%E5%AE%9E%E7%8E%B0%E5%B8%A6where%E7%9A%84group-by/"/>
      <url>/ITWO/2017/10/09/mongo-%E4%B8%AD%E5%AE%9E%E7%8E%B0%E5%B8%A6where%E7%9A%84group-by/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>需要在mongo中统计同一个时间段内各个账号的接口调用量．<a id="more"></a></p></blockquote><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路:"></a>解决思路:</h2><blockquote><p>通常我们在关系型数据库中可以这么解决:</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> <span class="keyword">account</span>,<span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> db.table <span class="keyword">where</span> requestTime&gt;=<span class="string">'2017-10-01'</span> <span class="keyword">and</span> requestTime &lt;<span class="string">'2017-10-08'</span></div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">account</span>;</div></pre></td></tr></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2><blockquote><p>参照sql语句的思路，然后给出mongo中的解决方案</p></blockquote><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">db.sysRequestWrapper.aggregate([</div><div class="line">    &#123;"$match":&#123;requestTime:&#123;$gte:ISODate("2017-10-01T00:00:00.000Z"),$lt:ISODate("2017-10-19T00:00:00.000Z")&#125;&#125;&#125;, </div><div class="line">    &#123;"$group":&#123;_id:&#123;account:"$account"&#125;,"count":&#123;"$sum":1&#125;&#125;&#125;</div><div class="line">]);</div></pre></td></tr></table></figure><blockquote><p>ps:如果需要实现having count(*)&gt;1 则你需要再在后面追加match,来实现对group by 聚合结果的过滤．<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">db.sysRequestWrapper.aggregate([</div><div class="line">    &#123;"$match":&#123;requestTime:&#123;$gte:ISODate("2017-10-01T00:00:00.000Z"),$lt:ISODate("2017-10-19T00:00:00.000Z")&#125;&#125;&#125;, </div><div class="line">    &#123;"$group":&#123;_id:&#123;account:"$account"&#125;,"count":&#123;"$sum":1&#125;&#125;&#125;,</div><div class="line">&#123;<span class="attr">"$match"</span>:&#123;<span class="attr">"count"</span>:&#123;<span class="attr">"$gt"</span>: <span class="number">1</span>&#125;&#125;&#125;</div><div class="line">]);</div></pre></td></tr></table></figure></p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> mongo </tag>
            
            <tag> groupby </tag>
            
            <tag> where </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ssh 免登陆设置</title>
      <link href="/ITWO/2017/09/29/ssh-%E5%85%8D%E7%99%BB%E9%99%86%E8%AE%BE%E7%BD%AE/"/>
      <url>/ITWO/2017/09/29/ssh-%E5%85%8D%E7%99%BB%E9%99%86%E8%AE%BE%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>在搭建大数据平台的时候，我们测试或者入门可以在local模式下进行，但是要模拟集群环境的话，就需要设置主从模式，这里已spark为例，搭建spark的standalone模式，因为涉及到远端启动所以我们需要设置ssh免登陆，<a id="more"></a></p></blockquote><h2 id="步骤如下"><a href="#步骤如下" class="headerlink" title="步骤如下:"></a>步骤如下:</h2><p> 1.在各个节点上使用ssh-keygen -t rsa,过程中三次回车即可,然后在当前用户的.ssh目录下面会生成私钥文件.<br> 2.我们需要将这个公钥文件使用scp拷贝到其他节点并且重命名为authorized_keys．<br> 3.跟有交互需求的拷贝自己的公钥文件给对方从而实现该节点可以免登陆到其他节点．．</p><p> 拷贝公钥代码如下:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">　scp id_rsa.pub B:~/.ssh/authorized_keys</div></pre></td></tr></table></figure></p>]]></content>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> spark </tag>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark lzo 体验</title>
      <link href="/ITWO/2017/09/21/spark-lzo-%E4%BD%93%E9%AA%8C/"/>
      <url>/ITWO/2017/09/21/spark-lzo-%E4%BD%93%E9%AA%8C/</url>
      <content type="html"><![CDATA[<h2 id="需求背景："><a href="#需求背景：" class="headerlink" title="需求背景："></a>需求背景：</h2><blockquote><p>项目中需要读取lzo文件并且提取其中的几个字段放到表中，与另一个文件join，建立映射文件，并存储为parquet格式。<a id="more"></a></p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><blockquote><p>具体实现如下：</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> midPidCard = sc.newAPIHadoopFile[<span class="type">LongWritable</span>, <span class="type">Text</span>, <span class="type">LzoTextInputFormat</span>](args(<span class="number">1</span>)).map(_._2.toString.split(<span class="string">","</span>)).map(mpc =&gt; <span class="type">MidPidCard</span>(mpc(<span class="number">1</span>), mpc(<span class="number">16</span>), mpc(<span class="number">0</span>), mpc(<span class="number">3</span>), mpc(<span class="number">18</span>))).toDF()</div></pre></td></tr></table></figure><h2 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h2><blockquote><p>一、使用hadoopapi指定输入文件格式为lzoText</p><p>二、需要注意的是该方法返回的是tuple格式的rdd。</p><p>tuple中有两个元素，</p><p>其一是文件中的行数据偏移量，</p><p>其二是当前行的内容，我们需要关心的是行内容，所以需要指定处理的内容为_._2。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> lzo </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>sublime 给文本排序</title>
      <link href="/ITWO/2017/09/21/sublime-%E7%BB%99%E6%96%87%E6%9C%AC%E6%8E%92%E5%BA%8F/"/>
      <url>/ITWO/2017/09/21/sublime-%E7%BB%99%E6%96%87%E6%9C%AC%E6%8E%92%E5%BA%8F/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>工作中有很多需求，例如：你需要把数据排序从而便于处理、一些约定好的算法需要你将所有的key按照顺序排好然后加密处理，这时，你就可以利用工具，那么sublime 怎么通过快捷键给文本按照首字母字典顺序排序?<a id="more"></a></p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2><h3 id="①方案一"><a href="#①方案一" class="headerlink" title="①方案一"></a>①方案一</h3><blockquote><p>前提数据多行排成列，然后</p></blockquote><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">1.</span>ctrl+A</div><div class="line"><span class="number">2.</span>F9</div></pre></td></tr></table></figure><h3 id="②方案二"><a href="#②方案二" class="headerlink" title="②方案二"></a>②方案二</h3><blockquote><p>放到文本文件中，然后使用如下命令去排序(有操作系统限制)</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sort file</div></pre></td></tr></table></figure><h2 id="结言"><a href="#结言" class="headerlink" title="结言:"></a>结言:</h2><blockquote><p>很容易上手。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> sublime </tag>
            
            <tag> sort </tag>
            
            <tag> 排序 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>shell 获取上个月或者上一年</title>
      <link href="/ITWO/2017/09/21/shell-%E8%8E%B7%E5%8F%96%E4%B8%8A%E4%B8%AA%E6%9C%88%E6%88%96%E8%80%85%E4%B8%8A%E4%B8%80%E5%B9%B4/"/>
      <url>/ITWO/2017/09/21/shell-%E8%8E%B7%E5%8F%96%E4%B8%8A%E4%B8%AA%E6%9C%88%E6%88%96%E8%80%85%E4%B8%8A%E4%B8%80%E5%B9%B4/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>开发过程中会遇到很多情况，有用到date函数去获得上个月（上一年）的需求，比如用来获取上个月的日志或者上个月的数据之类的诉求。<a id="more"></a></p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">lastMonth=`date -d <span class="string">"1 month ago"</span> +%Y_%m`</div><div class="line">lastYear=`date -d <span class="string">"1 year ago"</span> +%Y_%m`</div></pre></td></tr></table></figure><h2 id="结言："><a href="#结言：" class="headerlink" title="结言："></a>结言：</h2><blockquote><p>感觉很直观，很容易记住。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> date </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark scala中map和flatmap的区别</title>
      <link href="/ITWO/2017/09/19/spark-scala%E4%B8%ADmap%E5%92%8Cflatmap%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/ITWO/2017/09/19/spark-scala%E4%B8%ADmap%E5%92%8Cflatmap%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      <content type="html"><![CDATA[<h1 id="需求背景："><a href="#需求背景：" class="headerlink" title="需求背景："></a>需求背景：</h1><blockquote><p>统计相邻两个单词出现的次数。<a id="more"></a></p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> s=<span class="string">"A;B;C;D;B;D;C;B;D;A;E;D;C;A;B"</span></div><div class="line"></div><div class="line">s: <span class="type">String</span> = <span class="type">A</span>;<span class="type">B</span>;<span class="type">C</span>;<span class="type">D</span>;<span class="type">B</span>;<span class="type">D</span>;<span class="type">C</span>;<span class="type">B</span>;<span class="type">D</span>;<span class="type">A</span>;<span class="type">E</span>;<span class="type">D</span>;<span class="type">C</span>;<span class="type">A</span>;<span class="type">B</span></div><div class="line"></div><div class="line"> <span class="keyword">val</span> data=sc.parallelize(<span class="type">Seq</span>(s))</div><div class="line"></div><div class="line">data.collect()</div><div class="line"></div><div class="line">res0: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="type">A</span>;<span class="type">B</span>;<span class="type">C</span>;<span class="type">D</span>;<span class="type">B</span>;<span class="type">D</span>;<span class="type">C</span>;<span class="type">B</span>;<span class="type">D</span>;<span class="type">A</span>;<span class="type">E</span>;<span class="type">D</span>;<span class="type">C</span>;<span class="type">A</span>;<span class="type">B</span>)</div></pre></td></tr></table></figure><blockquote><p>截止目前位置是一个String类型的数组。</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> mapTemp=data.map(_.split(<span class="string">";"</span>))</div><div class="line"></div><div class="line">scala&gt; mapTemp.collect</div><div class="line"></div><div class="line">res4: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">String</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(<span class="type">A</span>, <span class="type">B</span>, <span class="type">C</span>, <span class="type">D</span>, <span class="type">B</span>, <span class="type">D</span>, <span class="type">C</span>, <span class="type">B</span>, <span class="type">D</span>, <span class="type">A</span>, <span class="type">E</span>, <span class="type">D</span>, <span class="type">C</span>, <span class="type">A</span>, <span class="type">B</span>))</div></pre></td></tr></table></figure><blockquote><p>map操作在于处理之前和处理之后的数据类型是一致的。</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> mapRs=data.map(_.split(<span class="string">";"</span>)).map(x=&gt;&#123;<span class="keyword">for</span>(i&lt;<span class="number">-0</span> until x.length<span class="number">-1</span>) <span class="keyword">yield</span> (x(i)+<span class="string">","</span>+x(i+<span class="number">1</span>),<span class="number">1</span>)&#125;)</div><div class="line"></div><div class="line">mapRs.collect</div><div class="line"></div><div class="line">res1: <span class="type">Array</span>[scala.collection.immutable.<span class="type">IndexedSeq</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = <span class="type">Array</span>(<span class="type">Vector</span>((<span class="type">A</span>,<span class="type">B</span>,<span class="number">1</span>), (<span class="type">B</span>,<span class="type">C</span>,<span class="number">1</span>), (<span class="type">C</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">B</span>,<span class="number">1</span>), (<span class="type">B</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">C</span>,<span class="number">1</span>), (<span class="type">C</span>,<span class="type">B</span>,<span class="number">1</span>), (<span class="type">B</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">A</span>,<span class="number">1</span>), (<span class="type">A</span>,<span class="type">E</span>,<span class="number">1</span>), (<span class="type">E</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">C</span>,<span class="number">1</span>), (<span class="type">C</span>,<span class="type">A</span>,<span class="number">1</span>), (<span class="type">A</span>,<span class="type">B</span>,<span class="number">1</span>)))</div></pre></td></tr></table></figure><blockquote><p><em>map输出的数据类型:Array[scala.collection.immutable.IndexedSeq[(String, Int)]]</em><br>而flatMap会把一类集合类的数据抹平从而展示的效果是元素的方式，真实效果:从Vector中遍历然后罗列出来。</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> flatMapRs=data.map(_.split(<span class="string">";"</span>)).flatMap(x=&gt;&#123;<span class="keyword">for</span>(i&lt;<span class="number">-0</span> until x.length<span class="number">-1</span>) <span class="keyword">yield</span>　(x(i)+<span class="string">","</span>+x(i+<span class="number">1</span>),<span class="number">1</span>)&#125;)</div><div class="line"></div><div class="line">flatMapRs.collect</div><div class="line"></div><div class="line">res3: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="type">A</span>,<span class="type">B</span>,<span class="number">1</span>), (<span class="type">B</span>,<span class="type">C</span>,<span class="number">1</span>), (<span class="type">C</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">B</span>,<span class="number">1</span>), (<span class="type">B</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">C</span>,<span class="number">1</span>), (<span class="type">C</span>,<span class="type">B</span>,<span class="number">1</span>), (<span class="type">B</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">A</span>,<span class="number">1</span>), (<span class="type">A</span>,<span class="type">E</span>,<span class="number">1</span>), (<span class="type">E</span>,<span class="type">D</span>,<span class="number">1</span>), (<span class="type">D</span>,<span class="type">C</span>,<span class="number">1</span>), (<span class="type">C</span>,<span class="type">A</span>,<span class="number">1</span>), (<span class="type">A</span>,<span class="type">B</span>,<span class="number">1</span>))</div></pre></td></tr></table></figure><blockquote><p>flatmap输出的数据类型:Array[(String, Int)]*</p></blockquote><h2 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> flatMap= data.map(_.split(<span class="string">";"</span>)).flatMap(x=&gt;&#123;<span class="keyword">for</span>(i&lt;<span class="number">-0</span> until x.length<span class="number">-1</span>) <span class="keyword">yield</span> (x(i)+<span class="string">","</span>+x(i+<span class="number">1</span>),<span class="number">1</span>)&#125;).reduceByKey(_+_).foreach(println)</div></pre></td></tr></table></figure><p>(A,E,1)</p><p>(C,D,1)</p><p>(B,D,2)</p><p>(D,B,1)</p><p>(C,A,1)</p><p>(C,B,1)</p><p>(E,D,1)</p><p>(D,A,1)</p><p>(B,C,1)</p><p>(D,C,2)</p><p>(A,B,2)</p><h2 id="如果只是做抹平操作该怎么做"><a href="#如果只是做抹平操作该怎么做" class="headerlink" title="如果只是做抹平操作该怎么做"></a>如果只是做抹平操作该怎么做</h2><blockquote><p>Array(Array(A, B, C, D, B, D, C, B, D, A, E, D, C, A, B)) =&gt; Array(A, B, C, D, B, D, C, B, D, A, E, D, C, A, B)<br>=&gt; for (i &lt;- Array) print i<br> data.map(_.split(“;”)).flatMap(item =&gt; item).foreach(println)<br>A<br>B<br>C<br>D<br>B<br>D<br>C<br>B<br>D<br>A<br>E<br>D<br>C<br>A<br>B</p></blockquote><h2 id="源码走一趟"><a href="#源码走一趟" class="headerlink" title="源码走一趟"></a>源码走一趟</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">B</span>](f: <span class="type">A</span> =&gt; <span class="type">GenTraversableOnce</span>[<span class="type">B</span>]): <span class="type">Iterator</span>[<span class="type">B</span>] = <span class="keyword">new</span> <span class="type">AbstractIterator</span>[<span class="type">B</span>] &#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">var</span> cur: <span class="type">Iterator</span>[<span class="type">B</span>] = empty</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> =</div><div class="line">    cur.hasNext || self.hasNext &amp;&amp; &#123; cur = f(self.next).toIterator; hasNext &#125;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">B</span> = (<span class="keyword">if</span> (hasNext) cur <span class="keyword">else</span> empty).next()</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下:"></a>总结一下:</h2><blockquote><p>处理以前一定要意识到你自己最终拿到的数据的格式,如果是集合类的你则最终需要需要flat(抹平操作),从而才能使用一些函数对每个元素进行处理.</p></blockquote><h2 id="reduceByKey算数因子解释："><a href="#reduceByKey算数因子解释：" class="headerlink" title="reduceByKey算数因子解释："></a>reduceByKey算数因子解释：</h2><blockquote><p>Basically reduceByKey function works only for RDDs which contains key and value pairs kind of   elements(i.e RDDs having tuple or Map as a data element). It is a transformation operation   which means it is lazily evaluated.We need to pass one associative function as a parameter,   which will be applied to the source RDD and will create anew RDD as with resulting values(i.e.  key value pair). This operation is a wide operation as data shuffling may happen across the   partitions.【本质上来讲，reduceByKey函数（说算子也可以）只作用于包含key-value的RDDS上，它是  transformation类型的算子，这也就意味着它是懒加载的（就是说不调用Action的方法，是不会去计算的  ）,在使用时，我们需要传递一个相关的函数（<em>+</em>）作为参数，这个函数将会被应用到源RDD上并且创建一个新的  RDD作为返回结果，这个算子作为data Shuffling 在分区的时候被广泛使用】  </p></blockquote><h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h2><blockquote><p>Spark RDD flatMap function returns a new RDD by first applying a function to all elements of this RDD, and then flattening the results.<br>Important points to note are,</p></blockquote><ul><li>flatMap is a transformation operation in Spark hence it is lazily evaluated</li><li>It is a narrow operation as  it is not shuffling data from one partition to multiple partitions </li><li>Output of flatMap is flatten</li><li>flatMap parameter function should return array, list or sequence (anysubtype of scala.TraversableOnce)</li></ul>]]></content>
      
      
        <tags>
            
            <tag> scala </tag>
            
            <tag> spark </tag>
            
            <tag> map </tag>
            
            <tag> flatmap </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何在ubantu中设置任务栏和菜单中的快速启动和搜索</title>
      <link href="/ITWO/2017/09/19/%E5%A6%82%E4%BD%95%E5%9C%A8ubantu%E4%B8%AD%E8%AE%BE%E7%BD%AE%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%92%8C%E8%8F%9C%E5%8D%95%E4%B8%AD%E7%9A%84%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E5%92%8C%E6%90%9C%E7%B4%A2/"/>
      <url>/ITWO/2017/09/19/%E5%A6%82%E4%BD%95%E5%9C%A8ubantu%E4%B8%AD%E8%AE%BE%E7%BD%AE%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%92%8C%E8%8F%9C%E5%8D%95%E4%B8%AD%E7%9A%84%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E5%92%8C%E6%90%9C%E7%B4%A2/</url>
      <content type="html"><![CDATA[<h2 id="背景需求"><a href="#背景需求" class="headerlink" title="背景需求:"></a>背景需求:</h2><blockquote><p>一些应用程序（例如很多.sh程序）如果想在Ubuntu中添加到Dash home中进行快速的启动.<a id="more"></a></p></blockquote><h2 id="场景分析"><a href="#场景分析" class="headerlink" title="场景分析:"></a>场景分析:</h2><blockquote><p>需要找到/usr/share/applications这个目录，其中存放的全部是dash中的启动器，将你需要的程序xxx添加其中即可。</p></blockquote><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现:"></a>技术实现:</h2><blockquote><p>具体操作步骤为：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/share/applications sudo gedit xxx.desktop</div></pre></td></tr></table></figure><blockquote><p>打开需要编辑的文本内容为：</p></blockquote><figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="section">[Desktop Entry]</span> </div><div class="line"><span class="attr">Version</span>=<span class="number">1.0</span> </div><div class="line"><span class="attr">Name</span>=robomongo</div><div class="line"><span class="attr">GenericName</span>=robomongo</div><div class="line"><span class="attr">Keywords</span>=mongo;robo;robomongo (此配置是在程序搜索时，可以使用罗列的关键字)</div><div class="line"><span class="attr">Exec</span>=/home/username/xxx.sh（这个是启动程序需要执行的文件路径名） </div><div class="line"><span class="attr">Terminal</span>=<span class="literal">false</span> </div><div class="line"><span class="attr">Icon</span>=/home/username/xxx.png（这个是图标，这个一般程序里面不带，可以去官网找logo） </div><div class="line"><span class="attr">Type</span>=Application </div><div class="line"><span class="attr">Categories</span>=Development</div></pre></td></tr></table></figure><blockquote><p>这样就可以在dash中看到xxx的启动器图标了，也可以直接将其添加锁定到launcher</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> ubantu </tag>
            
            <tag> dash </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark 项目启动的时候报出如下错误</title>
      <link href="/ITWO/2017/09/19/spark-%E9%A1%B9%E7%9B%AE%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5%E5%87%BA%E5%A6%82%E4%B8%8B%E9%94%99%E8%AF%AF/"/>
      <url>/ITWO/2017/09/19/spark-%E9%A1%B9%E7%9B%AE%E5%90%AF%E5%8A%A8%E7%9A%84%E6%97%B6%E5%80%99%E6%8A%A5%E5%87%BA%E5%A6%82%E4%B8%8B%E9%94%99%E8%AF%AF/</url>
      <content type="html"><![CDATA[<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h2><blockquote><p>在spark打包启动的时候报错信息如下:</p></blockquote><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">“class "javax.servlet.FilterRegistration"'s signer information does not match signer information of other classes in the same package”</div></pre></td></tr></table></figure><h2 id="细节分析"><a href="#细节分析" class="headerlink" title="细节分析:"></a>细节分析:</h2><blockquote><p>从字面意思可以看出是因为pom中有多个jar包中出现了该类，在程序中或者依赖的程序去使用该类的时候导致无法唯一确定jar包的来源.</p></blockquote><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2><blockquote><p>对于此类问题处理的方式是：<br>找到该类所在的父gav然后在其中exesusion掉该jar包，因为exesusion只可以指定到ga,所以就会把该类所有的jar包去掉，但是如果这么用又会出现该类找不到（no class found）,此时的解决办法就是引入一个确定的jar包版本指定gav,放在exclusion父类之前.</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> match </tag>
            
            <tag> not </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ubantu16.04怎么彻底移除mysql</title>
      <link href="/ITWO/2017/09/18/ubantu16-04%E6%80%8E%E4%B9%88%E5%BD%BB%E5%BA%95%E7%A7%BB%E9%99%A4mysql/"/>
      <url>/ITWO/2017/09/18/ubantu16-04%E6%80%8E%E4%B9%88%E5%BD%BB%E5%BA%95%E7%A7%BB%E9%99%A4mysql/</url>
      <content type="html"><![CDATA[<h1 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h1><p>安装mysql之后不小心造成不可挽回的错误,造成崩溃,修复就没有重新安装来的省心,当然前提是在你本地损坏了.<a id="more"></a></p><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo apt purge mysql-*</div><div class="line">sudo rm -rf /etc/mysql/ /var/lib/mysql</div><div class="line">sudo apt autoremove</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> ubantu </tag>
            
            <tag> mysql </tag>
            
            <tag> 移除 </tag>
            
            <tag> remove </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>git commit 怎么撤销</title>
      <link href="/ITWO/2017/09/18/git-commit-%E6%80%8E%E4%B9%88%E6%92%A4%E9%94%80/"/>
      <url>/ITWO/2017/09/18/git-commit-%E6%80%8E%E4%B9%88%E6%92%A4%E9%94%80/</url>
      <content type="html"><![CDATA[<h1 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h1><blockquote><p>当你不小心提交错某个文件或者或者多提交了某些文件，并且还没有push.<br><a id="more"></a><br>可以使用如下步骤来回退到提交前的状态.    （ps:每次提交先stash,pull,stash pop 然后再commit,push）</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">log</span></div></pre></td></tr></table></figure><blockquote><p>会打印出所有的提交历史。<br>然后定位到自己想要回退到的对应版本,找到其hash值。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">commit 0c17bf55de2054ffd6bd67714c75c0861618e3de</div><div class="line">Author: aa</div><div class="line">Date:   Tue Aug 8 18:14:16 2017 +0800</div><div class="line"></div><div class="line">    bug fix: aa fix</div><div class="line"></div><div class="line">commit 7fc618a62b219829089cb47a6c04db95157a2b4f</div><div class="line">Author: bb</div><div class="line">Date:   Tue Aug 8 17:56:04 2017 +0800</div><div class="line"></div><div class="line">   bb fix bug</div></pre></td></tr></table></figure><blockquote><p>然后使用git reset –hard commitid 回退到对应版本。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> git </tag>
            
            <tag> commit </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>apache http ssl模块NoClassDefFoundError: org/apache/http/ssl/TrustStrategy</title>
      <link href="/ITWO/2017/09/18/apache-http-ssl%E6%A8%A1%E5%9D%97NoClassDefFoundError-org-apache-http-ssl-TrustStrategy/"/>
      <url>/ITWO/2017/09/18/apache-http-ssl%E6%A8%A1%E5%9D%97NoClassDefFoundError-org-apache-http-ssl-TrustStrategy/</url>
      <content type="html"><![CDATA[<h1 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景:"></a>需求背景:</h1><blockquote><p>项目中有链接https接口的请求所以使用了,apache的httpcomponents中的httpclient,但是启动测试的时候报错，NoClassDefFoundError: org/apache/http/ssl/TrustStrategy<br><a id="more"></a></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2><p>然后找了下该类竟然出现在三个版本的包中，使用mvn dependency:tree &gt;temp,找到了dubbo、disconf中也有出现，然后exclued掉.但是还是报错找不到类，后来发现该包正确使用的包在dubbo的引用下面，把该包的引用移动到上面，然后问题解决。</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> apache </tag>
            
            <tag> https </tag>
            
            <tag> ssl </tag>
            
            <tag> NoClassDefFound </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>shell在指定行插入文本</title>
      <link href="/ITWO/2017/09/18/shell%E5%9C%A8%E6%8C%87%E5%AE%9A%E8%A1%8C%E6%8F%92%E5%85%A5%E6%96%87%E6%9C%AC/"/>
      <url>/ITWO/2017/09/18/shell%E5%9C%A8%E6%8C%87%E5%AE%9A%E8%A1%8C%E6%8F%92%E5%85%A5%E6%96%87%E6%9C%AC/</url>
      <content type="html"><![CDATA[<h1 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h1><blockquote><p>在指定行插入特定文本<a id="more"></a></p></blockquote><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sed -i <span class="string">'第几行i文本内容'</span> 文件</div></pre></td></tr></table></figure><p>ps:sed -i 会直接改变文件的内容</p><h2 id="特殊用法"><a href="#特殊用法" class="headerlink" title="特殊用法"></a>特殊用法</h2><blockquote><p>在a文件的第三行插入只有一个空格的空行</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sed -i <span class="string">'3i\ '</span> a</div></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> sed </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
